# Table of Contents

- [Directory](#directory)
- [Analysis](#analysis)
- [Code Files](#code-files)
- [Report Generated On](#report-generated-on)

# Report Generated On

*Generated on 10/30/2024, 5:11:59 PM*


# Directory

```
├── config
│   └── default.js
├── routes
│   ├── convertRoutes.js
│   └── proxyRoutes.js
├── services
│   ├── converter
│   │   ├── data
│   │   │   ├── csvConverter.js
│   │   │   ├── jsonConverter.js
│   │   │   ├── xlsxConverter.js
│   │   │   └── yamlConverter.js
│   │   ├── multimedia
│   │   │   ├── audioconverter.js
│   │   │   └── videoConverter.js
│   │   ├── text
│   │   │   ├── docxConverter.js
│   │   │   ├── epubConverter.js
│   │   │   ├── odtConverter.js
│   │   │   ├── pdfConverter.js
│   │   │   ├── pptxConverter.js
│   │   │   ├── rtfConverter.js
│   │   │   └── txtConverter.js
│   │   ├── web
│   │   │   ├── htmlConverter.js
│   │   │   ├── parentUrlConverter.js
│   │   │   ├── urlConverter.js
│   │   │   ├── xmlConverter.js
│   │   │   └── youtubeConverter.js
│   │   └── textConverterFactory.js
│   ├── fileProcessor.js
│   ├── fileStorage.js
│   ├── openaiProxy.js
│   └── transcriber.js
├── temp
├── utils
│   ├── errorHandler.js
│   └── markdownGenerator.js
├── package.json
└── server.js

```

# Analysis

No analysis was generated.

# Code Files

## config/default.js

```js
// config/default.js

export const config = {
  server: {
    port: process.env.PORT || 3000,
    env: process.env.NODE_ENV || 'development'
  },
  api: {
    openai: {
      baseUrl: 'https://api.openai.com/v1',
      timeout: 30000,
      maxRetries: 3,
      apiKey: process.env.OPENAI_API_KEY
    }
  },
  conversion: {
    allowedFileTypes: [
      "txt", "rtf", "pdf", "docx", "odt", "epub",
      "csv", "json", "yaml", "yml", "xlsx", "pptx",
      "html", "htm", "xml",
      "mp3", "wav", "ogg", "mp4", "mov", "avi", "webm"
    ],
    maxFileSize: 52428800
  },
  storage: {
    tempDir: '/tmp/obsidian-converter'
  },
  security: {
    rateLimitPerMinute: 100
  }
};

```

## package.json

```json
{
  "name": "obsidian-note-converter",
  "version": "1.0.0",
  "description": "A service to convert various file types to Obsidian-compatible Markdown notes",
  "main": "src/server.js",
  "type": "module",
  "imports": {
    "pdfjs-dist": {
      "default": "pdfjs-dist/build/pdf.mjs"
    }
  },
  "scripts": {
    "start": "node src/server.js",
    "dev": "nodemon src/server.js",
    "test": "jest",
    "lint": "eslint .",
    "build": "babel src -d dist",
    "precommit": "lint-staged"
  },
  "keywords": [
    "obsidian",
    "markdown",
    "converter",
    "notes"
  ],
  "author": "Your Name",
  "license": "MIT",
  "dependencies": {
    "@bundled-es-modules/pdfjs-dist": "^3.6.172-alpha.1",
    "@iarna/rtf-to-html": "^1.1.0",
    "@squoosh/lib": "^0.3.1",
    "archiver": "^7.0.1",
    "axios-retry": "^3.3.1",
    "config": "^3.3.6",
    "cors": "^2.8.5",
    "dotenv": "^16.4.5",
    "epub": "^1.2.1",
    "express": "^4.17.1",
    "express-rate-limit": "^6.7.0",
    "express-validator": "^6.14.0",
    "ffmpeg-static": "^5.1.0",
    "fluent-ffmpeg": "^2.1.2",
    "helmet": "^6.0.0",
    "joi": "^17.9.2",
    "limiter": "^2.1.0",
    "mammoth": "^1.4.21",
    "multer": "^1.4.2",
    "node-cache": "^5.1.2",
    "node-cron": "^3.0.0",
    "node-fetch": "^3.3.2",
    "node-poppler": "^7.2.2",
    "openai": "^4.0.0",
    "p-limit": "^3.1.0",
    "pdf-img-convert": "^2.0.0",
    "pdf-parse": "^1.1.1",
    "pdf.js": "^0.1.0",
    "pdfjs-dist": "^2.16.105",
    "sanitize-filename": "^1.6.3",
    "sharp": "^0.33.5",
    "turndown": "^7.2.0",
    "winston": "^3.3.3",
    "winston-daily-rotate-file": "^4.6.5",
    "xlsx": "^0.18.5",
    "yaml": "^2.2.1"
  },
  "overrides": {
    "pdf-export-images": {
      "pdfjs-dist": "3.11.174"
    }
  },
  "devDependencies": {
    "@babel/cli": "^7.14.8",
    "@babel/core": "^7.15.0",
    "@babel/preset-env": "^7.15.0",
    "axios": "^1.7.7",
    "canvas": "^2.11.2",
    "cheerio": "^1.0.0",
    "commander": "^12.1.0",
    "csv-parse": "^5.5.6",
    "eslint": "^7.32.0",
    "husky": "^8.0.0",
    "jest": "^27.0.6",
    "jsdom": "^25.0.1",
    "jszip": "^3.10.1",
    "lint-staged": "^13.1.0",
    "nodemon": "^2.0.12",
    "office-text-extractor": "^3.0.3",
    "officeparser": "^5.0.0",
    "pdf-export-images": "^1.2.0",
    "pdf-extractor": "^2.2.0",
    "pdf-lib": "^1.17.1",
    "puppeteer": "^23.6.0",
    "tmp-promise": "^3.0.3",
    "xml2js": "^0.6.2",
    "youtube-transcript": "^1.2.1"
  },
  "lint-staged": {
    "*.js": [
      "eslint --fix",
      "git add"
    ]
  },
  "engines": {
    "node": ">=14.0.0"
  }
}

```

## routes/convertRoutes.js

```js
// routes/convertRoutes.js

import express from 'express';
import { body, validationResult } from 'express-validator';
import { textConverterFactory } from '../services/converter/textConverterFactory.js';
import { config } from '../config/default.js';
import { AppError } from '../utils/errorHandler.js';
import rateLimit from 'express-rate-limit';
import multer from 'multer';
import path from 'path';
import JSZip from 'jszip';

/**
 * Router configuration and middleware setup
 */
const router = express.Router();

/**
 * Rate limiter configuration - 100 requests per minute
 */
const rateLimiter = rateLimit({
  windowMs: 60 * 1000,
  max: config.security.rateLimitPerMinute,
  message: 'Too many requests from this IP, please try again after a minute',
  standardHeaders: true,
  legacyHeaders: false,
});

/**
 * Multer storage and upload configuration
 */
const multerConfig = {
  storage: multer.memoryStorage(),
  limits: {
    fileSize: config.conversion.maxFileSize,
    files: 1
  },
  fileFilter: (req, file, cb) => {
    try {
      console.log('Processing file:', {
        originalname: file.originalname,
        mimetype: file.mimetype,
        size: file.size
      });

      const ext = path.extname(file.originalname).toLowerCase().slice(1);
      if (config.conversion.allowedFileTypes.includes(ext)) {
        cb(null, true);
      } else {
        cb(new AppError(
          `Unsupported file type: ${ext}. Allowed types: ${config.conversion.allowedFileTypes.join(', ')}`,
          400
        ));
      }
    } catch (error) {
      console.error('File filter error:', error);
      cb(new AppError('Error processing file', 500));
    }
  }
};

const upload = multer(multerConfig).single('file');

/**
 * Validation middleware
 */
const validators = {
  apiKey: (req, _res, next) => {
    const apiKey = req.headers['x-api-key'];
    
    if (!apiKey) {
      return next(new AppError('API key is required', 401));
    }

    if (!apiKey.startsWith('sk-')) {
      return next(new AppError('Invalid API key format', 401));
    }

    next();
  },

  file: [
    body('fileType')
      .optional()
      .isString()
      .withMessage('fileType must be a string')
      .custom(value => {
        if (value && !config.conversion.allowedFileTypes.includes(value)) {
          throw new Error(`Unsupported file type. Allowed types: ${config.conversion.allowedFileTypes.join(', ')}`);
        }
        return true;
      })
  ],

  url: [
    body('url')
      .notEmpty()
      .withMessage('URL is required')
      .isURL()
      .withMessage('Invalid URL format')
  ],

  parentUrl: [
    body('parentUrl')
      .notEmpty()
      .withMessage('Parent URL is required')
      .isURL()
      .withMessage('Invalid URL format')
  ],

  checkResult: (req, _res, next) => {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      return next(new AppError('Validation failed', 400, errors.array()));
    }
    next();
  }
};

/**
 * Error handlers
 */
const errorHandlers = {
  multer: (error, _req, _res, next) => {
    if (error instanceof multer.MulterError) {
      if (error.code === 'LIMIT_FILE_SIZE') {
        return next(new AppError(
          `File size exceeds limit of ${config.conversion.maxFileSize / (1024 * 1024)}MB`,
          400
        ));
      }
      return next(new AppError(`Upload error: ${error.message}`, 400));
    }
    next(error);
  },

  general: (err, _req, res, _next) => {
    console.error('Route error:', {
      message: err.message,
      stack: err.stack,
      details: err.details
    });

    res.status(err.statusCode || 500).json({
      success: false,
      error: {
        message: err.message,
        code: err.code || 'INTERNAL_ERROR',
        details: err.details || null
      }
    });
  }
};

/**
 * Conversion handlers
 */
const conversionHandlers = {
  file: async (req, res, next) => {
    try {
      if (!req.file) {
        throw new AppError('No file uploaded', 400);
      }

      const fileType = req.body.fileType || 
        path.extname(req.file.originalname).toLowerCase().slice(1);

      console.log('Converting file:', {
        name: req.file.originalname,
        type: fileType
      });

      const result = await textConverterFactory.convertToMarkdown(
        fileType,
        req.file.buffer,
        req.file.originalname
      );

      res.json({
        success: true,
        content: result.content,
        images: result.images || [],
        metadata: {
          originalName: req.file.originalname,
          type: fileType,
          hasImages: result.images?.length > 0
        }
      });

    } catch (error) {
      console.error('File conversion error:', error);
      next(new AppError('File conversion failed', 500, error.message));
    }
  },

  url: async (req, res, next) => {
    try {
      const { url } = req.body;
      console.log('Converting URL:', url);

      const result = await textConverterFactory.convertToMarkdown(
        'url',
        url,
        new URL(url).hostname
      );

      res.json({
        success: true,
        content: result.content,
        images: result.images || [],
        metadata: {
          originalUrl: url,
          type: 'url'
        }
      });

    } catch (error) {
      console.error('URL conversion error:', error);
      next(new AppError(
        `URL conversion failed: ${error.message}`,
        500,
        error.stack
      ));
    }
  },

  parentUrl: async (req, res, next) => {
    try {
      const { parentUrl } = req.body;
      console.log('Converting Parent URL:', parentUrl);

      const result = await textConverterFactory.convertToMarkdown(
        'parentUrl',
        parentUrl,
        new URL(parentUrl).hostname,
        req.headers['x-api-key']
      );

      res.json({
        success: true,
        content: result.content,
        images: result.images || [],
        metadata: {
          originalUrl: parentUrl,
          type: 'parentUrl',
          childUrls: result.childUrls || []
        }
      });

    } catch (error) {
      console.error('Parent URL conversion error:', error);
      next(new AppError(
        `Parent URL conversion failed: ${error.message}`,
        500,
        error.stack
      ));
    }
  }
};

/**
 * Route handlers
 */
const routes = {
  health: (_req, res) => {
    res.json({
      status: 'OK',
      timestamp: new Date().toISOString(),
      allowedTypes: config.conversion.allowedFileTypes,
      version: process.env.npm_package_version || '1.0.0'
    });
  }
};

// Apply rate limiter to all routes
router.use(rateLimiter);

// File conversion endpoint
router.post('/file',
  validators.apiKey,
  validators.file,
  (req, res, next) => {
    upload(req, res, err => {
      if (err) return errorHandlers.multer(err, req, res, next);
      conversionHandlers.file(req, res, next);
    });
  }
);

// URL conversion endpoint
router.post('/url',
  validators.apiKey,
  validators.url,
  validators.checkResult,
  conversionHandlers.url
);

// Parent URL endpoint
router.post('/parent-url',
  validators.apiKey,
  validators.parentUrl,
  validators.checkResult,
  conversionHandlers.parentUrl
);

// Health check endpoint
router.get('/health', routes.health);

// Error handling middleware
router.use(errorHandlers.general);

export default router;
```

## routes/proxyRoutes.js

```js
// routes/proxyRoutes.js
import express from 'express';
import { body, validationResult } from 'express-validator';
import { openaiProxy } from '../services/openaiProxy.js';
import { AppError } from '../utils/errorHandler.js';
import rateLimit from 'express-rate-limit';
import { config } from '../config/default.js';

const router = express.Router();

// Rate limiter specific to proxy routes
const proxyLimiter = rateLimit({
  windowMs: 60 * 1000, // 1 minute
  max: config.security.rateLimitPerMinute,
  message: 'Too many requests to proxy API, please try again after a minute.',
});

// Apply rate limiter to all proxy routes
router.use(proxyLimiter);

// Validation middleware
const validateProxyRequest = [
  body('endpoint')
    .notEmpty()
    .withMessage('Endpoint is required')
    .isString()
    .withMessage('Endpoint must be a string'),
  body('data')
    .optional()
    .isObject()
    .withMessage('Data must be an object'),
];

router.post('/openai', validateProxyRequest, async (req, res, next) => {
  // Handle validation errors
  const errors = validationResult(req);
  if (!errors.isEmpty()) {
    return next(new AppError('Validation failed', 400, errors.array()));
  }

  try {
    const apiKey = req.headers['x-api-key'];
    if (!apiKey) {
      throw new AppError('API key is required in headers', 401);
    }

    const { endpoint, data } = req.body;

    const response = await openaiProxy.makeRequest(apiKey, endpoint, data);
    res.json(response);
  } catch (error) {
    next(error);
  }
});

export default router;

```

## server.js

```js
// server.js

import express from 'express';
import cors from 'cors';
import helmet from 'helmet';
import { config } from './config/default.js';
import convertRoutes from './routes/convertRoutes.js';
import proxyRoutes from './routes/proxyRoutes.js';
import { errorHandler } from './utils/errorHandler.js';
import rateLimit from 'express-rate-limit';
import dotenv from 'dotenv';

// Load environment variables from .env file
dotenv.config();

const app = express();
const PORT = process.env.PORT || config.server.port || 3000;
const ENV = process.env.NODE_ENV || config.server.env || 'development';

// Middleware
app.use(helmet());

// Configure CORS to allow specific origins and headers
app.use(cors({
  origin: ['http://localhost:5173', 'https://your-frontend-domain.com'], // Update as needed
  methods: ['GET', 'POST', 'OPTIONS'], // Include OPTIONS method for preflight
  allowedHeaders: ['Content-Type', 'Authorization', 'x-api-key'], // Add 'x-api-key' here
  credentials: true, // If you need to send cookies or authentication headers
}));

// Handle preflight requests globally
app.options('*', cors());

// Global Rate Limiter
const globalLimiter = rateLimit({
  windowMs: 60 * 1000, // 1 minute
  max: config.security.rateLimitPerMinute * 2, // Example: global rate limit
  message: 'Too many requests from this IP, please try again later.',
});

app.use(globalLimiter);

app.use(express.json());
app.use(express.urlencoded({ extended: true }));

// API Routes with versioning
app.use('/api/v1/convert', convertRoutes);
app.use('/api/v1/proxy', proxyRoutes);

// Health check route
app.get('/health', (req, res) => {
  res.status(200).json({ status: 'OK', message: 'Server is running' });
});

// Error handling middleware
app.use(errorHandler);

// Start server
app.listen(PORT, () => {
  console.log(`Server is running on port ${PORT}`);
  console.log(`Environment: ${ENV}`);
  console.log(`Allowed file types: ${config.conversion.allowedFileTypes.join(', ')}`);
});

export default app;

```

## services/converter/data/csvConverter.js

```js
// services/converter/data/csvConverter.js

import { parse } from 'csv-parse/sync';

/**
 * Converts a CSV buffer or string to Markdown format.
 * @param {Buffer|string} input - The CSV content as a buffer or string.
 * @param {string} originalName - Original filename for context.
 * @param {string} [apiKey] - API key if needed.
 * @returns {Promise<{ content: string, images: Array }>} - Converted content and images.
 */
export async function convertCsvToMarkdown(input, originalName, apiKey) {
  try {
    // Convert buffer to string if necessary
    const csvContent = Buffer.isBuffer(input) ? input.toString('utf-8') : input;

    // Parse the CSV data
    const records = parse(csvContent, {
      columns: true,
      skip_empty_lines: true
    });

    if (records.length === 0) {
      return { content: "The CSV file is empty.", images: [] };
    }

    // Get headers
    const headers = Object.keys(records[0]);

    // Create Markdown table
    let markdownTable = `| ${headers.join(' | ')} |\n`;
    markdownTable += `| ${headers.map(() => '---').join(' | ')} |\n`;

    // Add data rows
    records.forEach(record => {
      markdownTable += `| ${headers.map(header => record[header] || '').join(' | ')} |\n`;
    });

    return { content: markdownTable, images: [] };
  } catch (error) {
    console.error('Error converting CSV to Markdown:', error);
    throw error;
  }
}

```

## services/converter/data/jsonConverter.js

```js
// services/converter/data/jsonConverter.js

/**
 * Converts a JSON buffer or string to Markdown format.
 * @param {Buffer|string} input - The JSON content as a buffer or string.
 * @param {string} originalName - Original filename for context.
 * @param {string} [apiKey] - API key if needed.
 * @returns {Promise<{ content: string, images: Array }>} - Converted content and images.
 */
export async function convertJsonToMarkdown(input, originalName, apiKey) {
  try {
    // Convert buffer to string if necessary
    const jsonContent = Buffer.isBuffer(input) ? input.toString('utf-8') : input;

    // Parse the JSON data
    const jsonData = JSON.parse(jsonContent);

    // Convert JSON to Markdown
    const markdownContent = jsonToMarkdown(jsonData);

    return { content: markdownContent, images: [] };
  } catch (error) {
    console.error('Error converting JSON to Markdown:', error);
    throw error;
  }
}

/**
 * Recursively converts JSON data to Markdown format.
 * @param {any} data - The JSON data to convert.
 * @param {number} depth - The current depth for nested structures.
 * @returns {string} - The converted Markdown string.
 */
function jsonToMarkdown(data, depth = 0) {
  const indent = '  '.repeat(depth);

  if (Array.isArray(data)) {
    return data.map(item => `${indent}- ${jsonToMarkdown(item, depth + 1)}`).join('\n');
  } else if (typeof data === 'object' && data !== null) {
    return Object.entries(data)
      .map(([key, value]) => `${indent}- **${key}**: ${jsonToMarkdown(value, depth + 1)}`)
      .join('\n');
  } else {
    return String(data);
  }
}

```

## services/converter/data/xlsxConverter.js

```js
// services/converter/data/xlsxConverter.js

import xlsx from 'xlsx';

/**
 * Converts an XLSX buffer or string to Markdown format.
 * @param {Buffer|string} input - The XLSX content as a buffer or string (file path not used).
 * @param {string} originalName - Original filename for context.
 * @param {string} [apiKey] - API key if needed.
 * @returns {Promise<{ content: string, images: Array }>} - Converted content and images.
 */
export async function convertXlsxToMarkdown(input, originalName, apiKey) {
  try {
    let workbook;
    if (Buffer.isBuffer(input)) {
      workbook = xlsx.read(input, { type: 'buffer' });
    } else {
      // If input is a string, assume it's a buffer represented as a string (unlikely)
      throw new Error('Invalid input type for XLSX converter. Expected a Buffer.');
    }

    // Convert each sheet to Markdown
    const markdownSheets = workbook.SheetNames.map(sheetName => {
      const sheet = workbook.Sheets[sheetName];
      const jsonData = xlsx.utils.sheet_to_json(sheet, { header: 1 });
      
      if (jsonData.length === 0) {
        return `## ${sheetName}\n\nThis sheet is empty.`;
      }

      const headers = jsonData[0];
      let markdownTable = `## ${sheetName}\n\n`;
      markdownTable += `| ${headers.join(' | ')} |\n`;
      markdownTable += `| ${headers.map(() => '---').join(' | ')} |\n`;

      jsonData.slice(1).forEach(row => {
        markdownTable += `| ${row.map(cell => cell !== null && cell !== undefined ? cell : '').join(' | ')} |\n`;
      });

      return markdownTable;
    });

    // Combine all sheets
    const combinedMarkdown = markdownSheets.join('\n\n');
    
    return { content: combinedMarkdown, images: [] };
  } catch (error) {
    console.error('Error converting XLSX to Markdown:', error);
    throw error;
  }
}

```

## services/converter/data/yamlConverter.js

```js
// services/converter/data/yamlConverter.js

import yaml from 'js-yaml';

/**
 * Converts a YAML buffer or string to Markdown format.
 * @param {Buffer|string} input - The YAML content as a buffer or string.
 * @param {string} originalName - Original filename for context.
 * @param {string} [apiKey] - API key if needed.
 * @returns {Promise<{ content: string, images: Array }>} - Converted content and images.
 */
export async function convertYamlToMarkdown(input, originalName, apiKey) {
  try {
    // Convert buffer to string if necessary
    const yamlContent = Buffer.isBuffer(input) ? input.toString('utf-8') : input;

    // Parse the YAML data
    const yamlData = yaml.load(yamlContent);

    // Reuse the JSON to Markdown conversion logic
    const markdownContent = jsonToMarkdown(yamlData);

    return { content: markdownContent, images: [] };
  } catch (error) {
    console.error('Error converting YAML to Markdown:', error);
    throw error;
  }
}

/**
 * Recursively converts JSON/YAML data to Markdown format.
 * @param {any} data - The data to convert.
 * @param {number} depth - The current depth for nested structures.
 * @returns {string} - The converted Markdown string.
 */
function jsonToMarkdown(data, depth = 0) {
  const indent = '  '.repeat(depth);

  if (Array.isArray(data)) {
    return data.map(item => `${indent}- ${jsonToMarkdown(item, depth + 1)}`).join('\n');
  } else if (typeof data === 'object' && data !== null) {
    return Object.entries(data)
      .map(([key, value]) => `${indent}- **${key}**: ${jsonToMarkdown(value, depth + 1)}`)
      .join('\n');
  } else {
    return String(data);
  }
}

```

## services/converter/multimedia/audioconverter.js

```js
// audioConverter.js
import fs from 'fs/promises';
import { openaiProxy } from '../../openaiProxy.js';
import { generateMarkdown } from './markdownGenerator.js';

const MAX_FILE_SIZE = 25 * 1024 * 1024; // 25 MB (OpenAI's current limit)

export async function convertAudioToMarkdown(filePath, apiKey) {
  try {
    // Check file size
    const stats = await fs.stat(filePath);
    if (stats.size > MAX_FILE_SIZE) {
      throw new Error(`File size exceeds the maximum limit of ${MAX_FILE_SIZE / (1024 * 1024)} MB`);
    }

    // Read file
    const fileBuffer = await fs.readFile(filePath);

    // Prepare form data for OpenAI API
    const formData = new FormData();
    formData.append('file', new Blob([fileBuffer]), 'audio.mp3');
    formData.append('model', 'whisper-1');

    // Call OpenAI Whisper API via proxy
    const transcriptionResponse = await openaiProxy.makeRequest(
      apiKey,
      'audio/transcriptions',
      formData
    );

    if (!transcriptionResponse || !transcriptionResponse.text) {
      throw new Error('Failed to transcribe audio');
    }

    // Generate Markdown
    const markdown = generateMarkdown({
      title: 'Audio Transcription',
      content: transcriptionResponse.text
    });

    return markdown;
  } catch (error) {
    console.error('Error in audio conversion:', error);
    throw error;
  }
}

// Helper function to format timestamps (if provided by the API)
function formatTimestamp(seconds) {
  const minutes = Math.floor(seconds / 60);
  const remainingSeconds = Math.floor(seconds % 60);
  return `${minutes.toString().padStart(2, '0')}:${remainingSeconds.toString().padStart(2, '0')}`;
}
```

## services/converter/multimedia/videoConverter.js

```js
// services/converter/multimedia/videoConverter.js

import { transcriber } from '../transcriber.js';
import { generateMarkdown } from '../../utils/markdownGenerator.js';

export async function convertVideoToMarkdown(filePath, apiKey) {
  try {
    // Transcribe video to text
    const transcription = await transcriber.transcribe(filePath, apiKey);

    // Generate Markdown
    const markdown = generateMarkdown({
      title: `Video Transcription: ${path.basename(filePath)}`,
      content: transcription,
    });

    return markdown;
  } catch (error) {
    console.error('Error converting video to Markdown:', error);
    throw error;
  }
}

```

## services/converter/text/docxConverter.js

```js
// services/converter/text/docxConverter.js

import mammoth from 'mammoth';
import path from 'path';
import { v4 as uuidv4 } from 'uuid';

/**
 * Converts a DOCX buffer to Markdown format while properly handling images
 * @param {Buffer} buffer - The DOCX file buffer
 * @param {string} originalName - Original filename for context
 * @returns {Promise<{content: string, images: Array}>} Markdown content and images
 */
export async function convertDocxToMarkdown(buffer, originalName) {
  try {
    console.log('Starting DOCX conversion:', originalName);
    
    // Store extracted images
    const images = [];
    
    // Get base name for folder structure
    const baseName = path.basename(originalName, '.docx');
    
    // Configure conversion options
    const options = {
      convertImage: mammoth.images.imgElement(async (image) => {
        try {
          // Get image buffer and info
          const imageBuffer = await image.read();
          const extension = image.contentType.split('/')[1];
          const imageName = `${baseName}-${uuidv4().slice(0, 8)}.${extension}`;
          
          // Store image info and data
          images.push({
            name: imageName,
            data: imageBuffer.toString('base64'),
            type: image.contentType,
            path: `attachments/${baseName}/${imageName}`
          });
          
          // Return markdown image reference
          return {
            src: `attachments/${baseName}/${imageName}`
          };
        } catch (error) {
          console.error('Error processing image:', error);
          return { src: 'error-processing-image' };
        }
      })
    };

    // Correctly pass the buffer directly
    const result = await mammoth.convertToMarkdown(buffer, options);

    // Log any warnings
    if (result.messages.length > 0) {
      console.log('Conversion warnings:', result.messages);
    }

    // Create the frontmatter and content
    const markdown = [
      '---',
      `title: ${baseName}`,
      `attachmentFolder: attachments/${baseName}`,
      'created: ' + new Date().toISOString(),
      '---',
      '',
      result.value
    ].join('\n');

    // Return both markdown and images with proper paths
    return {
      content: markdown,
      images: images
    };

  } catch (error) {
    console.error('Error converting DOCX:', error);
    throw error;
  }
}

```

## services/converter/text/epubConverter.js

```js
// services/converter/text/epubConverter.js

import EPub from 'epub';
import TurndownService from 'turndown';
import { promisify } from 'util';
import tmp from 'tmp-promise';
import fs from 'fs/promises';
import path from 'path';

/**
 * Converts an EPUB buffer to Markdown format, extracting text and images.
 * @param {Buffer} input - The EPUB file buffer.
 * @param {string} originalName - Original filename for context.
 * @param {string} [apiKey] - API key if needed.
 * @returns {Promise<{ content: string, images: Array }>} - Converted content and images.
 */
export async function convertEpubToMarkdown(input, originalName, apiKey) {
  let tempFile;
  try {
    // Create a temporary file to store the EPUB buffer
    tempFile = await tmp.file({ postfix: '.epub' });
    const tempFilePath = tempFile.path;

    // Write buffer to the temporary file
    await fs.writeFile(tempFilePath, input);

    // Initialize EPub with the temporary file path
    const epub = new EPub(tempFilePath);
    const openEpub = promisify(epub.open.bind(epub));
    const getChapter = promisify(epub.getChapter.bind(epub));
    const getImage = promisify(epub.getImage.bind(epub));

    await openEpub();

    const turndownService = new TurndownService({
      headingStyle: 'atx',
      codeBlockStyle: 'fenced'
    });

    // Metadata
    let markdown = `# ${epub.metadata.title || 'Untitled EPUB'}\n\n`;
    markdown += `**Author:** ${epub.metadata.creator || 'Unknown'}\n\n`;
    if (epub.metadata.description) {
      markdown += `**Description:** ${epub.metadata.description}\n\n`;
    }
    markdown += `**Publication Date:** ${epub.metadata.date || 'Unknown'}\n\n`;

    // Table of Contents
    markdown += `## Table of Contents\n\n`;
    epub.flow.forEach((chapter, index) => {
      markdown += `${index + 1}. [${chapter.title}](#chapter-${index + 1})\n`;
    });
    markdown += '\n';

    // Process chapters
    const baseName = path.basename(originalName || 'untitled', path.extname(originalName || ''));
    const images = [];

    for (let i = 0; i < epub.flow.length; i++) {
      const chapter = epub.flow[i];
      const chapterContent = await getChapter(chapter.id);
      markdown += `## Chapter ${i + 1}: ${chapter.title}\n\n`;

      // Convert HTML to Markdown
      const markdownContent = turndownService.turndown(chapterContent);
      markdown += markdownContent + '\n\n';
    }

    // Extract images from the EPUB manifest
    const imagePromises = Object.values(epub.manifest)
      .filter(item => item.mediaType.startsWith('image/'))
      .map(async (item) => {
        const imageBuffer = await getImage(item.id);
        const imageName = path.basename(item.href);
        const imageData = imageBuffer.toString('base64');
        const imageType = item.mediaType;

        images.push({
          name: imageName,
          data: imageData,
          type: imageType,
          path: `attachments/${baseName}/${imageName}`
        });

        return {
          originalPath: item.href,
          newPath: `attachments/${baseName}/${imageName}`
        };
      });

    const imageMappings = await Promise.all(imagePromises);

    // Replace image sources in markdown with the new attachment paths
    imageMappings.forEach(mapping => {
      const originalHref = mapping.originalPath;
      const newPath = mapping.newPath;

      // EPUB image hrefs may have internal references, e.g., "../Images/image1.png"
      // Normalize the originalHref by removing directory paths
      const normalizedHref = path.basename(originalHref);

      // Replace all occurrences of the original image path with the new path
      const regex = new RegExp(`\\(.*${normalizedHref}\\)`, 'g');
      markdown = markdown.replace(regex, `(${newPath})`);
    });

    return {
      content: markdown,
      images: images
    };
  } catch (error) {
    console.error('Error converting EPUB to Markdown:', error);
    throw error;
  } finally {
    // Clean up the temporary file
    if (tempFile) {
      await tempFile.cleanup();
    }
  }
}

```

## services/converter/text/odtConverter.js

```js
// services/converter/text/odtConverter.js

import JSZip from 'jszip';
import xml2js from 'xml2js';
import TurndownService from 'turndown';
import path from 'path';

/**
 * Converts an ODT buffer to Markdown format, extracting text and images.
 * @param {Buffer} input - The ODT file buffer.
 * @param {string} originalName - Original filename for context.
 * @param {string} [apiKey] - API key if needed.
 * @returns {Promise<{ content: string, images: Array }>} - Converted content and images.
 */
export async function convertOdtToMarkdown(input, originalName, apiKey) {
  try {
    const zip = await JSZip.loadAsync(input);

    // Extract content.xml
    const contentXml = await zip.file('content.xml').async('string');

    // Extract images from 'Pictures/' folder
    const imagesFolder = zip.folder('Pictures');
    const images = [];

    if (imagesFolder) {
      const imageFiles = Object.keys(imagesFolder.files);
      for (const imageFileName of imageFiles) {
        const file = imagesFolder.file(imageFileName);
        if (file) {
          const imageBuffer = await file.async('base64');
          const imageType = file.name.split('.').pop().toLowerCase();
          images.push({
            name: file.name,
            data: imageBuffer,
            type: `image/${imageType}`,
            path: `attachments/${path.basename(originalName, path.extname(originalName))}/${file.name}`
          });
        }
      }
    }

    // Parse content.xml
    const parser = new xml2js.Parser();
    const parsedXml = await parser.parseStringPromise(contentXml);

    // Extract text and image references
    const body = parsedXml['office:document-content']['office:body'][0]['office:text'][0];
    const textContent = extractTextFromODT(parsedXml);

    // Initialize TurndownService for markdown conversion
    const turndownService = new TurndownService({
      headingStyle: 'atx',
      codeBlockStyle: 'fenced'
    });

    // Convert HTML to Markdown
    const markdownContent = turndownService.turndown(textContent);

    // Build markdown with metadata and table of contents
    let markdown = `# ${path.basename(originalName, path.extname(originalName))}\n\n`;
    markdown += `**Author:** ${parsedXml['office:document-content']['office:meta'][0]['dc:creator'] ? parsedXml['office:document-content']['office:meta'][0]['dc:creator'][0] : 'Unknown'}\n\n`;
    markdown += `**Description:** ${parsedXml['office:document-content']['office:meta'][0]['dc:description'] ? parsedXml['office:document-content']['office:meta'][0]['dc:description'][0] : 'N/A'}\n\n`;
    markdown += `**Publication Date:** ${parsedXml['office:document-content']['office:meta'][0]['meta:creation-date'] ? parsedXml['office:document-content']['office:meta'][0]['meta:creation-date'][0] : 'Unknown'}\n\n`;

    // Table of Contents - optional, based on headings
    markdown += `## Table of Contents\n\n`;
    // Optionally parse headings from markdownContent
    const headings = markdownContent.match(/^#{1,6}\s.+$/gm);
    if (headings) {
      headings.forEach((heading, index) => {
        const title = heading.replace(/^#+\s/, '').trim();
        const slug = title.toLowerCase().replace(/[^\w]+/g, '-');
        markdown += `${index + 1}. [${title}](#${slug})\n`;
      });
    }
    markdown += '\n';

    // Append content
    markdown += markdownContent + '\n\n';

    return {
      content: markdown,
      images: images
    };
  } catch (error) {
    console.error('Error converting ODT to Markdown:', error);
    throw error;
  }
}

/**
 * Extracts text from parsed ODT XML.
 * @param {Object} parsedXml - Parsed XML object.
 * @returns {string} - Extracted text as HTML.
 */
function extractTextFromODT(parsedXml) {
  const body = parsedXml['office:document-content']['office:body'][0]['office:text'][0];
  let html = '';

  function traverse(element) {
    if (typeof element === 'string') {
      html += element;
    } else if (Array.isArray(element)) {
      element.forEach(traverse);
    } else if (typeof element === 'object') {
      for (const key in element) {
        const items = element[key];
        items.forEach(item => {
          switch (key) {
            case 'text:p':
              html += `<p>${processParagraph(item)}</p>`;
              break;
            case 'text:h':
              const level = parseInt(item.$['text:outline-level'], 10) || 1;
              html += `<h${level}>${processParagraph(item)}</h${level}>\n`;
              break;
            case 'draw:frame':
              // Handle images
              const imageHref = item['draw:image'][0].$['xlink:href']; // Corrected Syntax
              if (imageHref) {
                const href = imageHref.replace('#', '');
                html += `<img src="${href}" alt="Image"/>`;
              }
              break;
            default:
              traverse(item);
          }
        });
      }
    }
  }

  function processParagraph(paragraph) {
    let text = '';
    if (paragraph['text:span']) {
      paragraph['text:span'].forEach(span => {
        if (span['text:a']) {
          // Handle links
          const href = span['text:a'][0].$['xlink:href'] || '#'; // Corrected Syntax
          const spanText = span['_'] || '';
          text += `[${spanText}](${href})`;
        } else {
          text += span['_'] || '';
        }
      });
    }
    return text;
  }

  traverse(body);
  return html;
}

```

## services/converter/text/pdfConverter.js

```js
// services/converter/text/pdfConverter.js


import { fileURLToPath } from 'url';
import { dirname } from 'path';
import path from 'path';
import crypto from 'crypto';
import * as fs from 'fs/promises';
import { promisify } from 'util';
import { exec } from 'child_process';
import { v4 as uuidv4 } from 'uuid';
import pdfParse from 'pdf-parse';

const execAsync = promisify(exec);
const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

/**
 * Checks if a file exists
 * @param {string} path - Path to check
 * @returns {Promise<boolean>} True if file exists
 */
async function fileExists(path) {
  try {
    await fs.access(path);
    return true;
  } catch {
    return false;
  }
}

/**
 * Gets the poppler binary path based on the operating system
 * @returns {Promise<string>} Path to poppler binaries
 */
async function getPopplerPath() {
  if (process.platform === 'win32') {
    // Check common installation paths
    const possiblePaths = [
      'C:\\Program Files\\poppler\\Library\\bin',
      'C:\\Program Files\\poppler-23.11.0\\Library\\bin',
      'C:\\Program Files (x86)\\poppler\\Library\\bin',
      'C:\\poppler\\Library\\bin',
      process.env.POPPLER_PATH
    ].filter(Boolean);

    for (const binPath of possiblePaths) {
      if (!binPath) continue;
      
      const pdfimagesPath = path.join(binPath, 'pdfimages.exe');
      console.log('Checking poppler path:', pdfimagesPath);
      
      try {
        const exists = await fileExists(pdfimagesPath);
        if (exists) {
          console.log('Found poppler at:', binPath);
          return binPath;
        }
      } catch (error) {
        console.warn(`Failed to check path ${binPath}:`, error);
      }
    }
    
    throw new Error('Poppler not found. Please install poppler-utils and set POPPLER_PATH environment variable.');
  }
  
  return ''; // Unix systems typically have it in PATH
}

/**
 * Executes poppler command with proper path handling
 * @param {string} command - The command to execute
 * @returns {Promise<string>} Command output
 */
async function executePopplerCommand(command) {
  try {
    if (process.platform === 'win32') {
      const popplerPath = await getPopplerPath();
      // Add poppler path to command
      if (command.startsWith('pdfimages')) {
        command = command.replace('pdfimages', `"${path.join(popplerPath, 'pdfimages.exe')}"`);
      }
    }

    console.log('Executing command:', command);
    const { stdout, stderr } = await execAsync(command);
    
    if (stderr) {
      console.warn('Command stderr:', stderr);
    }
    
    return stdout;
  } catch (error) {
    console.error('Poppler command failed:', error);
    throw error;
  }
}

/**
 * Extracts images from PDF using poppler-utils with fallback
 * @param {string} pdfPath - Path to the PDF file
 * @param {string} originalName - Original filename
 * @returns {Promise<Array>} Array of image objects
 */
async function extractImages(pdfPath, originalName) {
  const tempDir = path.join(process.cwd(), 'temp', uuidv4());
  const imageRoot = path.join(tempDir, 'image');
  const images = [];
  const imageHashes = new Map();

  try {
    await fs.mkdir(tempDir, { recursive: true });

    try {
      // Use pdfimages for extraction
      const command = `pdfimages -all "${pdfPath}" "${imageRoot}"`;
      await executePopplerCommand(command);

      // Process extracted images
      const files = await fs.readdir(tempDir);
      const imageFiles = files.filter(f => /\.(jpg|jpeg|png|ppm|pbm)$/i.test(f));

      for (const imageFile of imageFiles) {
        const imagePath = path.join(tempDir, imageFile);
        const stats = await fs.stat(imagePath);

        // Skip tiny images (likely artifacts)
        if (stats.size < 5120) continue;

        // Calculate image hash
        const imageBuffer = await fs.readFile(imagePath);
        const hash = crypto.createHash('sha256').update(imageBuffer).digest('hex');

        // Check for duplicates
        if (imageHashes.has(hash)) continue;
        imageHashes.set(hash, true);

        const ext = path.extname(imageFile).slice(1);
        const baseName = path.basename(originalName, '.pdf');
        const newImageName = `${baseName}-image-${images.length + 1}.${ext}`;

        images.push({
          name: newImageName,
          data: imageBuffer.toString('base64'),
          type: `image/${ext}`,
          path: `attachments/${baseName}/${newImageName}`,
          hash: hash,
          size: stats.size
        });
      }

    } catch (error) {
      console.warn('Poppler extraction failed:', error);
      console.log('Attempting fallback image extraction...');
      return await extractImagesWithFallback(pdfPath, originalName);
    }

    return images;

  } catch (error) {
    console.error('Image extraction error:', error);
    return [];
  } finally {
    // Cleanup
    try {
      await fs.rm(tempDir, { recursive: true, force: true });
    } catch (error) {
      console.warn('Failed to cleanup temp directory:', error);
    }
  }
}

/**
 * Fallback image extraction using pdf-lib
 * @param {string} pdfPath - Path to the PDF file
 * @param {string} originalName - Original filename
 * @returns {Promise<Array>} Array of image objects
 */
async function extractImagesWithFallback(pdfPath, originalName) {
  try {
    const { PDFDocument } = await import('pdf-lib');
    const pdfBytes = await fs.readFile(pdfPath);
    const pdfDoc = await PDFDocument.load(pdfBytes);
    const images = [];
    const imageHashes = new Map();

    for (let i = 0; i < pdfDoc.getPageCount(); i++) {
      const page = pdfDoc.getPage(i);
      
      // Get page resources
      if (!page || !page.node) continue;
      
      const resources = page.node.Resources;
      if (!resources) continue;
      
      const xObjects = resources.lookup('XObject');
      if (!xObjects) continue;

      // Get all XObject names
      const xObjectKeys = xObjects.keys();

      for (const key of xObjectKeys) {
        const xObject = xObjects.lookup(key);
        
        // Check if it's an image
        if (!xObject || xObject.Subtype?.name !== 'Image') continue;

        try {
          const imageData = await xObject.getContents();
          if (!imageData || imageData.length < 5120) continue;

          const hash = crypto.createHash('sha256').update(imageData).digest('hex');
          if (imageHashes.has(hash)) continue;
          
          imageHashes.set(hash, true);

          // Determine format based on filter
          const filter = xObject.Filter?.name;
          const format = filter === 'DCTDecode' ? 'jpeg' : 'png';

          const baseName = path.basename(originalName, '.pdf');
          const imageName = `${baseName}-image-${i + 1}-${images.length + 1}.${format}`;

          images.push({
            name: imageName,
            data: imageData.toString('base64'),
            type: `image/${format}`,
            path: `attachments/${baseName}/${imageName}`,
            hash: hash,
            size: imageData.length,
            pageIndex: i
          });
        } catch (imageError) {
          console.warn(`Failed to extract image from page ${i}:`, imageError);
          continue;
        }
      }
    }

    return images;
  } catch (error) {
    console.error('Fallback image extraction failed:', error);
    return [];
  }
}

/**
 * Validates PDF input buffer
 * @param {Buffer} input - The input buffer to validate
 * @returns {boolean} True if input is a valid PDF
 */
export function validatePdfInput(input) {
  if (!input || !Buffer.isBuffer(input)) return false;
  
  // Check PDF magic number
  const header = input.slice(0, 5).toString();
  if (header !== '%PDF-') return false;

  // Check for EOF marker
  const trailer = input.slice(-6).toString();
  return trailer.includes('%%EOF');
}

/**
 * Converter configuration object
 */
export const pdfConverterConfig = {
  name: 'PDF Converter',
  version: '1.0.0',
  supportedExtensions: ['.pdf'],
  supportedMimeTypes: ['application/pdf'],
  maxSizeBytes: 100 * 1024 * 1024, // 100MB
  requiresPoppler: true,
  options: {
    imageQuality: 300,
    minImageSize: 5120, // 5KB
    debug: false,
    popplerPath: process.env.POPPLER_PATH
  }
};

/**
 * Main converter function that transforms PDF to Markdown with images
 * @param {Buffer} input - The PDF file buffer
 * @param {string} originalName - Original filename for context
 * @param {string} [apiKey] - Optional API key (not used for PDF conversion)
 * @returns {Promise<{content: string, images: Array}>} - Converted content and images
 */
export async function convertPdfToMarkdown(input, originalName, apiKey) {
  if (!validatePdfInput(input)) {
    throw new Error('Invalid PDF input');
  }

  const tempDir = path.join(process.cwd(), 'temp', uuidv4());
  const tempPdfPath = path.join(tempDir, 'input.pdf');
  
  try {
    await fs.mkdir(tempDir, { recursive: true });
    await fs.writeFile(tempPdfPath, input);
    
    // Extract text
    const pdfData = await pdfParse(input);
    
    // Extract images
    const images = await extractImages(tempPdfPath, originalName);
    
    // Generate markdown content
    const baseName = path.basename(originalName, '.pdf');
    
    // Create frontmatter
    const frontmatter = [
      '---',
      `title: ${baseName}`,
      `created: ${new Date().toISOString()}`,
      `source: ${originalName}`,
      `type: pdf`,
      `pages: ${pdfData.numpages}`,
      `image_count: ${images.length}`,
      '---',
      ''
    ].join('\n');

    // Process text content
    let textContent = pdfData.text
      .replace(/\f/g, '\n\n---\n\n')
      .replace(/(\r\n|\r|\n){3,}/g, '\n\n')
      .replace(/[^\S\r\n]+/g, ' ')
      .trim();

    // Add image references
    let imageSection = '';
    if (images.length > 0) {
      imageSection = '\n\n## Extracted Images\n\n' +
        images.map(img => 
          `![${img.name}](${img.path})`
        ).join('\n\n');
    }

    const markdownContent = [
      frontmatter,
      '## Content\n',
      textContent,
      imageSection
    ].join('\n');

    return {
      content: markdownContent,
      images: images
    };

  } catch (error) {
    console.error('Error converting PDF:', error);
    throw error;
  } finally {
    // Cleanup
    try {
      await fs.rm(tempDir, { recursive: true, force: true });
    } catch (error) {
      console.warn('Failed to cleanup temp directory:', error);
    }
  }
}

export default {
  convert: convertPdfToMarkdown,
  validate: validatePdfInput,
  config: pdfConverterConfig
};
```

## services/converter/text/pptxConverter.js

```js
// services/converter/text/pptxConverter.js

import JSZip from 'jszip';
import TurndownService from 'turndown';
import path from 'path';

/**
 * Converts a PPTX buffer to Markdown format, extracting text and images.
 * @param {Buffer} input - The PPTX file buffer.
 * @param {string} originalName - Original filename for context.
 * @param {string} [apiKey] - API key if needed.
 * @returns {Promise<{ content: string, images: Array }>} - Converted content and images.
 * @throws {Error} - If conversion fails.
 */
export async function convertPptxToMarkdown(input, originalName, apiKey) {
  try {
    const zip = await JSZip.loadAsync(input);
    const slides = [];

    // Extract all slide XML files
    const slideFiles = Object.keys(zip.files).filter(fileName => /^ppt\/slides\/slide\d+\.xml$/.test(fileName));

    // Extract images from 'ppt/media/' folder
    const mediaFolder = zip.folder('ppt/media');
    const images = [];

    if (mediaFolder) {
      const imageFiles = Object.keys(mediaFolder.files);
      for (const imageFileName of imageFiles) {
        const file = mediaFolder.file(imageFileName);
        if (file) {
          const imageBuffer = await file.async('base64');
          const imageType = imageFileName.split('.').pop().toLowerCase();
          images.push({
            name: file.name,
            data: imageBuffer,
            type: `image/${imageType}`,
            path: `attachments/${path.basename(originalName, path.extname(originalName))}/${file.name}`
          });
        }
      }
    }

    const turndownService = new TurndownService({
      headingStyle: 'atx',
      codeBlockStyle: 'fenced'
    });

    let markdown = `# ${path.basename(originalName, path.extname(originalName))}\n\n`;
    markdown += `**Converted on:** ${new Date().toISOString()}\n\n`;

    // Process each slide
    for (const slideFileName of slideFiles) {
      const slideXml = await zip.file(slideFileName).async('string');
      const slideContent = extractTextFromPPTX(slideXml);

      markdown += `## Slide ${extractSlideNumber(slideFileName)}\n\n`;
      markdown += turndownService.turndown(slideContent) + '\n\n';
    }

    // Append image references to markdown (optional)
    images.forEach((image, index) => {
      markdown += `![Image ${index + 1}](attachments/${path.basename(originalName, path.extname(originalName))}/${image.name})\n\n`;
    });

    return {
      content: markdown,
      images: images
    };
  } catch (error) {
    console.error('Error converting PPTX to Markdown:', error);
    throw error;
  }
}

/**
 * Extracts text content from PPTX slide XML.
 * @param {string} slideXml - The slide XML content.
 * @returns {string} - Extracted text as HTML.
 */
function extractTextFromPPTX(slideXml) {
  // Simple regex-based extraction of text within <a:t> tags
  const textMatches = slideXml.match(/<a:t>(.*?)<\/a:t>/g);
  const texts = textMatches ? textMatches.map(match => match.replace(/<\/?a:t>/g, '')) : [];
  return texts.join(' ');
}

/**
 * Extracts slide number from slide file name.
 * @param {string} slideFileName - The slide file name (e.g., ppt/slides/slide1.xml).
 * @returns {number} - The slide number.
 */
function extractSlideNumber(slideFileName) {
  const match = slideFileName.match(/slide(\d+)\.xml$/);
  return match ? parseInt(match[1], 10) : 0;
}

```

## services/converter/text/rtfConverter.js

```js
// services/converter/text/rtfConverter.js

import rtfModule from '@iarna/rtf-to-html'; // CommonJS module
import TurndownService from 'turndown';
import path from 'path';

/**
 * Converts an RTF buffer to Markdown format.
 * @param {Buffer} input - The RTF file buffer.
 * @param {string} originalName - Original filename for context.
 * @param {string} [apiKey] - API key if needed.
 * @returns {Promise<{ content: string, images: Array }>} - Converted content and images.
 * @throws Will throw an error if the conversion fails.
 */
export async function convertRtfToMarkdown(input, originalName, apiKey) {
  try {
    // Destructure the rtfToHTML function from the imported CommonJS module
    const { rtfToHTML } = rtfModule;

    // Convert RTF to HTML using the rtfToHTML function
    const html = await new Promise((resolve, reject) => {
      rtfToHTML(input, (err, htmlOutput) => {
        if (err) {
          reject(err);
        } else {
          resolve(htmlOutput);
        }
      });
    });

    // Initialize TurndownService for HTML to Markdown conversion
    const turndownService = new TurndownService();

    // Convert the HTML content to Markdown
    const markdown = turndownService.turndown(html);

    // Add some basic metadata
    const metadataMarkdown = `# ${path.basename(originalName, path.extname(originalName))}\n\n` +
                             `**Converted on:** ${new Date().toISOString()}\n\n`;

    return {
      content: metadataMarkdown + markdown,
      images: [] // No image extraction
    };
  } catch (error) {
    console.error('Error converting RTF to Markdown:', error);
    throw error;
  }
}

```

## services/converter/text/txtConverter.js

```js
// services/converter/text/txtConverter.js

import path from 'path';

/**
 * Converts a TXT buffer to Markdown format.
 * @param {Buffer} input - The TXT file buffer.
 * @param {string} originalName - Original filename for context.
 * @param {string} [apiKey] - API key if needed.
 * @returns {Promise<{ content: string, images: Array }>} - Converted content and images.
 * @throws Will throw an error if the conversion fails.
 */
export async function convertTxtToMarkdown(input, originalName, apiKey) {
  try {
    // Convert buffer to string
    const content = input.toString('utf-8');

    // Split content into lines
    const lines = content.split(/\r?\n/);

    // Process each line
    const markdownLines = lines.map(line => {
      // Escape Markdown syntax characters
      const escapedLine = line.replace(/([\\`*_{}[\]()#+\-.!])/g, '\\$1');
      
      // Ensure line breaks are preserved in Markdown
      return escapedLine + '  ';
    });

    // Join lines back together
    const markdownContent = markdownLines.join('\n');

    // Add some basic metadata
    const metadataMarkdown = `# ${path.basename(originalName, path.extname(originalName))}\n\n` +
                             `**Converted on:** ${new Date().toISOString()}\n\n`;

    return {
      content: metadataMarkdown + markdownContent,
      images: [] // No image extraction
    };
  } catch (error) {
    console.error('Error converting TXT to Markdown:', error);
    throw error;
  }
}

```

## services/converter/textConverterFactory.js

```js
// services/converter/textConverterFactory.js

import path from 'path';
// Import all your converters
import { convertTxtToMarkdown } from './text/txtConverter.js';
import { convertRtfToMarkdown } from './text/rtfConverter.js';
import { convertPdfToMarkdown } from './text/pdfConverter.js';
import { convertDocxToMarkdown } from './text/docxConverter.js';
import { convertOdtToMarkdown } from './text/odtConverter.js';
import { convertEpubToMarkdown } from './text/epubConverter.js';
import { convertPptxToMarkdown } from './text/pptxConverter.js';
import { convertCsvToMarkdown } from './data/csvConverter.js';
import { convertJsonToMarkdown } from './data/jsonConverter.js';
import { convertYamlToMarkdown } from './data/yamlConverter.js';
import { convertXlsxToMarkdown } from './data/xlsxConverter.js';
import { convertHtmlToMarkdown } from './web/htmlConverter.js';
import { convertXmlToMarkdown } from './web/xmlConverter.js';
import { convertUrlToMarkdown } from './web/urlConverter.js';
import { convertParentUrlToMarkdown } from './web/parentUrlConverter.js'; 
import { convertYoutubeToMarkdown } from './web/youtubeConverter.js';

/**
 * Factory class for managing different types of Markdown converters
 */
class TextConverterFactory {
  /**
   * Initialize the converter factory with supported file type mappings
   */
  constructor() {
    this.converters = {
      // Text converters
      txt: convertTxtToMarkdown,
      rtf: convertRtfToMarkdown,
      pdf: convertPdfToMarkdown,
      docx: convertDocxToMarkdown,
      odt: convertOdtToMarkdown,
      epub: convertEpubToMarkdown,
      pptx: convertPptxToMarkdown,

      // Data converters
      csv: convertCsvToMarkdown,
      json: convertJsonToMarkdown,
      yaml: convertYamlToMarkdown,
      yml: convertYamlToMarkdown,
      xlsx: convertXlsxToMarkdown,

      // Web converters
      html: convertHtmlToMarkdown,
      htm: convertHtmlToMarkdown,
      xml: convertXmlToMarkdown,
      url: convertUrlToMarkdown,
      parentUrl: convertParentUrlToMarkdown, // Register the new converter
      youtube: convertYoutubeToMarkdown,
    };

    // Map of expected input types for validation
    this.expectedInputTypes = {
      docx: ['buffer'],
      pdf: ['buffer'],
      txt: ['string', 'buffer'],
      rtf: ['buffer'],
      epub: ['buffer'],
      odt: ['buffer'],
      pptx: ['buffer'],
      html: ['string'],
      htm: ['string'],
      xml: ['string'],
      url: ['string'],
      parentUrl: ['string'],
      youtube: ['string'],
    };
  }

  /**
   * Validates input type against expected types for the format
   * @private
   * @param {string} type - The file type
   * @param {any} input - The input to validate
   * @throws {Error} If input type is invalid
   */
  validateInput(type, input) {
    const expectedTypes = this.expectedInputTypes[type.toLowerCase()] || ['buffer', 'string'];
    const inputType = typeof input;
    const isBuffer = Buffer.isBuffer(input);

    console.log('Validating input:', {
      fileType: type,
      inputType,
      isBuffer,
      expectedTypes,
      constructorName: input?.constructor?.name
    });

    if (!expectedTypes.includes('buffer') && isBuffer) {
      throw new Error(`${type} converter does not accept Buffer input`);
    }

    if (!expectedTypes.includes(inputType) && !isBuffer) {
      throw new Error(
        `Invalid input type for ${type}. Expected ${expectedTypes.join(' or ')}, got ${inputType}`
      );
    }
  }

  /**
   * Converts input content to Markdown format
   * @param {string} type - The type of content
   * @param {Buffer|string} input - The content to convert
   * @param {string} originalName - Original filename or identifier
   * @param {string} [apiKey] - API key for services that require authentication
   * @returns {Promise<{ content: string, images: Array }>} - Converted content and images
   */
  async convertToMarkdown(type, input, originalName, apiKey) {
    try {
      // Input validation
      if (!input) {
        throw new Error('No input provided');
      }

      if (!type) {
        throw new Error('No file type specified');
      }

      const normalizedType = type.toLowerCase();

      // Get the appropriate converter
      const converter = this.converters[normalizedType];
      if (!converter) {
        throw new Error(`Unsupported file type: ${type}`);
      }

      // Validate input type
      this.validateInput(normalizedType, input);

      // Log conversion attempt
      console.log('Attempting conversion:', {
        type: normalizedType,
        inputType: typeof input,
        isBuffer: Buffer.isBuffer(input),
        originalName
      });

      // Perform conversion
      // Pass originalName and apiKey to converter if needed
      const convertedResult = await converter(input, originalName, apiKey);

      // Verify conversion result
      if (!convertedResult || !convertedResult.content) {
        throw new Error('Converter returned empty content');
      }

      // Ensure images array exists
      if (!convertedResult.images) {
        convertedResult.images = [];
      }

      return convertedResult;
    } catch (error) {
      console.error('Conversion error:', {
        type,
        error: error.message,
        stack: error.stack
      });
      throw error;
    }
  }

  /**
   * Registers a new converter for a file type
   * @param {string} type - The file type
   * @param {Function} converterFunction - The converter function
   */
  addConverter(type, converterFunction) {
    if (typeof converterFunction !== 'function') {
      throw new Error('Converter must be a function');
    }
    this.converters[type.toLowerCase()] = converterFunction;
  }
}

// Export singleton instance
export const textConverterFactory = new TextConverterFactory();

```

## services/converter/web/htmlConverter.js

```js
// services/converter/web/htmlConverter.js

import TurndownService from 'turndown';
import * as cheerio from 'cheerio'; // Corrected import
import path from 'path';

/**
 * Converts an HTML string or buffer to Markdown format, extracting images.
 * @param {Buffer|string} input - The HTML content as a buffer or string.
 * @param {string} originalName - Original filename for context.
 * @param {string} [apiKey] - API key if needed.
 * @returns {Promise<{ content: string, images: Array }>} - Converted content and images.
 */
export async function convertHtmlToMarkdown(input, originalName, apiKey) {
  try {
    // Convert buffer to string if necessary
    const htmlContent = Buffer.isBuffer(input) ? input.toString('utf-8') : input;

    // Initialize TurndownService
    const turndownService = new TurndownService({
      headingStyle: 'atx',
      codeBlockStyle: 'fenced',
      emDelimiter: '_',
      strongDelimiter: '**'
    });

    // Add custom rules if needed
    turndownService.addRule('strikethrough', {
      filter: ['del', 's', 'strike'],
      replacement: function (content) {
        return '~~' + content + '~~';
      }
    });

    // Load HTML into Cheerio for parsing
    const $ = cheerio.load(htmlContent);

    // Extract images
    const images = [];
    $('img').each((index, img) => {
      const src = $(img).attr('src');
      const alt = $(img).attr('alt') || `Image ${index + 1}`;
      if (src) {
        // Handle base64 images or external URLs
        if (src.startsWith('data:')) {
          const matches = src.match(/^data:(image\/[a-zA-Z]+);base64,(.+)$/);
          if (matches) {
            const imageType = matches[1].split('/')[1];
            const imageData = matches[2];
            const imageName = `image-${index + 1}.${imageType}`;
            images.push({
              name: imageName,
              data: imageData,
              type: `image/${imageType}`,
              path: `attachments/${path.basename(originalName, path.extname(originalName))}/${imageName}`
            });

            // Replace src with new path
            $(img).attr(
              'src',
              `attachments/${path.basename(originalName, path.extname(originalName))}/${imageName}`
            );
          }
        } else {
          // For external URLs, you might want to download and include them
          // This implementation assumes images are to be handled externally
          images.push({
            name: path.basename(src),
            data: '', // Placeholder if you plan to download images
            type: '', // Placeholder for image type
            path: src // External path
          });
        }
      }
    });

    // Get modified HTML with updated image paths
    const modifiedHtml = $.html();

    // Convert HTML to Markdown
    let markdownContent = turndownService.turndown(modifiedHtml);

    // Add metadata
    const metadataMarkdown =
      `# ${path.basename(originalName, path.extname(originalName))}\n\n` +
      `**Converted on:** ${new Date().toISOString()}\n\n`;

    // Combine metadata and content
    const fullMarkdown = metadataMarkdown + markdownContent;

    return {
      content: fullMarkdown,
      images: images
    };
  } catch (error) {
    console.error('Error converting HTML to Markdown:', error);
    throw error;
  }
}

```

## services/converter/web/parentUrlConverter.js

```js
// services/converter/web/parentUrlConverter.js

import puppeteer from 'puppeteer';
import TurndownService from 'turndown';
import * as cheerio from 'cheerio';
import path from 'path';
import { convertUrlToMarkdown } from './urlConverter.js';

/**
 * Configuration object for puppeteer
 */
const PUPPETEER_CONFIG = {
  headless: true,
  args: [
    '--no-sandbox',
    '--disable-setuid-sandbox',
    '--disable-dev-shm-usage',
    '--disable-accelerated-2d-canvas',
    '--disable-gpu'
  ],
  defaultViewport: { width: 1920, height: 1080 }
};

/**
 * URL processing configuration
 */
const URL_CONFIG = {
  timeout: 30000,
  concurrentLimit: 5,
  validProtocols: ['http:', 'https:']
};

/**
 * Validates and normalizes a URL string
 * @param {string} url - The URL to validate
 * @returns {string} - Normalized URL
 * @throws {Error} - If URL is invalid
 */
function validateAndNormalizeUrl(url) {
  try {
    // Remove leading/trailing whitespace
    url = url.trim();
    
    // Add https:// if no protocol specified
    if (!/^https?:\/\//i.test(url)) {
      url = 'https://' + url.replace(/^\/\//, '');
    }
    
    const urlObj = new URL(url);
    if (!URL_CONFIG.validProtocols.includes(urlObj.protocol)) {
      throw new Error(`Invalid protocol: ${urlObj.protocol}`);
    }
    
    return urlObj.href;
  } catch (error) {
    throw new Error(`Invalid URL format: ${error.message}`);
  }
}

/**
 * Scrapes all child URLs under a given Parent URL
 * @param {string} parentUrl - The Parent URL to scrape
 * @returns {Promise<Set<string>>} - Set of unique child URLs
 */
async function scrapeChildUrls(parentUrl) {
  const browser = await puppeteer.launch(PUPPETEER_CONFIG);
  const processedUrls = new Set();
  const pendingUrls = new Set([parentUrl]);
  const links = new Set();

  try {
    const page = await browser.newPage();
    await page.setUserAgent('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36');

    while (pendingUrls.size > 0) {
      const currentUrl = pendingUrls.values().next().value;
      pendingUrls.delete(currentUrl);

      if (processedUrls.has(currentUrl)) {
        continue;
      }

      try {
        console.log(`Processing URL: ${currentUrl}`);
        await page.goto(currentUrl, { 
          waitUntil: 'networkidle2',
          timeout: URL_CONFIG.timeout
        });

        const content = await page.content();
        const $ = cheerio.load(content);
        const parentUrlObj = new URL(parentUrl);
        const currentUrlObj = new URL(currentUrl);

        $('a[href]').each((_, element) => {
          const href = $(element).attr('href');
          if (!href) return;

          try {
            let fullUrl = href.startsWith('http') ? href : new URL(href, currentUrl).href;
            const urlObj = new URL(fullUrl);

            // Only include URLs from the same domain
            if (urlObj.hostname === parentUrlObj.hostname) {
              const normalizedUrl = validateAndNormalizeUrl(fullUrl);
              links.add(normalizedUrl);
              
              // Add to pending if not processed
              if (!processedUrls.has(normalizedUrl)) {
                pendingUrls.add(normalizedUrl);
              }
            }
          } catch (error) {
            console.warn(`Invalid URL encountered: ${href}`, error);
          }
        });

        processedUrls.add(currentUrl);
      } catch (error) {
        console.error(`Error processing URL ${currentUrl}:`, error);
        // Continue with other URLs even if one fails
        processedUrls.add(currentUrl);
      }
    }

    console.log(`Found ${links.size} unique URLs under ${parentUrl}`);
    return links;

  } catch (error) {
    console.error(`Error in scrapeChildUrls for ${parentUrl}:`, error);
    throw error;
  } finally {
    await browser.close();
  }
}

/**
 * Processes URLs in chunks to prevent memory issues
 * @param {Array<string>} urls - Array of URLs to process
 * @param {number} chunkSize - Size of each chunk
 * @param {function} processor - Async function to process each URL
 * @returns {Promise<Array>} - Array of processed results
 */
async function processUrlsInChunks(urls, chunkSize, processor) {
  const results = [];
  const chunks = Array.from({ length: Math.ceil(urls.length / chunkSize) }, (_, i) =>
    urls.slice(i * chunkSize, (i + 1) * chunkSize)
  );

  for (const [index, chunk] of chunks.entries()) {
    console.log(`Processing chunk ${index + 1} of ${chunks.length}`);
    const chunkResults = await Promise.all(
      chunk.map(url => processor(url).catch(error => ({ error, url })))
    );
    results.push(...chunkResults);
  }

  return results;
}

/**
 * Converts a Parent URL to Markdown by scraping all child URLs
 * @param {string} parentUrl - The Parent URL to convert
 * @param {string} originalName - Original identifier for the Parent URL
 * @param {string} [apiKey] - API key for services that require authentication
 * @returns {Promise<{ content: string, images: Array }>} - Aggregated content and images
 */
export async function convertParentUrlToMarkdown(parentUrl, originalName, apiKey) {
  try {
    // Validate and normalize parent URL
    const normalizedParentUrl = validateAndNormalizeUrl(parentUrl);
    console.log(`Starting Parent URL conversion for: ${normalizedParentUrl}`);

    // Scrape child URLs
    const childUrls = await scrapeChildUrls(normalizedParentUrl);
    if (childUrls.size === 0) {
      throw new Error('No URLs found under the specified Parent URL');
    }

    // Initialize aggregated content
    let aggregatedContent = `# Website Conversion: ${normalizedParentUrl}\n\n`;
    aggregatedContent += `Converted on: ${new Date().toISOString()}\n\n`;
    const aggregatedImages = [];

    // Process URLs in chunks
    const results = await processUrlsInChunks(
      Array.from(childUrls),
      URL_CONFIG.concurrentLimit,
      async (url) => {
        try {
          const urlObj = new URL(url);
          const { content, images } = await convertUrlToMarkdown(
            { url, name: urlObj.pathname || urlObj.hostname },
            apiKey
          );
          return { success: true, url, content, images };
        } catch (error) {
          return { success: false, url, error: error.message };
        }
      }
    );

    // Aggregate results
    for (const result of results) {
      aggregatedContent += `\n\n## ${result.url}\n\n`;
      if (result.success) {
        aggregatedContent += result.content;
        if (result.images?.length > 0) {
          aggregatedImages.push(...result.images);
        }
      } else {
        aggregatedContent += `**Error:** ${result.error}\n\n`;
      }
    }

    // Add summary section
    const successCount = results.filter(r => r.success).length;
    aggregatedContent += `\n\n## Summary\n\n`;
    aggregatedContent += `- Total URLs processed: ${results.length}\n`;
    aggregatedContent += `- Successfully converted: ${successCount}\n`;
    aggregatedContent += `- Failed conversions: ${results.length - successCount}\n`;
    aggregatedContent += `- Total images extracted: ${aggregatedImages.length}\n`;

    console.log('Parent URL conversion completed successfully');

    return {
      content: aggregatedContent,
      images: aggregatedImages,
      stats: {
        totalUrls: results.length,
        successCount,
        failureCount: results.length - successCount,
        imageCount: aggregatedImages.length
      }
    };

  } catch (error) {
    console.error('Error converting Parent URL to Markdown:', error);
    throw error;
  }
}
```

## services/converter/web/urlConverter.js

```js
// services/converter/web/urlConverter.js

import puppeteer from 'puppeteer';
import TurndownService from 'turndown';
import * as cheerio from 'cheerio';
import path from 'path';

/**
 * Cleans up HTML content before conversion
 * @param {CheerioStatic} $ - Cheerio instance
 */
function cleanupContent($) {
  // Remove unwanted elements
  $('script').remove();
  $('style').remove();
  $('link').remove();
  $('meta').remove();
  $('noscript').remove();
  $('iframe').remove();
  $('.hidden').remove();
  $('[style*="display: none"]').remove();
  $('[style*="display:none"]').remove();
  $('[hidden]').remove();

  // Remove all CSS classes and IDs
  $('*').removeAttr('class').removeAttr('id');

  // Remove empty elements
  $('p:empty').remove();
  $('div:empty').remove();

  // Remove tracking and advertisement elements
  $('[data-ad]').remove();
  $('[id*="google"]').remove();
  $('[class*="advert"]').remove();
  $('[class*="tracking"]').remove();
  $('[aria-hidden="true"]').remove();
}

/**
 * Extracts main content from HTML
 * @param {CheerioStatic} $ - Cheerio instance
 * @returns {string} - Clean HTML content
 */
function extractMainContent($) {
  // Try to find main content container
  const possibleContentSelectors = [
    'main',
    'article',
    '[role="main"]',
    '.main-content',
    '.content',
    '#content',
    '.post-content',
    '.article-content'
  ];

  let mainContent = null;

  // Try each selector until we find content
  for (const selector of possibleContentSelectors) {
    const element = $(selector);
    if (element.length && element.text().trim().length > 100) {
      mainContent = element;
      break;
    }
  }

  // If no main content found, use body
  if (!mainContent) {
    mainContent = $('body');
  }

  return mainContent;
}

/**
 * Converts a URL to Markdown format
 * @param {string} url - The URL to convert
 * @param {string} originalName - Original identifier
 * @returns {Promise<{ content: string, images: Array }>}
 */
export async function convertUrlToMarkdown(url, originalName) {
  let browser;
  try {
    console.log(`Starting conversion for URL: ${url}`);

    browser = await puppeteer.launch({ 
      headless: true,
      args: ['--no-sandbox', '--disable-setuid-sandbox']
    });
    console.log('Puppeteer launched successfully');

    const page = await browser.newPage();
    await page.goto(url, { 
      waitUntil: 'networkidle2',
      timeout: 30000
    });
    console.log(`Navigated to URL: ${url}`);

    const content = await page.content();
    console.log('Page content retrieved');

    const $ = cheerio.load(content);
    cleanupContent($);
    console.log('Content cleaned up');

    const mainContent = extractMainContent($);
    if (!mainContent || mainContent.text().trim().length === 0) {
      throw new Error('Main content extraction failed or resulted in empty content');
    }
    console.log('Main content extracted successfully');

    // Process images
    const images = [];
    mainContent.find('img').each((index, img) => {
      const src = $(img).attr('src');
      const alt = $(img).attr('alt') || `Image ${index + 1}`;
      
      if (src) {
        if (src.startsWith('data:')) {
          // Handle Base64 images
          const matches = src.match(/^data:(image\/[a-zA-Z]+);base64,(.+)$/);
          if (matches) {
            const imageType = matches[1].split('/')[1];
            const imageData = matches[2];
            const imageName = `image-${index + 1}.${imageType}`;
            
            images.push({
              name: imageName,
              data: imageData,
              type: `image/${imageType}`,
              path: `attachments/${path.basename(originalName, path.extname(originalName))}/${imageName}`
            });

            // Update image source in content
            $(img).attr('src', `attachments/${path.basename(originalName, path.extname(originalName))}/${imageName}`);
          }
        } else {
          // Handle external images
          console.warn(`External image found but not handled: ${src}`);
          // Optionally, implement downloading external images here
        }
      }
    });
    console.log(`Processed ${images.length} images`);

    // Configure Turndown
    const turndownService = new TurndownService({
      headingStyle: 'atx',
      codeBlockStyle: 'fenced',
      emDelimiter: '_',
      strongDelimiter: '**',
      bulletListMarker: '-'
    });

    // Add custom rules
    turndownService.addRule('strikethrough', {
      filter: ['del', 's', 'strike'],
      replacement: content => `~~${content}~~`
    });

    // Convert to Markdown
    let markdown = turndownService.turndown(mainContent.html());
    console.log('Content converted to Markdown');

    // Add metadata
    const metadataMarkdown = [
      `# ${$('title').text() || new URL(url).hostname}`,
      '',
      $('meta[name="description"]').attr('content') ? `> ${$('meta[name="description"]').attr('content')}` : '',
      '',
      `**Source:** [${url}](${url})`,
      '',
      '---',
      ''
    ].filter(Boolean).join('\n');

    markdown = metadataMarkdown + markdown;
    console.log('Metadata added to Markdown content');

    return {
      content: markdown,
      images: images
    };

  } catch (error) {
    console.error('Error converting URL to Markdown:', error);
    throw error;
  } finally {
    if (browser) {
      await browser.close();
      console.log('Puppeteer browser closed');
    }
  }
}

```

## services/converter/web/xmlConverter.js

```js
// services/converter/web/xmlConverter.js

import xml2js from 'xml2js';
import TurndownService from 'turndown';
import path from 'path';

/**
 * Converts an XML string or buffer to Markdown format.
 * @param {Buffer|string} input - The XML content as a buffer or string.
 * @param {string} originalName - Original filename for context.
 * @param {string} [apiKey] - API key if needed.
 * @returns {Promise<{ content: string, images: Array }>} - Converted content and images.
 */
export async function convertXmlToMarkdown(input, originalName, apiKey) {
  try {
    // Convert buffer to string if necessary
    const xmlContent = Buffer.isBuffer(input) ? input.toString('utf-8') : input;

    // Parse XML
    const parser = new xml2js.Parser({ explicitArray: false });
    const parsedXml = await parser.parseStringPromise(xmlContent);

    // Convert parsed XML to HTML or directly to Markdown
    const htmlContent = xmlToHtml(parsedXml);

    // Initialize TurndownService
    const turndownService = new TurndownService({
      headingStyle: 'atx',
      codeBlockStyle: 'fenced',
      emDelimiter: '_',
      strongDelimiter: '**'
    });

    // Add custom rules if needed
    turndownService.addRule('strikethrough', {
      filter: ['del', 's', 'strike'],
      replacement: function(content) {
        return '~~' + content + '~~';
      }
    });

    // Extract images if the XML contains image references
    // This implementation assumes that images are referenced in a specific way
    // Adjust the selector based on your XML structure
    const images = [];
    // Example: If XML has <image src="data:image/png;base64,..." alt="Description" />
    // Adjust according to actual XML structure

    // For demonstration, let's assume images are in a specific tag
    // You need to modify this based on your XML schema
    if (parsedXml.images && Array.isArray(parsedXml.images.image)) {
      parsedXml.images.image.forEach((img, index) => {
        const src = img.$.src;
        const alt = img.$.alt || `Image ${index + 1}`;
        if (src) {
          if (src.startsWith('data:')) {
            const matches = src.match(/^data:(image\/[a-zA-Z]+);base64,(.+)$/);
            if (matches) {
              const imageType = matches[1].split('/')[1];
              const imageData = matches[2];
              const imageName = `image-${index + 1}.${imageType}`;
              images.push({
                name: imageName,
                data: imageData,
                type: `image/${imageType}`,
                path: `attachments/${path.basename(originalName, path.extname(originalName))}/${imageName}`
              });

              // Replace src with new path in htmlContent
              // This requires converting xml to HTML in a way that includes the image src
              // Alternatively, handle image references separately in Markdown
            }
          } else {
            // Handle external image URLs if needed
            images.push({
              name: path.basename(src),
              data: '', // Placeholder if you plan to download images
              type: '', // Placeholder for image type
              path: src // External path
            });
          }
        }
      });
    }

    // Convert HTML to Markdown
    let markdownContent = turndownService.turndown(htmlContent);

    // Add metadata
    const metadataMarkdown = `# ${path.basename(originalName, path.extname(originalName))}\n\n` +
                             `**Converted on:** ${new Date().toISOString()}\n\n`;

    // Combine metadata and content
    const fullMarkdown = metadataMarkdown + markdownContent;

    return {
      content: fullMarkdown,
      images: images
    };
  } catch (error) {
    console.error('Error converting XML to Markdown:', error);
    throw error;
  }
}

/**
 * Converts parsed XML object to HTML string.
 * This function should be customized based on the XML schema.
 * @param {Object} parsedXml - Parsed XML object.
 * @returns {string} - HTML string.
 */
function xmlToHtml(parsedXml) {
  // Implement a conversion logic from XML to HTML based on your specific XML structure
  // Here's a simple example for demonstration purposes:

  let html = '';

  function traverse(obj) {
    for (const key in obj) {
      if (obj.hasOwnProperty(key)) {
        const value = obj[key];
        if (typeof value === 'object') {
          html += `<${key}>`;
          traverse(value);
          html += `</${key}>`;
        } else {
          html += `<${key}>${value}</${key}>`;
        }
      }
    }
  }

  traverse(parsedXml);
  return html;
}

```

## services/converter/web/youtubeConverter.js

```js
// services/converter/web/youtubeConverter.js

import { YoutubeTranscript } from 'youtube-transcript';
import fetch from 'node-fetch';

export async function convertYoutubeToMarkdown(url) {
  try {
    const videoId = extractVideoId(url);
    if (!videoId) {
      throw new Error('Invalid YouTube URL');
    }

    // Fetch video metadata
    const metadata = await fetchVideoMetadata(videoId);

    // Fetch transcript
    const transcript = await YoutubeTranscript.fetchTranscript(videoId);

    // Generate Markdown
    let markdown = `# ${metadata.title}\n\n`;
    markdown += `**Link:** [${url}](${url})\n\n`;
    markdown += `**Description:** ${metadata.description}\n\n`;
    markdown += `**Published:** ${metadata.publishedAt}\n\n`;
    markdown += `## Transcript\n\n`;

    transcript.forEach((entry, index) => {
      const timestamp = formatTimestamp(entry.offset);
      markdown += `**[${timestamp}]** ${entry.text}\n\n`;
    });

    return markdown;
  } catch (error) {
    console.error('Error converting YouTube video to Markdown:', error);
    throw error;
  }
}

function extractVideoId(url) {
  const regex = /(?:https?:\/\/)?(?:www\.)?(?:youtube\.com|youtu\.be)\/(?:watch\?v=)?(.+)/;
  const match = url.match(regex);
  return match ? match[1] : null;
}

async function fetchVideoMetadata(videoId) {
  // Note: This is a placeholder. You would typically use the YouTube Data API here.
  // For demonstration, we're returning mock data.
  return {
    title: 'Sample YouTube Video',
    description: 'This is a sample description for the video.',
    publishedAt: new Date().toISOString()
  };
}

function formatTimestamp(milliseconds) {
  const seconds = Math.floor(milliseconds / 1000);
  const minutes = Math.floor(seconds / 60);
  const hours = Math.floor(minutes / 60);
  return `${hours.toString().padStart(2, '0')}:${(minutes % 60).toString().padStart(2, '0')}:${(seconds % 60).toString().padStart(2, '0')}`;
}
```

## services/fileProcessor.js

```js
// services/fileProcessor.js
import { textConverterFactory } from './converter/textConverterFactory.js';
import { storeConvertedFile } from './fileStorage.js';
import { AppError } from '../utils/errorHandler.js';
import path from 'path';
import sanitize from 'sanitize-filename';

export async function processFile(fileBuffer, fileType, apiKey, originalName) {
  try {
    // Use the factory to convert the file
    const convertedContent = await textConverterFactory.convertToMarkdown(
      fileBuffer,
      fileType,
      apiKey,
      originalName
    );

    // Create filename
    const filename = `${sanitize(originalName.replace(path.extname(originalName), ''))}.md`;

    console.log(`Converted content for ${filename}:`, convertedContent.substring(0, 100));

    // Store and return fileId
    const fileId = storeConvertedFile(convertedContent, filename);
    return fileId;

  } catch (error) {
    console.error(`Error processing file ${originalName}:`, error);
    throw new AppError('File conversion failed', 500, error.message);
  }
}
```

## services/fileStorage.js

```js
// services/fileStorage.js

import { v4 as uuidv4 } from 'uuid';

/**
 * In-memory storage for converted files.
 * Key: fileId (string)
 * Value: { content: string, filename: string }
 */
const fileDatabase = new Map();

/**
 * Stores a converted file and returns its unique fileId.
 * @param {string} content - The converted content (Markdown string).
 * @param {string} filename - The sanitized filename.
 * @returns {string} The generated fileId.
 */
export function storeConvertedFile(content, filename) {
  const fileId = uuidv4();
  fileDatabase.set(fileId, { content, filename });
  console.log(`Stored converted file: ${filename} with ID: ${fileId}`);
  return fileId;
}

/**
 * Retrieves a converted file by its fileId.
 * @param {string} fileId - The unique identifier of the file.
 * @returns {Object|null} The file object or null if not found.
 */
export function getConvertedFile(fileId) {
  return fileDatabase.get(fileId) || null;
}

/**
 * Retrieves multiple converted files by their fileIds.
 * @param {Array<string>} fileIds - Array of fileIds.
 * @returns {Array<Object>} Array of file objects.
 */
export function getMultipleConvertedFiles(fileIds) {
  return fileIds.map(id => {
    const file = getConvertedFile(id);
    if (file) {
      return { fileId: id, ...file };
    }
    return null;
  }).filter(file => file !== null);
}

```

## services/openaiProxy.js

```js
// services/openaiProxy.js

import OpenAI from 'openai';
import { createRequire } from 'module'; // Import createRequire
const require = createRequire(import.meta.url); // Create a require function
const { RateLimiter } = require('limiter'); // Destructure RateLimiter from the required package
import fs from 'fs';
import axios from 'axios';
import axiosRetry from 'axios-retry';
import { config } from '../config/default.js';
import NodeCache from 'node-cache';
import { AppError } from '../utils/errorHandler.js';

class OpenAIProxy {
  constructor() {
    this.openai = null;
    this.rateLimiter = new RateLimiter({
      tokensPerInterval: config.api.openai.maxRequests || 50,
      interval: 'minute',
    });
    this.cache = new NodeCache({ stdTTL: 300 }); // Cache for 5 minutes
  }

  async initialize(apiKey) {
    if (!this.openai) {
      this.openai = new OpenAI({
        apiKey,
        baseURL: config.api.openai.baseUrl,
        timeout: config.api.openai.timeout,
      });

      // Configure axios retry
      axiosRetry(this.openai.httpClient, {
        retries: config.api.openai.maxRetries,
        retryDelay: axiosRetry.exponentialDelay,
        retryCondition: (error) => {
          return axiosRetry.isNetworkError(error) || axiosRetry.isRetryableError(error);
        },
      });
    }
  }

  async makeRequest(apiKey, endpoint, data) {
    await this.rateLimiter.removeTokens(1);
    await this.initialize(apiKey);

    const cacheKey = `${endpoint}:${JSON.stringify(data)}`;
    const cachedResponse = this.cache.get(cacheKey);
    if (cachedResponse) {
      return cachedResponse;
    }

    try {
      const response = await this.openai.httpClient.post(`/${endpoint}`, data, {
        headers: {
          Authorization: `Bearer ${apiKey}`,
          ...(data.getHeaders ? data.getHeaders() : {}),
        },
      });

      this.cache.set(cacheKey, response.data);
      return response.data;
    } catch (error) {
      throw this.handleApiError(error);
    }
  }

  handleApiError(error) {
    if (error.response) {
      const { status, data } = error.response;
      switch (status) {
        case 401:
          return new AppError('Invalid API key', 401);
        case 429:
          return new AppError('Rate limit exceeded', 429);
        case 500:
          return new AppError('OpenAI server error', 500);
        default:
          return new AppError(`Whisper API error: ${data.error.message}`, status);
      }
    }
    return new AppError('Unknown OpenAI API error', 500);
  }
}

export const openaiProxy = new OpenAIProxy();

```

## services/transcriber.js

```js
// services/transcriber.js

import fs from 'fs/promises';
import path from 'path';
import { OpenAI } from 'openai';
import ffmpeg from 'fluent-ffmpeg';
import ffmpegStatic from 'ffmpeg-static';
import { Readable } from 'stream';

// Set the ffmpeg path
ffmpeg.setFfmpegPath(ffmpegStatic);

class Transcriber {
  constructor() {
    this.openai = null;
  }

  initialize(apiKey) {
    this.openai = new OpenAI({ apiKey });
  }

  async transcribe(filePath, apiKey) {
    if (!this.openai) {
      this.initialize(apiKey);
    }

    try {
      const fileExtension = path.extname(filePath).toLowerCase();
      let audioFile = filePath;

      // Convert video to audio if necessary
      if (['.mp4', '.avi', '.mov', '.webm'].includes(fileExtension)) {
        audioFile = await this.convertVideoToAudio(filePath);
      }

      // Check if the audio format is supported, convert if not
      if (!['.mp3', '.mp4', '.mpeg', '.mpga', '.m4a', '.wav', '.webm'].includes(path.extname(audioFile).toLowerCase())) {
        audioFile = await this.convertToSupportedAudioFormat(audioFile);
      }

      const transcript = await this.transcribeAudio(audioFile);

      // Clean up temporary audio file if it was created
      if (audioFile !== filePath) {
        await fs.unlink(audioFile);
      }

      return transcript;
    } catch (error) {
      console.error('Transcription error:', error);
      throw error;
    }
  }

  async convertVideoToAudio(videoPath) {
    const outputPath = videoPath.replace(path.extname(videoPath), '.mp3');
    return new Promise((resolve, reject) => {
      ffmpeg(videoPath)
        .outputOptions('-ab', '192k')
        .save(outputPath)
        .on('end', () => resolve(outputPath))
        .on('error', (err) => reject(err));
    });
  }

  async convertToSupportedAudioFormat(audioPath) {
    const outputPath = audioPath.replace(path.extname(audioPath), '.mp3');
    return new Promise((resolve, reject) => {
      ffmpeg(audioPath)
        .toFormat('mp3')
        .on('end', () => resolve(outputPath))
        .on('error', (err) => reject(err))
        .save(outputPath);
    });
  }

  async transcribeAudio(audioPath) {
    const audioStream = fs.createReadStream(audioPath);
    
    const response = await this.openai.audio.transcriptions.create({
      file: audioStream,
      model: "whisper-1",
    });

    return response.text;
  }
}

export const transcriber = new Transcriber();
```

## utils/errorHandler.js

```js
// utils/errorHandler.js

import winston from 'winston';
import 'winston-daily-rotate-file';

// Create a Winston logger instance with daily rotation
const logger = winston.createLogger({
  level: 'error',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.json()
  ),
  transports: [
    new winston.transports.DailyRotateFile({
      filename: 'logs/error-%DATE%.log',
      datePattern: 'YYYY-MM-DD',
      maxSize: '20m',
      maxFiles: '14d'
    }),
    new winston.transports.Console()
  ]
});

// Custom Error Class
class AppError extends Error {
  constructor(message, statusCode, details = null) {
    super(message);
    this.statusCode = statusCode;
    this.status = `${statusCode}`.startsWith('4') ? 'fail' : 'error';
    this.details = details;
    this.isOperational = true;

    Error.captureStackTrace(this, this.constructor);
  }
}

// Error handling functions
const handleCastError = (err) => {
  const message = `Invalid ${err.path}: ${err.value}.`;
  return new AppError(message, 400);
};

const handleDuplicateFields = (err) => {
  const value = err.message.match(/(["'])(\\?.)*?\1/)[0];
  const message = `Duplicate field value: ${value}. Please use another value!`;
  return new AppError(message, 400);
};

const handleValidationError = (err) => {
  const errors = Object.values(err.errors).map(el => el.message);
  const message = `Invalid input data. ${errors.join('. ')}`;
  return new AppError(message, 400);
};

const handleJWTError = () => new AppError('Invalid token. Please log in again!', 401);
const handleJWTExpiredError = () => new AppError('Your token has expired! Please log in again.', 401);

// Send error during development
const sendErrorDev = (err, res) => {
  res.status(err.statusCode).json({
    status: err.status,
    error: err,
    message: err.message,
    stack: err.stack
  });
};

// Send error during production
const sendErrorProd = (err, res) => {
  if (err.isOperational) {
    // Operational, trusted error: send message to client
    res.status(err.statusCode).json({
      status: err.status,
      message: err.message
    });
  } else {
    // Programming or other unknown error: don't leak details
    // Log the error
    logger.error('ERROR 💥', { message: err.message, stack: err.stack });

    // Send generic message
    res.status(500).json({
      status: 'error',
      message: 'Something went wrong!'
    });
  }
};

// Centralized Error Handling Middleware
export const errorHandler = (err, req, res, next) => {
  // Set defaults
  err.statusCode = err.statusCode || 500;
  err.status = err.status || 'error';

  // Determine environment
  const env = process.env.NODE_ENV || 'development';

  if (env === 'development') {
    sendErrorDev(err, res);
  } else if (env === 'production') {
    let error = { ...err };
    error.message = err.message;

    // Handle specific error types
    if (error.name === 'CastError') error = handleCastError(error);
    if (error.code === 11000) error = handleDuplicateFields(error);
    if (error.name === 'ValidationError') error = handleValidationError(error);
    if (error.name === 'JsonWebTokenError') error = handleJWTError();
    if (error.name === 'TokenExpiredError') error = handleJWTExpiredError();

    sendErrorProd(error, res);
  } else {
    // Fallback for other environments
    sendErrorProd(err, res);
  }
};

// Export AppError for use in other modules
export { AppError };

```

## utils/markdownGenerator.js

```js
// utils/markdownGenerator.js

/**
 * Generates a Markdown document from the given content
 * @param {Object} options - The content and formatting options
 * @param {string} options.title - The title of the document
 * @param {string|Array} options.content - The main content (string or array of strings)
 * @param {Object} [options.metadata] - Optional metadata key-value pairs
 * @param {boolean} [options.tableOfContents=false] - Whether to include a table of contents
 * @returns {string} The formatted Markdown content
 */
export function generateMarkdown(options) {
    const { title, content, metadata = {}, tableOfContents = false } = options;
    let markdown = '';
  
    // Add title
    markdown += `# ${escapeMarkdown(title)}\n\n`;
  
    // Add metadata
    if (Object.keys(metadata).length > 0) {
      markdown += '## Metadata\n\n';
      for (const [key, value] of Object.entries(metadata)) {
        markdown += `- **${escapeMarkdown(key)}**: ${escapeMarkdown(value)}\n`;
      }
      markdown += '\n';
    }
  
    // Add table of contents if requested
    if (tableOfContents) {
      markdown += generateTableOfContents(content);
    }
  
    // Add main content
    markdown += formatContent(content);
  
    return markdown;
  }
  
  /**
   * Formats the main content, handling both strings and arrays
   * @param {string|Array} content - The content to format
   * @returns {string} The formatted content
   */
  function formatContent(content) {
    if (Array.isArray(content)) {
      return content.map(item => formatContentItem(item)).join('\n\n');
    } else {
      return formatContentItem(content);
    }
  }
  
  /**
   * Formats a single content item
   * @param {string|Object} item - The content item to format
   * @returns {string} The formatted content item
   */
  function formatContentItem(item) {
    if (typeof item === 'string') {
      return item;
    } else if (typeof item === 'object') {
      if (item.type === 'list') {
        return formatList(item.items, item.ordered);
      } else if (item.type === 'code') {
        return formatCodeBlock(item.code, item.language);
      } else if (item.type === 'quote') {
        return formatBlockquote(item.text);
      }
    }
    return '';
  }
  
  /**
   * Generates a table of contents from the content
   * @param {string|Array} content - The content to generate TOC from
   * @returns {string} The table of contents in Markdown format
   */
  function generateTableOfContents(content) {
    // This is a simplified TOC generation. You might want to enhance this
    // to handle nested headers and more complex structures.
    let toc = '## Table of Contents\n\n';
    const headers = content.match(/^#{2,3} .+$/gm) || [];
    headers.forEach(header => {
      const level = header.match(/^#{2,3}/)[0].length - 2;
      const title = header.replace(/^#{2,3} /, '');
      const link = title.toLowerCase().replace(/[^\w]+/g, '-');
      toc += `${'  '.repeat(level)}* [${title}](#${link})\n`;
    });
    return toc + '\n';
  }
  
  /**
   * Formats a list in Markdown
   * @param {Array} items - The list items
   * @param {boolean} [ordered=false] - Whether the list is ordered
   * @returns {string} The formatted list
   */
  function formatList(items, ordered = false) {
    return items.map((item, index) => 
      `${ordered ? `${index + 1}.` : '-'} ${escapeMarkdown(item)}`
    ).join('\n');
  }
  
  /**
   * Formats a code block in Markdown
   * @param {string} code - The code content
   * @param {string} [language=''] - The programming language
   * @returns {string} The formatted code block
   */
  function formatCodeBlock(code, language = '') {
    return `\`\`\`${language}\n${code}\n\`\`\``;
  }
  
  /**
   * Formats a blockquote in Markdown
   * @param {string} text - The quote text
   * @returns {string} The formatted blockquote
   */
  function formatBlockquote(text) {
    return text.split('\n').map(line => `> ${line}`).join('\n');
  }
  
  /**
   * Escapes special Markdown characters in a string
   * @param {string} text - The text to escape
   * @returns {string} The escaped text
   */
  function escapeMarkdown(text) {
    return text.replace(/([*_`~\[\]()#+\-.!])/g, '\\$1');
  }
```



