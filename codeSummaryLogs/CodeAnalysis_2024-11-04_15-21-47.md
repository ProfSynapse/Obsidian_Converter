# Table of Contents

- [Directory](#directory)
- [Analysis](#analysis)
- [Code Files](#code-files)
- [Report Generated On](#report-generated-on)

# Report Generated On

*Generated on 11/4/2024, 3:21:47 PM*


# Directory

```
├── .genaiscript
│   └── .gitattributes
├── config
│   └── default.js
├── routes
│   ├── handlers
│   │   ├── batchHandler.js
│   │   ├── fileHandler.js
│   │   ├── parentUrlHandler.js
│   │   ├── urlHandler.js
│   │   └── youtubeHandler.js
│   ├── middleware
│   │   ├── rateLimit.js
│   │   ├── upload.js
│   │   └── validators.js
│   ├── utils
│   │   ├── apiKeyChecker.js
│   │   ├── categoryDetector.js
│   │   ├── youtubeUtils.js
│   │   └── zipProcessor.js
│   ├── index.js
│   └── proxyRoutes.js
├── services
│   ├── converter
│   │   ├── data
│   │   │   ├── csvConverter.js
│   │   │   ├── jsonConverter.js
│   │   │   ├── xlsxConverter.js
│   │   │   └── yamlConverter.js
│   │   ├── multimedia
│   │   │   ├── audioconverter.js
│   │   │   └── videoConverter.js
│   │   ├── text
│   │   │   ├── docxConverter.js
│   │   │   ├── epubConverter.js
│   │   │   ├── odtConverter.js
│   │   │   ├── pdfConverter.js
│   │   │   ├── pptxConverter.js
│   │   │   ├── rtfConverter.js
│   │   │   └── txtConverter.js
│   │   ├── web
│   │   │   ├── htmlConverter.js
│   │   │   ├── parentUrlConverter.js
│   │   │   ├── urlConverter.js
│   │   │   ├── xmlConverter.js
│   │   │   └── youtubeConverter.js
│   │   └── textConverterFactory.js
│   ├── fileProcessor.js
│   ├── fileStorage.js
│   ├── openaiProxy.js
│   └── transcriber.js
├── temp
├── utils
│   ├── errorHandler.js
│   ├── markdownGenerator.js
│   └── metadataExtractor.js
├── package.json
└── server.js

```

# Analysis

No analysis was generated.

# Code Files

## .genaiscript/.gitattributes

```
# avoid merge issues and ignore files in diffs
*.json -diff merge=ours linguist-generated
*.jsonl -diff merge=ours linguist-generated        
*.js -diff merge=ours linguist-generated

```

## config/default.js

```js
// config/default.js

export const config = {
  server: {
    port: process.env.PORT || 3000,
    env: process.env.NODE_ENV || 'development'
  },
  api: {
    openai: {
      baseUrl: 'https://api.openai.com/v1',
      timeout: 30000,
      maxRetries: 3,
      apiKey: process.env.OPENAI_API_KEY
    }
  },
  conversion: {
    allowedFileTypes: [
      "txt", "rtf", "pdf", "docx", "odt", "epub",
      "csv", "json", "yaml", "yml", "xlsx", "pptx",
      "html", "htm", "xml",
      "mp3", "wav", "ogg", "mp4", "mov", "avi", "webm"
    ],
    maxFileSize: 52428800
  },
  storage: {
    tempDir: '/tmp/obsidian-converter'
  },
  security: {
    rateLimitPerMinute: 100
  }
};

```

## package.json

```json
{
  "name": "obsidian-note-converter",
  "version": "1.0.0",
  "description": "A service to convert various file types to Obsidian-compatible Markdown notes",
  "main": "src/server.js",
  "type": "module",
  "imports": {
    "pdfjs-dist": {
      "default": "pdfjs-dist/build/pdf.mjs"
    }
  },
  "scripts": {
    "start": "node src/server.js",
    "dev": "nodemon src/server.js",
    "test": "jest",
    "lint": "eslint .",
    "build": "babel src -d dist",
    "precommit": "lint-staged"
  },
  "keywords": [
    "obsidian",
    "markdown",
    "converter",
    "notes"
  ],
  "author": "Your Name",
  "license": "MIT",
  "dependencies": {
    "@bundled-es-modules/pdfjs-dist": "^3.6.172-alpha.1",
    "@iarna/rtf-to-html": "^1.1.0",
    "@squoosh/lib": "^0.3.1",
    "archiver": "^7.0.1",
    "axios-retry": "^3.3.1",
    "config": "^3.3.6",
    "cors": "^2.8.5",
    "dotenv": "^16.4.5",
    "epub": "^1.2.1",
    "express": "^4.17.1",
    "express-rate-limit": "^6.7.0",
    "express-validator": "^6.14.0",
    "ffmpeg-static": "^5.1.0",
    "fluent-ffmpeg": "^2.1.2",
    "helmet": "^6.0.0",
    "joi": "^17.9.2",
    "limiter": "^2.1.0",
    "mammoth": "^1.4.21",
    "multer": "^1.4.2",
    "node-cache": "^5.1.2",
    "node-cron": "^3.0.0",
    "node-fetch": "^3.3.2",
    "node-poppler": "^7.2.2",
    "openai": "^4.0.0",
    "p-limit": "^3.1.0",
    "pdf-img-convert": "^2.0.0",
    "pdf-parse": "^1.1.1",
    "pdf.js": "^0.1.0",
    "pdfjs-dist": "^2.16.105",
    "sanitize-filename": "^1.6.3",
    "sharp": "^0.33.5",
    "turndown": "^7.2.0",
    "winston": "^3.3.3",
    "winston-daily-rotate-file": "^4.6.5",
    "xlsx": "^0.18.5",
    "yaml": "^2.2.1"
  },
  "overrides": {
    "pdf-export-images": {
      "pdfjs-dist": "3.11.174"
    }
  },
  "devDependencies": {
    "@babel/cli": "^7.14.8",
    "@babel/core": "^7.15.0",
    "@babel/preset-env": "^7.15.0",
    "axios": "^1.7.7",
    "canvas": "^2.11.2",
    "cheerio": "^1.0.0",
    "commander": "^12.1.0",
    "csv-parse": "^5.5.6",
    "eslint": "^7.32.0",
    "husky": "^8.0.0",
    "jest": "^27.0.6",
    "jsdom": "^25.0.1",
    "jszip": "^3.10.1",
    "lint-staged": "^13.1.0",
    "nodemon": "^2.0.12",
    "office-text-extractor": "^3.0.3",
    "officeparser": "^5.0.0",
    "pdf-export-images": "^1.2.0",
    "pdf-extractor": "^2.2.0",
    "pdf-lib": "^1.17.1",
    "puppeteer": "^23.6.0",
    "tmp-promise": "^3.0.3",
    "xml2js": "^0.6.2",
    "youtube-transcript": "^1.2.1"
  },
  "lint-staged": {
    "*.js": [
      "eslint --fix",
      "git add"
    ]
  },
  "engines": {
    "node": ">=14.0.0"
  }
}

```

## routes/handlers/batchHandler.js

```js
// routes/convert/handlers/batchHandler.js

import { createBatchZip, handleConversion } from '../utils/zipProcessor.js';
import { AppError } from '../../utils/errorHandler.js';
import sanitizeFilename from 'sanitize-filename';

/**
 * Batch conversion handler
 */
export async function handleBatchConversion(req, res, next) {
  try {
    const { items } = req.body;
    const apiKey = req.headers['x-api-key'];

    if (!Array.isArray(items)) {
      throw new AppError('Items must be an array', 400);
    }

    // Validate each item has 'type', 'content', and 'name'
    for (const item of items) {
      if (!item.type || typeof item.type !== 'string') {
        throw new AppError(`Item "${item.name || 'unknown'}" is missing a valid 'type' property`, 400);
      }
      if (!item.content) {
        throw new AppError(`Item "${item.name || 'unknown'}" is missing 'content' property`, 400);
      }
      if (!item.name || typeof item.name !== 'string') {
        throw new AppError(`Item is missing a valid 'name' property`, 400);
      }
    }

    // Process all items concurrently
    const results = await Promise.all(
      items.map(async (item) => {
        const type = item.type.toLowerCase();
        const content = item.content;
        const name = item.name;

        return await handleConversion(type, content, name, apiKey);
      })
    );

    // Create and send ZIP
    const zipBuffer = await createBatchZip(results);

    // Determine ZIP filename based on current date-time
    const zipFilename = `conversion_${new Date()
      .toISOString()
      .replace(/[:.]/g, '-')}.zip`;

    res.set({
      'Content-Type': 'application/zip',
      'Content-Disposition': `attachment; filename=${sanitizeFilename(zipFilename)}`,
    });
    res.send(zipBuffer);
  } catch (error) {
    console.error(`Batch conversion handler error: ${error.message}`);
    next(new AppError(error.message, 500));
  }
}

```

## routes/handlers/fileHandler.js

```js
// routes/convert/handlers/fileHandler.js

import { createBatchZip, handleConversion } from '../utils/zipProcessor.js';
import { AppError } from '../../utils/errorHandler.js';
import sanitizeFilename from 'sanitize-filename';

/**
 * File upload handler
 */
export async function handleFileUpload(req, res, next) {
  try {
    if (!req.file) {
      throw new AppError('No file uploaded', 400);
    }

    const conversionResult = await handleConversion(
      'file',
      req.file.buffer,
      req.file.originalname,
      req.headers['x-api-key']
    );

    const zipBuffer = await createBatchZip([conversionResult]);

    res.set({
      'Content-Type': 'application/zip',
      'Content-Disposition': `attachment; filename=${sanitizeFilename(
        req.file.originalname
      )}_converted.zip`,
    });
    res.send(zipBuffer);
  } catch (error) {
    console.error(`File conversion error: ${error.message}`);
    next(new AppError(`File conversion failed: ${error.message}`, 500));
  }
}

```

## routes/handlers/parentUrlHandler.js

```js
// routes/convert/handlers/parentUrlHandler.js

import { createBatchZip, handleConversion } from '../utils/zipProcessor.js';
import { AppError } from '../../utils/errorHandler.js';
import sanitizeFilename from 'sanitize-filename';

/**
 * Parent URL conversion handler
 */
export async function handleParentUrlConversion(req, res, next) {
  try {
    const { parenturl } = req.body;
    console.log('Converting Parent URL:', parenturl);

    const urlString =
      typeof parenturl === 'object' ? parenturl.url || parenturl.parenturl : parenturl;
    const hostname = new URL(urlString).hostname;
    const conversionResult = await handleConversion(
      'parenturl',
      urlString,
      hostname,
      req.headers['x-api-key']
    );

    const zipBuffer = await createBatchZip([conversionResult]);

    // Set proper headers for ZIP file download
    const zipFilename = `${sanitizeFilename(hostname)}_archive_${new Date()
      .toISOString()
      .replace(/[:.]/g, '-')}.zip`;

    res.set({
      'Content-Type': 'application/zip',
      'Content-Disposition': `attachment; filename=${sanitizeFilename(zipFilename)}`,
      'Cache-Control': 'no-cache',
      Pragma: 'no-cache',
      Expires: '0',
    });

    return res.send(zipBuffer);
  } catch (error) {
    console.error(`Parent URL conversion error: ${error.message}`);
    next(new AppError(`Parent URL conversion failed: ${error.message}`, 500));
  }
}

```

## routes/handlers/urlHandler.js

```js
// routes/convert/handlers/urlHandler.js

import { createBatchZip, handleConversion } from '../utils/zipProcessor.js';
import { AppError } from '../../utils/errorHandler.js';
import sanitizeFilename from 'sanitize-filename';

/**
 * URL conversion handler
 */
export async function handleUrlConversion(req, res, next) {
  try {
    const { url } = req.body;
    console.log('Converting URL:', url);

    const hostname = new URL(url).hostname;
    const conversionResult = await handleConversion(
      'url',
      url,
      hostname,
      req.headers['x-api-key']
    );

    const zipBuffer = await createBatchZip([conversionResult]);

    // Set proper headers for ZIP file download
    const zipFilename = `${sanitizeFilename(hostname)}_page_${new Date()
      .toISOString()
      .replace(/[:.]/g, '-')}.zip`;

    res.set({
      'Content-Type': 'application/zip',
      'Content-Disposition': `attachment; filename=${sanitizeFilename(zipFilename)}`,
      'Cache-Control': 'no-cache',
      Pragma: 'no-cache',
      Expires: '0',
    });

    return res.send(zipBuffer);
  } catch (error) {
    console.error(`URL conversion error: ${error.message}`);
    next(new AppError(`URL conversion failed: ${error.message}`, 500));
  }
}

```

## routes/handlers/youtubeHandler.js

```js
// routes/handlers/youtubeHandler.js
import JSZip from 'jszip';
import sanitizeFilename from 'sanitize-filename';
import { convertYoutubeToMarkdown } from '../../services/converter/web/youtubeConverter.js';
import { AppError } from '../../utils/errorHandler.js';
import { extractVideoId } from '../../routes/utils/youtubeUtils.js';

/**
 * Main YouTube conversion handler
 * @param {Object} req - The HTTP request object
 * @param {Object} res - The HTTP response object
 * @param {Function} next - The next middleware function
 */
export async function handleYouTubeConversion(req, res, next) {
  try {
    const { url } = req.body;
    const apiKey = req.headers['x-api-key']; // If needed
    const videoId = extractVideoId(url);

    if (videoId === 'unknown') {
      throw new Error('Invalid YouTube URL');
    }

    // Get the conversion result which includes metadata
    const result = await convertYoutubeToMarkdown(url, apiKey);

    if (!result.success) {
      throw new Error(result.error);
    }

    // Create ZIP with the proper filename using metadata
    const zip = new JSZip();
    const safeTitle = sanitizeFilename(result.name || `${videoId}`);
    const safeFilename = `${safeTitle}.md`;

    zip.file(safeFilename, result.content);
    const zipBuffer = await zip.generateAsync({ type: 'nodebuffer' });

    // Use the video title in the ZIP filename
    const zipFilename = `youtube_${safeTitle}_${new Date()
      .toISOString()
      .replace(/[:.]/g, '-')}.zip`;

    res.set({
      'Content-Type': 'application/zip',
      'Content-Disposition': `attachment; filename=${zipFilename}`,
      'Cache-Control': 'no-cache',
      'Pragma': 'no-cache',
      'Expires': '0',
    });

    return res.send(zipBuffer);
  } catch (error) {
    console.error(`YouTube conversion error: ${error.message}`);
    next(new AppError(`YouTube conversion failed: ${error.message}`, 500));
  }
}

```

## routes/index.js

```js
// routes/convert/index.js

import express from 'express';
import { conversionRateLimiter } from './middleware/rateLimit.js';
import { validators } from './middleware/validators.js';
import { apiKeyChecker } from './utils/apiKeyChecker.js';
import { upload } from './middleware/upload.js';
import { handleBatchConversion } from './handlers/batchHandler.js';
import { handleFileUpload } from './handlers/fileHandler.js';
import { handleUrlConversion } from './handlers/urlHandler.js';
import { handleParentUrlConversion } from './handlers/parentUrlHandler.js';
import { handleYouTubeConversion } from './handlers/youtubeHandler.js';
import { config } from '../config/default.js';

const router = express.Router();

// Apply rate limiter to all conversion routes
router.use(conversionRateLimiter);

// Batch conversion endpoint
router.post(
  '/batch',
  validators.batch,
  validators.checkResult,
  handleBatchConversion
);

// Single file upload endpoint
router.post(
  '/file',
  apiKeyChecker,
  upload,
  validators.file,
  validators.checkResult,
  handleFileUpload
);

// Single URL conversion endpoint
router.post(
  '/url',
  validators.url,
  validators.checkResult,
  handleUrlConversion
);

// Parent URL conversion endpoint
router.post(
  '/parent-url',
  validators.parenturl,
  validators.checkResult,
  handleParentUrlConversion
);

// YouTube conversion endpoint
router.post(
  '/youtube',
  validators.youtube,
  validators.checkResult,
  handleYouTubeConversion
);

export default router;

```

## routes/middleware/rateLimit.js

```js
// routes/convert/middleware/rateLimit.js

import rateLimit from 'express-rate-limit';
import { config } from '../../config/default.js';

/**
 * Rate limiting configuration specific to conversion routes
 */
export const conversionRateLimiter = rateLimit({
  windowMs: 60 * 1000, // 1 minute
  max: config.security.rateLimitPerMinute,
  message: 'Too many requests from this IP, please try again after a minute',
  standardHeaders: true,
  legacyHeaders: false,
});

```

## routes/middleware/upload.js

```js
// routes/convert/middleware/upload.js

import multer from 'multer';
import path from 'path';
import { AppError } from '../../utils/errorHandler.js';
import { config } from '../../config/default.js';

/**
 * Multer configuration for file uploads
 */
export const upload = multer({
  storage: multer.memoryStorage(),
  limits: {
    fileSize: config.conversion.maxFileSize,
    files: 10, // Increased for batch processing
  },
  fileFilter: (req, file, cb) => {
    const ext = path.extname(file.originalname).toLowerCase().slice(1);
    if (!config.conversion.allowedFileTypes.includes(ext)) {
      return cb(
        new AppError(
          `Unsupported file type: ${ext}. Allowed types: ${config.conversion.allowedFileTypes.join(
            ', '
          )}`,
          400
        )
      );
    }
    cb(null, true);
  },
}).single('file');

```

## routes/middleware/validators.js

```js
// routes/convert/middleware/validators.js

import { body, validationResult } from 'express-validator';
import { AppError } from '../../utils/errorHandler.js';
import { config } from '../../config/default.js';

const normalizeUrl = (url) => {
    if (!/^https?:\/\//i.test(url)) {
      return 'https://' + url;
    }
    return url;
  };

export const validators = {
  file: [
    body('fileType')
      .optional()
      .isString()
      .withMessage('fileType must be a string')
      .custom((value) => {
        if (
          value &&
          !config.conversion.allowedFileTypes.includes(value.toLowerCase())
        ) {
          throw new Error(
            `Unsupported file type. Allowed types: ${config.conversion.allowedFileTypes.join(
              ', '
            )}`
          );
        }
        return true;
      }),
  ],

  url: [
    body('url')
      .notEmpty()
      .withMessage('URL is required')
      .isString()
      .withMessage('URL must be a string')
      .custom((value) => {
        // Normalize the URL
        const normalizedUrl = normalizeUrl(value);
        try {
          new URL(normalizedUrl);
          return true;
        } catch (error) {
          throw new Error('Invalid URL format');
        }
      }),
  ],

  parenturl: [
    body('parenturl')
      .notEmpty()
      .withMessage('Parent URL is required')
      .isString()
      .withMessage('Parent URL must be a string')
      .custom((value) => {
        // Normalize the URL
        const normalizedUrl = normalizeUrl(value);
        try {
          new URL(normalizedUrl);
          return true;
        } catch (error) {
          throw new Error('Invalid Parent URL format');
        }
      }),
  ],

  youtube: [
    body('url')
      .notEmpty()
      .withMessage('YouTube URL is required')
      .isString()
      .withMessage('YouTube URL must be a string')
      .custom((value) => {
        // Normalize the URL
        const normalizedUrl = normalizeUrl(value);
        const regex = /^(https?\:\/\/)?(www\.youtube\.com|youtu\.be)\/.+$/;
        if (!regex.test(normalizedUrl)) {
          throw new Error('URL must be a valid YouTube link');
        }
        return true;
      }),
  ],

  batch: [
    body('items')
      .isArray()
      .withMessage('Items must be an array')
      .notEmpty()
      .withMessage('Items array cannot be empty'),
    body('items.*.type')
      .isString()
      .withMessage('Each item must have a type')
      .isIn(['file', 'url', 'parenturl', 'youtube'])
      .withMessage('Invalid item type'),
    body('items.*.content').notEmpty().withMessage('Each item must have content'),
    body('items.*.name').notEmpty().withMessage('Each item must have a name'),
  ],

  checkResult: (req, res, next) => {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      return next(new AppError('Validation failed', 400, errors.array()));
    }
    next();
  },
};

```

## routes/proxyRoutes.js

```js
// routes/proxyRoutes.js
import express from 'express';
import { body, validationResult } from 'express-validator';
import { openaiProxy } from '../services/openaiProxy.js';
import { AppError } from '../utils/errorHandler.js';
import rateLimit from 'express-rate-limit';
import { config } from '../config/default.js';

const router = express.Router();

// Rate limiter specific to proxy routes
const proxyLimiter = rateLimit({
  windowMs: 60 * 1000, // 1 minute
  max: config.security.rateLimitPerMinute,
  message: 'Too many requests to proxy API, please try again after a minute.',
});

// Apply rate limiter to all proxy routes
router.use(proxyLimiter);

// Validation middleware
const validateProxyRequest = [
  body('endpoint')
    .notEmpty()
    .withMessage('Endpoint is required')
    .isString()
    .withMessage('Endpoint must be a string'),
  body('data')
    .optional()
    .isObject()
    .withMessage('Data must be an object'),
];

router.post('/openai', validateProxyRequest, async (req, res, next) => {
  // Handle validation errors
  const errors = validationResult(req);
  if (!errors.isEmpty()) {
    return next(new AppError('Validation failed', 400, errors.array()));
  }

  try {
    const apiKey = req.headers['x-api-key'];
    if (!apiKey) {
      throw new AppError('API key is required in headers', 401);
    }

    const { endpoint, data } = req.body;

    const response = await openaiProxy.makeRequest(apiKey, endpoint, data);
    res.json(response);
  } catch (error) {
    next(error);
  }
});

export default router;

```

## routes/utils/apiKeyChecker.js

```js
// routes/convert/utils/apiKeyChecker.js

import { requiresApiKey } from './categoryDetector.js';
import { AppError } from '../../utils/errorHandler.js';
import path from 'path';

/**
 * Middleware to check API key based on file type
 */
export function apiKeyChecker(req, res, next) {
  // Determine fileType based on request
  let fileType = null;

  if (req.fileType) {
    fileType = req.fileType;
  } else if (req.body.fileType) {
    fileType = req.body.fileType;
  } else if (req.file && req.file.originalname) {
    fileType = path.extname(req.file.originalname).slice(1);
  }

  if (!requiresApiKey(fileType)) {
    return next();
  }

  const apiKey = req.headers['x-api-key'];

  if (!apiKey) {
    return next(new AppError('API key is required for audio/video conversion', 401));
  }

  if (!apiKey.startsWith('sk-')) {
    return next(new AppError('Invalid API key format', 401));
  }

  next();
}

```

## routes/utils/categoryDetector.js

```js
// routes/convert/utils/categoryDetector.js

/**
 * Utility function to determine if a file type requires an API key
 */
export function requiresApiKey(fileType) {
    if (!fileType) return false;
    const API_REQUIRED_TYPES = ['mp3', 'wav', 'ogg', 'mp4', 'mov', 'avi', 'webm'];
    return API_REQUIRED_TYPES.includes(fileType.toLowerCase());
  }
  
  /**
 * Determines the category based on the item type or file extension
 */
export function determineCategory(type, fileType) {
    if (type === 'url' || type === 'parenturl' || type === 'youtube') return 'web';
  
    const dataTypes = ['csv', 'xls', 'xlsx', 'json'];
    const multimediaTypes = ['mp3', 'wav', 'ogg', 'mp4', 'mov', 'avi', 'webm'];
    const textTypes = ['txt', 'doc', 'docx', 'pdf'];
  
    if (dataTypes.includes(fileType)) return 'data';
    if (multimediaTypes.includes(fileType)) return 'multimedia';
    if (textTypes.includes(fileType)) return 'text';
    return 'others'; // For any other types
  }
  
```

## routes/utils/youtubeUtils.js

```js
// routes/utils/youtubeUtils.js

/**
 * Extracts YouTube Video ID from URL
 * @param {string} url - The YouTube video URL
 * @returns {string} - The extracted video ID or 'unknown' if not found
 */
export function extractVideoId(url) {
    const regex = /(?:https?:\/\/)?(?:www\.)?(?:youtube\.com\/(?:watch\?v=|embed\/)|youtu\.be\/)([a-zA-Z0-9_-]{11})/;
    const match = url.match(regex);
    return match ? match[1] : 'unknown';
  }
  
  /**
   * Formats timestamp from seconds to HH:MM:SS
   * @param {number} seconds - The time in seconds
   * @returns {string} - Formatted timestamp
   */
  export function formatTimestamp(seconds) {
    const date = new Date(0);
    date.setSeconds(seconds);
    return date.toISOString().substr(11, 8);
  }
  
  /**
   * Extracts YouTube video metadata (only title) using Puppeteer
   * @param {puppeteer.Page} page - The Puppeteer page instance
   * @returns {Promise<{ title: string }>} - The extracted metadata
   */

    export async function extractYoutubeMetadata(page) {
        try {
        console.log('Waiting for YouTube title element...');
        
        // Updated selector based on the new DOM structure
        await page.waitForSelector('ytd-watch-metadata yt-formatted-string.style-scope', {
            timeout: 30000,
            visible: true,
        });
    
        // Extract the title using Puppeteer
        const metadata = await page.evaluate(() => {
            // Adjust the selector if needed
            const titleElement = document.querySelector('ytd-watch-metadata yt-formatted-string.style-scope');
            const title = titleElement ? titleElement.textContent.trim() : 'Untitled Video';
            return { title };
        });
    
        console.log('Extracted metadata:', {
            titleLength: metadata.title.length,
        });
    
        return metadata;
        } catch (error) {
        console.error('Failed to extract metadata:', error);
        return {
            title: 'Untitled Video',
        };
        }
    }
    
```

## routes/utils/zipProcessor.js

```js
// routes/convert/utils/zipProcessor.js

import JSZip from 'jszip';
import sanitizeFilename from 'sanitize-filename';
import path from 'path';
import { determineCategory } from './categoryDetector.js';
import { AppError } from '../../utils/errorHandler.js';
import { textConverterFactory } from '../../services/converter/textConverterFactory.js';

/**
 * Handles the conversion of a single item.
 * @param {string} type - The type of content (e.g., 'youtube', 'file', etc.)
 * @param {string|Buffer|Object} content - The content to convert
 * @param {string} name - The name of the item
 * @param {string} apiKey - The API key for authenticated services
 * @returns {Promise<Object>} - The result of the conversion
 */
// routes/convert/utils/zipProcessor.js

// routes/convert/utils/zipProcessor.js

export async function handleConversion(type, content, name, apiKey) {
    try {
      console.log(`Handling conversion for type: ${type}, name: ${name}`);
  
      const conversionResult = await textConverterFactory.convertToMarkdown(
        type,
        content,
        name,
        apiKey
      );
  
      console.log(`Conversion result for ${name}:`, conversionResult);
  
      // Ensure 'type' is always present
      if (!conversionResult.type) {
        conversionResult.type = type;
      }
  
      // Set 'name' and 'success'
      conversionResult.name = name;
      if (conversionResult.success === undefined) {
        conversionResult.success = true;
      }
  
      // Set 'originalUrl' if applicable
      if (type === 'url' || type === 'parenturl' || type === 'youtube') {
        conversionResult.originalUrl = content;
      }
  
      return conversionResult;
    } catch (error) {
      console.error(`Conversion error for ${name}:`, error);
      return {
        success: false,
        type, // Ensure 'type' is included even on error
        name,
        error: error.message,
      };
    }
  }
  
  

/**
 * Creates a structured ZIP file from multiple converted items
 */
export async function createBatchZip(items) {
  console.log('Starting ZIP creation with items:', items);
  const zip = new JSZip();

  // Initialize top-level folder references
  const topLevelFolders = {
    data: zip.folder('data'),
    multimedia: zip.folder('multimedia'),
    text: zip.folder('text'),
    web: zip.folder('web'),
    errors: zip.folder('errors'), // Ensure errors folder exists
  };

  // Process each converted item
  for (const item of items) {
    try {
      // Check if 'type' exists
      if (!item.type) {
        throw new Error(`Item "${item.name}" is missing the 'type' property.`);
      }

      console.log(`Processing item: ${item.name} of type: ${item.type}`);

      if (!item.success) {
        // Handle failed conversions
        console.log(`Adding error file for: ${item.name}`);
        topLevelFolders.errors.file(
          `${sanitizeFilename(item.name || 'unknown')}_error.md`,
          `# Conversion Error\n\n**Error:** ${item.error}\n**Time:** ${new Date().toISOString()}`
        );
        continue;
      }

      // Determine the category
      const category = item.category || determineCategory(item.type, item.fileType);
      console.log(`Determined category: ${category} for item: ${item.name}`);

      if (category === 'others') {
        // Optionally, handle or skip items with 'others' category
        console.warn(`Skipping item with 'others' category: ${item.name}`);
        continue;
      }

      const topLevelFolder = topLevelFolders[category];
      console.log(`Adding content to category folder: ${category}`);

      switch (item.type.toLowerCase()) {
        case 'file':
          await processFileContent(item, topLevelFolder);
          break;
        case 'url':
          await processUrlContent(item, topLevelFolder);
          break;
        case 'parenturl':
          await processParentUrlContent(item, topLevelFolder);
          break;
        case 'youtube':
          await processYoutubeContent(item, topLevelFolder);
          break;
        default:
          console.warn(`Unknown type: ${item.type}`);
      }
    } catch (error) {
      console.error(`Error processing item in ZIP: ${error.message}`);
      // Optionally, add to errors folder
      topLevelFolders.errors.file(
        `${sanitizeFilename(item.name || 'unknown')}_zip_error.md`,
        `# ZIP Processing Error\n\n**Error:** ${error.message}\n**Item:** ${item.name}\n**Time:** ${new Date().toISOString()}`
      );
    }
  }

  // Add conversion summary if any successful items exist
  if (items.some((item) => item.success)) {
    console.log('Adding summary.md to ZIP');
    zip.file('summary.md', generateSummary(items));
  }

  const zipBuffer = await zip.generateAsync({ type: 'nodebuffer' });
  console.log('ZIP creation completed');

  return zipBuffer;
}

/**
 * Processes YouTube content for ZIP
 */
export async function processYoutubeContent(item, folder) {
  console.log(`Processing YouTube content for: ${item.name}`);
  // Add main Markdown file
  const safeFilename = sanitizeFilename(`${item.name}.md`);
  folder.file(safeFilename, item.content);
  console.log(`Added Markdown file: ${safeFilename}`);

  // If the converter includes images or other assets, add them here
  if (item.images?.length) {
    const assetsFolder = folder.folder('assets');
    console.log(`Adding ${item.images.length} images to assets`);
    for (const image of item.images) {
      if (image.data && image.name) {
        const safeImageName = sanitizeFilename(path.basename(image.name));
        assetsFolder.file(safeImageName, image.data, { base64: true });
        console.log(`Added image: ${safeImageName}`);
      }
    }
  }
}

/**
 * Generates a summary markdown file for the batch conversion
 */
export function generateSummary(items) {
  console.log('Generating conversion summary');
  const successful = items.filter((i) => i.success);
  const failed = items.filter((i) => !i.success);

  return [
    '# Conversion Summary',
    '',
    `Generated: ${new Date().toISOString()}`,
    '',
    '## Statistics',
    `- Total Items: ${items.length}`,
    `- Successful: ${successful.length}`,
    `- Failed: ${failed.length}`,
    '',
    '## Successful Conversions',
    ...successful.map(
      (item) =>
        `- **${item.name}** (${item.type})${
          item.images?.length ? ` - ${item.images.length} image(s)` : ''
        }`
    ),
    '',
    failed.length
      ? [
          '## Failed Conversions',
          ...failed.map((item) => `- **${item.name}**: ${item.error}`),
        ].join('\n')
      : '',
  ]
    .filter(Boolean)
    .join('\n');
}

/**
 * Processes file content for ZIP
 */
async function processFileContent(item, folder) {
  console.log(`Processing file content for: ${item.name}`);
  // Add main content
  folder.file(sanitizeFilename(item.name), item.content);
  console.log(`Added file: ${sanitizeFilename(item.name)}`);

  // Add images if present
  if (item.images?.length) {
    // Ensure assets folder is created only once per category
    const assetsFolder = folder.folder('assets');
    console.log(`Adding ${item.images.length} images to assets`);
    for (const image of item.images) {
      if (image.data && image.name) {
        // Use only the base filename to prevent double nesting
        const safeImageName = sanitizeFilename(path.basename(image.name));
        assetsFolder.file(safeImageName, image.data, { base64: true });
        console.log(`Added image: ${safeImageName}`);
      }
    }
  }
}

/**
 * Processes URL content for ZIP
 */
/**
 * Processes URL content for ZIP
 */
export async function processUrlContent(item, folder) {
    console.log(`Processing URL content for: ${item.name}`);
    const urlToUse = item.originalUrl || `https://${item.name}`;
    const siteName = sanitizeFilename(new URL(urlToUse).hostname);
  
    // Create a folder for the website under the 'web' top-level folder
    const siteFolder = folder.folder(siteName);
    console.log(`Created site folder: ${siteName}`);
  
    // Add index.md
    siteFolder.file('index.md', item.content);
    console.log(`Added index.md to ${siteName}`);
  
    // Add images to assets folder if present
    if (item.images?.length) {
      const assetsFolder = siteFolder.folder('assets');
      console.log(`Adding ${item.images.length} images to assets in ${siteName}`);
      for (const image of item.images) {
        if (image.data && image.name) {
          const safeImageName = sanitizeFilename(path.basename(image.name));
          assetsFolder.file(safeImageName, image.data, { base64: true });
          console.log(`Added image: ${safeImageName} to ${siteName}/assets`);
        }
      }
    }
  }  

/**
 * Processes Parent URL content for ZIP
 */
async function processParentUrlContent(item, folder) {
  console.log(`Processing Parent URL content for: ${item.name}`);
  const siteName = sanitizeFilename(new URL(item.url).hostname);

  // Create a folder for the website under the 'web' top-level folder
  const siteFolder = folder.folder(siteName);
  console.log(`Created site folder: ${siteName}`);

  // Add index.md
  siteFolder.file('index.md', item.content);
  console.log(`Added index.md to ${siteName}`);

  // Add page files directly under the site folder without 'pages/' prefix
  if (item.files) {
    for (const file of item.files) {
      const fileName = sanitizeFilename(path.basename(file.name));
      siteFolder.file(fileName, file.content);
      console.log(`Added page file: ${fileName} to ${siteName}`);
    }
  }

  // Add images to assets folder if present
  if (item.images?.length) {
    const assetsFolder = siteFolder.folder('assets');
    console.log(`Adding ${item.images.length} images to assets in ${siteName}`);
    for (const image of item.images) {
      if (image.data && image.name) {
        const safeImageName = sanitizeFilename(path.basename(image.name));
        assetsFolder.file(safeImageName, image.data, { base64: true });
        console.log(`Added image: ${safeImageName} to ${siteName}/assets`);
      }
    }
  }
}

```

## server.js

```js
// server.js

import express from 'express';
import cors from 'cors';
import helmet from 'helmet';
import dotenv from 'dotenv';
import rateLimit from 'express-rate-limit';
import { config } from './config/default.js';
import convertRoutes from './routes/index.js';
import proxyRoutes from './routes/proxyRoutes.js';
import { errorHandler } from './utils/errorHandler.js';

// Load environment variables from .env file
dotenv.config();

const app = express();
const PORT = process.env.PORT || config.server.port || 3000;
const ENV = process.env.NODE_ENV || config.server.env || 'development';

/**
 * Middleware Configuration
 */

// Security headers
app.use(helmet());

// Body parsers (ensure these are before your routes)
app.use(express.json());
app.use(express.urlencoded({ extended: true }));

// CORS Configuration
app.use(cors({
  origin: ['http://localhost:5176', 'https://your-frontend-domain.com'], // Update as needed
  methods: ['GET', 'POST', 'OPTIONS'],
  allowedHeaders: ['Content-Type', 'Authorization', 'x-api-key'],
  credentials: true,
}));

// Handle preflight requests globally
app.options('*', cors());

// Global Rate Limiter (applied after body parsers and CORS)
const globalLimiter = rateLimit({
  windowMs: 60 * 1000, // 1 minute
  max: config.security.globalRateLimitPerMinute || 100, // Default global rate limit
  message: 'Too many requests from this IP, please try again later.',
  standardHeaders: true,
  legacyHeaders: false,
});

app.use(globalLimiter);

// API Routes with versioning
app.use('/api/v1/convert', convertRoutes);
app.use('/api/v1/proxy', proxyRoutes);

// Health check route (moved here from convert routes)
app.get('/health', (req, res) => {
  res.status(200).json({
    status: 'OK',
    timestamp: new Date().toISOString(),
    allowedTypes: config.conversion.allowedFileTypes,
    version: process.env.npm_package_version || '1.0.0'
  });
});

// Root route
app.get('/', (req, res) => {
  res.send('Welcome to the Conversion API!');
});

// Error handling middleware (should be after all routes)
app.use(errorHandler);

// Start server
app.listen(PORT, () => {
  console.log(`Server is running on port ${PORT}`);
  console.log(`Environment: ${ENV}`);
  console.log(`Allowed file types: ${config.conversion.allowedFileTypes.join(', ')}`);
});

export default app;

```

## services/converter/data/csvConverter.js

```js
// services/converter/data/csvConverter.js

import { parse } from 'csv-parse/sync';

/**
 * Converts a CSV buffer or string to Markdown format.
 * @param {Buffer|string} input - The CSV content as a buffer or string.
 * @param {string} originalName - Original filename for context.
 * @param {string} [apiKey] - API key if needed.
 * @returns {Promise<{ content: string, images: Array }>} - Converted content and images.
 */
export async function convertCsvToMarkdown(input, originalName, apiKey) {
  try {
    // Convert buffer to string if necessary
    const csvContent = Buffer.isBuffer(input) ? input.toString('utf-8') : input;

    // Parse the CSV data
    const records = parse(csvContent, {
      columns: true,
      skip_empty_lines: true
    });

    if (records.length === 0) {
      return { content: "The CSV file is empty.", images: [] };
    }

    // Get headers
    const headers = Object.keys(records[0]);

    // Create Markdown table
    let markdownTable = `| ${headers.join(' | ')} |\n`;
    markdownTable += `| ${headers.map(() => '---').join(' | ')} |\n`;

    // Add data rows
    records.forEach(record => {
      markdownTable += `| ${headers.map(header => record[header] || '').join(' | ')} |\n`;
    });

    return { content: markdownTable, images: [] };
  } catch (error) {
    console.error('Error converting CSV to Markdown:', error);
    throw error;
  }
}

```

## services/converter/data/jsonConverter.js

```js
// services/converter/data/jsonConverter.js

/**
 * Converts a JSON buffer or string to Markdown format.
 * @param {Buffer|string} input - The JSON content as a buffer or string.
 * @param {string} originalName - Original filename for context.
 * @param {string} [apiKey] - API key if needed.
 * @returns {Promise<{ content: string, images: Array }>} - Converted content and images.
 */
export async function convertJsonToMarkdown(input, originalName, apiKey) {
  try {
    // Convert buffer to string if necessary
    const jsonContent = Buffer.isBuffer(input) ? input.toString('utf-8') : input;

    // Parse the JSON data
    const jsonData = JSON.parse(jsonContent);

    // Convert JSON to Markdown
    const markdownContent = jsonToMarkdown(jsonData);

    return { content: markdownContent, images: [] };
  } catch (error) {
    console.error('Error converting JSON to Markdown:', error);
    throw error;
  }
}

/**
 * Recursively converts JSON data to Markdown format.
 * @param {any} data - The JSON data to convert.
 * @param {number} depth - The current depth for nested structures.
 * @returns {string} - The converted Markdown string.
 */
function jsonToMarkdown(data, depth = 0) {
  const indent = '  '.repeat(depth);

  if (Array.isArray(data)) {
    return data.map(item => `${indent}- ${jsonToMarkdown(item, depth + 1)}`).join('\n');
  } else if (typeof data === 'object' && data !== null) {
    return Object.entries(data)
      .map(([key, value]) => `${indent}- **${key}**: ${jsonToMarkdown(value, depth + 1)}`)
      .join('\n');
  } else {
    return String(data);
  }
}

```

## services/converter/data/xlsxConverter.js

```js
// services/converter/data/xlsxConverter.js

import xlsx from 'xlsx';

/**
 * Converts an XLSX buffer or string to Markdown format.
 * @param {Buffer|string} input - The XLSX content as a buffer or string (file path not used).
 * @param {string} originalName - Original filename for context.
 * @param {string} [apiKey] - API key if needed.
 * @returns {Promise<{ content: string, images: Array }>} - Converted content and images.
 */
export async function convertXlsxToMarkdown(input, originalName, apiKey) {
  try {
    let workbook;
    if (Buffer.isBuffer(input)) {
      workbook = xlsx.read(input, { type: 'buffer' });
    } else {
      // If input is a string, assume it's a buffer represented as a string (unlikely)
      throw new Error('Invalid input type for XLSX converter. Expected a Buffer.');
    }

    // Convert each sheet to Markdown
    const markdownSheets = workbook.SheetNames.map(sheetName => {
      const sheet = workbook.Sheets[sheetName];
      const jsonData = xlsx.utils.sheet_to_json(sheet, { header: 1 });
      
      if (jsonData.length === 0) {
        return `## ${sheetName}\n\nThis sheet is empty.`;
      }

      const headers = jsonData[0];
      let markdownTable = `## ${sheetName}\n\n`;
      markdownTable += `| ${headers.join(' | ')} |\n`;
      markdownTable += `| ${headers.map(() => '---').join(' | ')} |\n`;

      jsonData.slice(1).forEach(row => {
        markdownTable += `| ${row.map(cell => cell !== null && cell !== undefined ? cell : '').join(' | ')} |\n`;
      });

      return markdownTable;
    });

    // Combine all sheets
    const combinedMarkdown = markdownSheets.join('\n\n');
    
    return { content: combinedMarkdown, images: [] };
  } catch (error) {
    console.error('Error converting XLSX to Markdown:', error);
    throw error;
  }
}

```

## services/converter/data/yamlConverter.js

```js
// services/converter/data/yamlConverter.js

import yaml from 'js-yaml';

/**
 * Converts a YAML buffer or string to Markdown format.
 * @param {Buffer|string} input - The YAML content as a buffer or string.
 * @param {string} originalName - Original filename for context.
 * @param {string} [apiKey] - API key if needed.
 * @returns {Promise<{ content: string, images: Array }>} - Converted content and images.
 */
export async function convertYamlToMarkdown(input, originalName, apiKey) {
  try {
    // Convert buffer to string if necessary
    const yamlContent = Buffer.isBuffer(input) ? input.toString('utf-8') : input;

    // Parse the YAML data
    const yamlData = yaml.load(yamlContent);

    // Reuse the JSON to Markdown conversion logic
    const markdownContent = jsonToMarkdown(yamlData);

    return { content: markdownContent, images: [] };
  } catch (error) {
    console.error('Error converting YAML to Markdown:', error);
    throw error;
  }
}

/**
 * Recursively converts JSON/YAML data to Markdown format.
 * @param {any} data - The data to convert.
 * @param {number} depth - The current depth for nested structures.
 * @returns {string} - The converted Markdown string.
 */
function jsonToMarkdown(data, depth = 0) {
  const indent = '  '.repeat(depth);

  if (Array.isArray(data)) {
    return data.map(item => `${indent}- ${jsonToMarkdown(item, depth + 1)}`).join('\n');
  } else if (typeof data === 'object' && data !== null) {
    return Object.entries(data)
      .map(([key, value]) => `${indent}- **${key}**: ${jsonToMarkdown(value, depth + 1)}`)
      .join('\n');
  } else {
    return String(data);
  }
}

```

## services/converter/multimedia/audioconverter.js

```js
// audioConverter.js
import fs from 'fs/promises';
import { openaiProxy } from '../../openaiProxy.js';
import { generateMarkdown } from './markdownGenerator.js';

const MAX_FILE_SIZE = 25 * 1024 * 1024; // 25 MB (OpenAI's current limit)

export async function convertAudioToMarkdown(filePath, apiKey) {
  try {
    // Check file size
    const stats = await fs.stat(filePath);
    if (stats.size > MAX_FILE_SIZE) {
      throw new Error(`File size exceeds the maximum limit of ${MAX_FILE_SIZE / (1024 * 1024)} MB`);
    }

    // Read file
    const fileBuffer = await fs.readFile(filePath);

    // Prepare form data for OpenAI API
    const formData = new FormData();
    formData.append('file', new Blob([fileBuffer]), 'audio.mp3');
    formData.append('model', 'whisper-1');

    // Call OpenAI Whisper API via proxy
    const transcriptionResponse = await openaiProxy.makeRequest(
      apiKey,
      'audio/transcriptions',
      formData
    );

    if (!transcriptionResponse || !transcriptionResponse.text) {
      throw new Error('Failed to transcribe audio');
    }

    // Generate Markdown
    const markdown = generateMarkdown({
      title: 'Audio Transcription',
      content: transcriptionResponse.text
    });

    return markdown;
  } catch (error) {
    console.error('Error in audio conversion:', error);
    throw error;
  }
}

// Helper function to format timestamps (if provided by the API)
function formatTimestamp(seconds) {
  const minutes = Math.floor(seconds / 60);
  const remainingSeconds = Math.floor(seconds % 60);
  return `${minutes.toString().padStart(2, '0')}:${remainingSeconds.toString().padStart(2, '0')}`;
}
```

## services/converter/multimedia/videoConverter.js

```js
// services/converter/multimedia/videoConverter.js

import { transcriber } from '../transcriber.js';
import { generateMarkdown } from '../../utils/markdownGenerator.js';

export async function convertVideoToMarkdown(filePath, apiKey) {
  try {
    // Transcribe video to text
    const transcription = await transcriber.transcribe(filePath, apiKey);

    // Generate Markdown
    const markdown = generateMarkdown({
      title: `Video Transcription: ${path.basename(filePath)}`,
      content: transcription,
    });

    return markdown;
  } catch (error) {
    console.error('Error converting video to Markdown:', error);
    throw error;
  }
}

```

## services/converter/text/docxConverter.js

```js
// services/converter/text/docxConverter.js

import mammoth from 'mammoth';
import path from 'path';
import { v4 as uuidv4 } from 'uuid';

/**
 * Converts a DOCX buffer to Markdown format while properly handling images
 * @param {Buffer} buffer - The DOCX file buffer
 * @param {string} originalName - Original filename for context
 * @returns {Promise<{content: string, images: Array}>} Markdown content and images
 */
export async function convertDocxToMarkdown(buffer, originalName) {
  try {
    console.log('Starting DOCX conversion:', originalName);
    
    // Store extracted images
    const images = [];
    
    // Get base name for folder structure
    const baseName = path.basename(originalName, '.docx');
    
    // Configure conversion options
    const options = {
      convertImage: mammoth.images.imgElement(async (image) => {
        try {
          // Get image buffer and info
          const imageBuffer = await image.read();
          const extension = image.contentType.split('/')[1];
          const imageName = `${baseName}-${uuidv4().slice(0, 8)}.${extension}`;
          
          // Store image info and data
          images.push({
            name: imageName,
            data: imageBuffer.toString('base64'),
            type: image.contentType,
            path: `attachments/${baseName}/${imageName}`
          });
          
          // Return markdown image reference
          return {
            src: `attachments/${baseName}/${imageName}`
          };
        } catch (error) {
          console.error('Error processing image:', error);
          return { src: 'error-processing-image' };
        }
      })
    };

    // Correctly pass the buffer directly
    const result = await mammoth.convertToMarkdown(buffer, options);

    // Log any warnings
    if (result.messages.length > 0) {
      console.log('Conversion warnings:', result.messages);
    }

    // Create the frontmatter and content
    const markdown = [
      '---',
      `title: ${baseName}`,
      `attachmentFolder: attachments/${baseName}`,
      'created: ' + new Date().toISOString(),
      '---',
      '',
      result.value
    ].join('\n');

    // Return both markdown and images with proper paths
    return {
      content: markdown,
      images: images
    };

  } catch (error) {
    console.error('Error converting DOCX:', error);
    throw error;
  }
}

```

## services/converter/text/epubConverter.js

```js
// services/converter/text/epubConverter.js

import EPub from 'epub';
import TurndownService from 'turndown';
import { promisify } from 'util';
import tmp from 'tmp-promise';
import fs from 'fs/promises';
import path from 'path';

/**
 * Converts an EPUB buffer to Markdown format, extracting text and images.
 * @param {Buffer} input - The EPUB file buffer.
 * @param {string} originalName - Original filename for context.
 * @param {string} [apiKey] - API key if needed.
 * @returns {Promise<{ content: string, images: Array }>} - Converted content and images.
 */
export async function convertEpubToMarkdown(input, originalName, apiKey) {
  let tempFile;
  try {
    // Create a temporary file to store the EPUB buffer
    tempFile = await tmp.file({ postfix: '.epub' });
    const tempFilePath = tempFile.path;

    // Write buffer to the temporary file
    await fs.writeFile(tempFilePath, input);

    // Initialize EPub with the temporary file path
    const epub = new EPub(tempFilePath);
    const openEpub = promisify(epub.open.bind(epub));
    const getChapter = promisify(epub.getChapter.bind(epub));
    const getImage = promisify(epub.getImage.bind(epub));

    await openEpub();

    const turndownService = new TurndownService({
      headingStyle: 'atx',
      codeBlockStyle: 'fenced'
    });

    // Metadata
    let markdown = `# ${epub.metadata.title || 'Untitled EPUB'}\n\n`;
    markdown += `**Author:** ${epub.metadata.creator || 'Unknown'}\n\n`;
    if (epub.metadata.description) {
      markdown += `**Description:** ${epub.metadata.description}\n\n`;
    }
    markdown += `**Publication Date:** ${epub.metadata.date || 'Unknown'}\n\n`;

    // Table of Contents
    markdown += `## Table of Contents\n\n`;
    epub.flow.forEach((chapter, index) => {
      markdown += `${index + 1}. [${chapter.title}](#chapter-${index + 1})\n`;
    });
    markdown += '\n';

    // Process chapters
    const baseName = path.basename(originalName || 'untitled', path.extname(originalName || ''));
    const images = [];

    for (let i = 0; i < epub.flow.length; i++) {
      const chapter = epub.flow[i];
      const chapterContent = await getChapter(chapter.id);
      markdown += `## Chapter ${i + 1}: ${chapter.title}\n\n`;

      // Convert HTML to Markdown
      const markdownContent = turndownService.turndown(chapterContent);
      markdown += markdownContent + '\n\n';
    }

    // Extract images from the EPUB manifest
    const imagePromises = Object.values(epub.manifest)
      .filter(item => item.mediaType.startsWith('image/'))
      .map(async (item) => {
        const imageBuffer = await getImage(item.id);
        const imageName = path.basename(item.href);
        const imageData = imageBuffer.toString('base64');
        const imageType = item.mediaType;

        images.push({
          name: imageName,
          data: imageData,
          type: imageType,
          path: `attachments/${baseName}/${imageName}`
        });

        return {
          originalPath: item.href,
          newPath: `attachments/${baseName}/${imageName}`
        };
      });

    const imageMappings = await Promise.all(imagePromises);

    // Replace image sources in markdown with the new attachment paths
    imageMappings.forEach(mapping => {
      const originalHref = mapping.originalPath;
      const newPath = mapping.newPath;

      // EPUB image hrefs may have internal references, e.g., "../Images/image1.png"
      // Normalize the originalHref by removing directory paths
      const normalizedHref = path.basename(originalHref);

      // Replace all occurrences of the original image path with the new path
      const regex = new RegExp(`\\(.*${normalizedHref}\\)`, 'g');
      markdown = markdown.replace(regex, `(${newPath})`);
    });

    return {
      content: markdown,
      images: images
    };
  } catch (error) {
    console.error('Error converting EPUB to Markdown:', error);
    throw error;
  } finally {
    // Clean up the temporary file
    if (tempFile) {
      await tempFile.cleanup();
    }
  }
}

```

## services/converter/text/odtConverter.js

```js
// services/converter/text/odtConverter.js

import JSZip from 'jszip';
import xml2js from 'xml2js';
import TurndownService from 'turndown';
import path from 'path';

/**
 * Converts an ODT buffer to Markdown format, extracting text and images.
 * @param {Buffer} input - The ODT file buffer.
 * @param {string} originalName - Original filename for context.
 * @param {string} [apiKey] - API key if needed.
 * @returns {Promise<{ content: string, images: Array }>} - Converted content and images.
 */
export async function convertOdtToMarkdown(input, originalName, apiKey) {
  try {
    const zip = await JSZip.loadAsync(input);

    // Extract content.xml
    const contentXml = await zip.file('content.xml').async('string');

    // Extract images from 'Pictures/' folder
    const imagesFolder = zip.folder('Pictures');
    const images = [];

    if (imagesFolder) {
      const imageFiles = Object.keys(imagesFolder.files);
      for (const imageFileName of imageFiles) {
        const file = imagesFolder.file(imageFileName);
        if (file) {
          const imageBuffer = await file.async('base64');
          const imageType = file.name.split('.').pop().toLowerCase();
          images.push({
            name: file.name,
            data: imageBuffer,
            type: `image/${imageType}`,
            path: `attachments/${path.basename(originalName, path.extname(originalName))}/${file.name}`
          });
        }
      }
    }

    // Parse content.xml
    const parser = new xml2js.Parser();
    const parsedXml = await parser.parseStringPromise(contentXml);

    // Extract text and image references
    const body = parsedXml['office:document-content']['office:body'][0]['office:text'][0];
    const textContent = extractTextFromODT(parsedXml);

    // Initialize TurndownService for markdown conversion
    const turndownService = new TurndownService({
      headingStyle: 'atx',
      codeBlockStyle: 'fenced'
    });

    // Convert HTML to Markdown
    const markdownContent = turndownService.turndown(textContent);

    // Build markdown with metadata and table of contents
    let markdown = `# ${path.basename(originalName, path.extname(originalName))}\n\n`;
    markdown += `**Author:** ${parsedXml['office:document-content']['office:meta'][0]['dc:creator'] ? parsedXml['office:document-content']['office:meta'][0]['dc:creator'][0] : 'Unknown'}\n\n`;
    markdown += `**Description:** ${parsedXml['office:document-content']['office:meta'][0]['dc:description'] ? parsedXml['office:document-content']['office:meta'][0]['dc:description'][0] : 'N/A'}\n\n`;
    markdown += `**Publication Date:** ${parsedXml['office:document-content']['office:meta'][0]['meta:creation-date'] ? parsedXml['office:document-content']['office:meta'][0]['meta:creation-date'][0] : 'Unknown'}\n\n`;

    // Table of Contents - optional, based on headings
    markdown += `## Table of Contents\n\n`;
    // Optionally parse headings from markdownContent
    const headings = markdownContent.match(/^#{1,6}\s.+$/gm);
    if (headings) {
      headings.forEach((heading, index) => {
        const title = heading.replace(/^#+\s/, '').trim();
        const slug = title.toLowerCase().replace(/[^\w]+/g, '-');
        markdown += `${index + 1}. [${title}](#${slug})\n`;
      });
    }
    markdown += '\n';

    // Append content
    markdown += markdownContent + '\n\n';

    return {
      content: markdown,
      images: images
    };
  } catch (error) {
    console.error('Error converting ODT to Markdown:', error);
    throw error;
  }
}

/**
 * Extracts text from parsed ODT XML.
 * @param {Object} parsedXml - Parsed XML object.
 * @returns {string} - Extracted text as HTML.
 */
function extractTextFromODT(parsedXml) {
  const body = parsedXml['office:document-content']['office:body'][0]['office:text'][0];
  let html = '';

  function traverse(element) {
    if (typeof element === 'string') {
      html += element;
    } else if (Array.isArray(element)) {
      element.forEach(traverse);
    } else if (typeof element === 'object') {
      for (const key in element) {
        const items = element[key];
        items.forEach(item => {
          switch (key) {
            case 'text:p':
              html += `<p>${processParagraph(item)}</p>`;
              break;
            case 'text:h':
              const level = parseInt(item.$['text:outline-level'], 10) || 1;
              html += `<h${level}>${processParagraph(item)}</h${level}>\n`;
              break;
            case 'draw:frame':
              // Handle images
              const imageHref = item['draw:image'][0].$['xlink:href']; // Corrected Syntax
              if (imageHref) {
                const href = imageHref.replace('#', '');
                html += `<img src="${href}" alt="Image"/>`;
              }
              break;
            default:
              traverse(item);
          }
        });
      }
    }
  }

  function processParagraph(paragraph) {
    let text = '';
    if (paragraph['text:span']) {
      paragraph['text:span'].forEach(span => {
        if (span['text:a']) {
          // Handle links
          const href = span['text:a'][0].$['xlink:href'] || '#'; // Corrected Syntax
          const spanText = span['_'] || '';
          text += `[${spanText}](${href})`;
        } else {
          text += span['_'] || '';
        }
      });
    }
    return text;
  }

  traverse(body);
  return html;
}

```

## services/converter/text/pdfConverter.js

```js
// services/converter/text/pdfConverter.js


import { fileURLToPath } from 'url';
import { dirname } from 'path';
import path from 'path';
import crypto from 'crypto';
import * as fs from 'fs/promises';
import { promisify } from 'util';
import { exec } from 'child_process';
import { v4 as uuidv4 } from 'uuid';
import pdfParse from 'pdf-parse';

const execAsync = promisify(exec);
const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

/**
 * Checks if a file exists
 * @param {string} path - Path to check
 * @returns {Promise<boolean>} True if file exists
 */
async function fileExists(path) {
  try {
    await fs.access(path);
    return true;
  } catch {
    return false;
  }
}

/**
 * Gets the poppler binary path based on the operating system
 * @returns {Promise<string>} Path to poppler binaries
 */
async function getPopplerPath() {
  if (process.platform === 'win32') {
    // Check common installation paths
    const possiblePaths = [
      'C:\\Program Files\\poppler\\Library\\bin',
      'C:\\Program Files\\poppler-23.11.0\\Library\\bin',
      'C:\\Program Files (x86)\\poppler\\Library\\bin',
      'C:\\poppler\\Library\\bin',
      process.env.POPPLER_PATH
    ].filter(Boolean);

    for (const binPath of possiblePaths) {
      if (!binPath) continue;
      
      const pdfimagesPath = path.join(binPath, 'pdfimages.exe');
      console.log('Checking poppler path:', pdfimagesPath);
      
      try {
        const exists = await fileExists(pdfimagesPath);
        if (exists) {
          console.log('Found poppler at:', binPath);
          return binPath;
        }
      } catch (error) {
        console.warn(`Failed to check path ${binPath}:`, error);
      }
    }
    
    throw new Error('Poppler not found. Please install poppler-utils and set POPPLER_PATH environment variable.');
  }
  
  return ''; // Unix systems typically have it in PATH
}

/**
 * Executes poppler command with proper path handling
 * @param {string} command - The command to execute
 * @returns {Promise<string>} Command output
 */
async function executePopplerCommand(command) {
  try {
    if (process.platform === 'win32') {
      const popplerPath = await getPopplerPath();
      // Add poppler path to command
      if (command.startsWith('pdfimages')) {
        command = command.replace('pdfimages', `"${path.join(popplerPath, 'pdfimages.exe')}"`);
      }
    }

    console.log('Executing command:', command);
    const { stdout, stderr } = await execAsync(command);
    
    if (stderr) {
      console.warn('Command stderr:', stderr);
    }
    
    return stdout;
  } catch (error) {
    console.error('Poppler command failed:', error);
    throw error;
  }
}

/**
 * Extracts images from PDF using poppler-utils with fallback
 * @param {string} pdfPath - Path to the PDF file
 * @param {string} originalName - Original filename
 * @returns {Promise<Array>} Array of image objects
 */
async function extractImages(pdfPath, originalName) {
  const tempDir = path.join(process.cwd(), 'temp', uuidv4());
  const imageRoot = path.join(tempDir, 'image');
  const images = [];
  const imageHashes = new Map();

  try {
    await fs.mkdir(tempDir, { recursive: true });

    try {
      // Use pdfimages for extraction
      const command = `pdfimages -all "${pdfPath}" "${imageRoot}"`;
      await executePopplerCommand(command);

      // Process extracted images
      const files = await fs.readdir(tempDir);
      const imageFiles = files.filter(f => /\.(jpg|jpeg|png|ppm|pbm)$/i.test(f));

      for (const imageFile of imageFiles) {
        const imagePath = path.join(tempDir, imageFile);
        const stats = await fs.stat(imagePath);

        // Skip tiny images (likely artifacts)
        if (stats.size < 5120) continue;

        // Calculate image hash
        const imageBuffer = await fs.readFile(imagePath);
        const hash = crypto.createHash('sha256').update(imageBuffer).digest('hex');

        // Check for duplicates
        if (imageHashes.has(hash)) continue;
        imageHashes.set(hash, true);

        const ext = path.extname(imageFile).slice(1);
        const baseName = path.basename(originalName, '.pdf');
        const newImageName = `${baseName}-image-${images.length + 1}.${ext}`;

        images.push({
          name: newImageName,
          data: imageBuffer.toString('base64'),
          type: `image/${ext}`,
          path: `attachments/${baseName}/${newImageName}`,
          hash: hash,
          size: stats.size
        });
      }

    } catch (error) {
      console.warn('Poppler extraction failed:', error);
      console.log('Attempting fallback image extraction...');
      return await extractImagesWithFallback(pdfPath, originalName);
    }

    return images;

  } catch (error) {
    console.error('Image extraction error:', error);
    return [];
  } finally {
    // Cleanup
    try {
      await fs.rm(tempDir, { recursive: true, force: true });
    } catch (error) {
      console.warn('Failed to cleanup temp directory:', error);
    }
  }
}

/**
 * Fallback image extraction using pdf-lib
 * @param {string} pdfPath - Path to the PDF file
 * @param {string} originalName - Original filename
 * @returns {Promise<Array>} Array of image objects
 */
async function extractImagesWithFallback(pdfPath, originalName) {
  try {
    const { PDFDocument } = await import('pdf-lib');
    const pdfBytes = await fs.readFile(pdfPath);
    const pdfDoc = await PDFDocument.load(pdfBytes);
    const images = [];
    const imageHashes = new Map();

    for (let i = 0; i < pdfDoc.getPageCount(); i++) {
      const page = pdfDoc.getPage(i);
      
      // Get page resources
      if (!page || !page.node) continue;
      
      const resources = page.node.Resources;
      if (!resources) continue;
      
      const xObjects = resources.lookup('XObject');
      if (!xObjects) continue;

      // Get all XObject names
      const xObjectKeys = xObjects.keys();

      for (const key of xObjectKeys) {
        const xObject = xObjects.lookup(key);
        
        // Check if it's an image
        if (!xObject || xObject.Subtype?.name !== 'Image') continue;

        try {
          const imageData = await xObject.getContents();
          if (!imageData || imageData.length < 5120) continue;

          const hash = crypto.createHash('sha256').update(imageData).digest('hex');
          if (imageHashes.has(hash)) continue;
          
          imageHashes.set(hash, true);

          // Determine format based on filter
          const filter = xObject.Filter?.name;
          const format = filter === 'DCTDecode' ? 'jpeg' : 'png';

          const baseName = path.basename(originalName, '.pdf');
          const imageName = `${baseName}-image-${i + 1}-${images.length + 1}.${format}`;

          images.push({
            name: imageName,
            data: imageData.toString('base64'),
            type: `image/${format}`,
            path: `attachments/${baseName}/${imageName}`,
            hash: hash,
            size: imageData.length,
            pageIndex: i
          });
        } catch (imageError) {
          console.warn(`Failed to extract image from page ${i}:`, imageError);
          continue;
        }
      }
    }

    return images;
  } catch (error) {
    console.error('Fallback image extraction failed:', error);
    return [];
  }
}

/**
 * Validates PDF input buffer
 * @param {Buffer} input - The input buffer to validate
 * @returns {boolean} True if input is a valid PDF
 */
export function validatePdfInput(input) {
  if (!input || !Buffer.isBuffer(input)) return false;
  
  // Check PDF magic number
  const header = input.slice(0, 5).toString();
  if (header !== '%PDF-') return false;

  // Check for EOF marker
  const trailer = input.slice(-6).toString();
  return trailer.includes('%%EOF');
}

/**
 * Converter configuration object
 */
export const pdfConverterConfig = {
  name: 'PDF Converter',
  version: '1.0.0',
  supportedExtensions: ['.pdf'],
  supportedMimeTypes: ['application/pdf'],
  maxSizeBytes: 100 * 1024 * 1024, // 100MB
  requiresPoppler: true,
  options: {
    imageQuality: 300,
    minImageSize: 5120, // 5KB
    debug: false,
    popplerPath: process.env.POPPLER_PATH
  }
};

/**
 * Main converter function that transforms PDF to Markdown with images
 * @param {Buffer} input - The PDF file buffer
 * @param {string} originalName - Original filename for context
 * @param {string} [apiKey] - Optional API key (not used for PDF conversion)
 * @returns {Promise<{content: string, images: Array}>} - Converted content and images
 */
export async function convertPdfToMarkdown(input, originalName, apiKey) {
  if (!validatePdfInput(input)) {
    throw new Error('Invalid PDF input');
  }

  const tempDir = path.join(process.cwd(), 'temp', uuidv4());
  const tempPdfPath = path.join(tempDir, 'input.pdf');
  
  try {
    await fs.mkdir(tempDir, { recursive: true });
    await fs.writeFile(tempPdfPath, input);
    
    // Extract text
    const pdfData = await pdfParse(input);
    
    // Extract images
    const images = await extractImages(tempPdfPath, originalName);
    
    // Generate markdown content
    const baseName = path.basename(originalName, '.pdf');
    
    // Create frontmatter
    const frontmatter = [
      '---',
      `title: ${baseName}`,
      `created: ${new Date().toISOString()}`,
      `source: ${originalName}`,
      `type: pdf`,
      `pages: ${pdfData.numpages}`,
      `image_count: ${images.length}`,
      '---',
      ''
    ].join('\n');

    // Process text content
    let textContent = pdfData.text
      .replace(/\f/g, '\n\n---\n\n')
      .replace(/(\r\n|\r|\n){3,}/g, '\n\n')
      .replace(/[^\S\r\n]+/g, ' ')
      .trim();

    // Add image references
    let imageSection = '';
    if (images.length > 0) {
      imageSection = '\n\n## Extracted Images\n\n' +
        images.map(img => 
          `![${img.name}](${img.path})`
        ).join('\n\n');
    }

    const markdownContent = [
      frontmatter,
      '## Content\n',
      textContent,
      imageSection
    ].join('\n');

    return {
      content: markdownContent,
      images: images
    };

  } catch (error) {
    console.error('Error converting PDF:', error);
    throw error;
  } finally {
    // Cleanup
    try {
      await fs.rm(tempDir, { recursive: true, force: true });
    } catch (error) {
      console.warn('Failed to cleanup temp directory:', error);
    }
  }
}

export default {
  convert: convertPdfToMarkdown,
  validate: validatePdfInput,
  config: pdfConverterConfig
};
```

## services/converter/text/pptxConverter.js

```js
// services/converter/text/pptxConverter.js

import JSZip from 'jszip';
import TurndownService from 'turndown';
import path from 'path';

/**
 * Converts a PPTX buffer to Markdown format, extracting text and images.
 * @param {Buffer} input - The PPTX file buffer.
 * @param {string} originalName - Original filename for context.
 * @param {string} [apiKey] - API key if needed.
 * @returns {Promise<{ content: string, images: Array }>} - Converted content and images.
 * @throws {Error} - If conversion fails.
 */
export async function convertPptxToMarkdown(input, originalName, apiKey) {
  try {
    const zip = await JSZip.loadAsync(input);
    const slides = [];

    // Extract all slide XML files
    const slideFiles = Object.keys(zip.files).filter(fileName => /^ppt\/slides\/slide\d+\.xml$/.test(fileName));

    // Extract images from 'ppt/media/' folder
    const mediaFolder = zip.folder('ppt/media');
    const images = [];

    if (mediaFolder) {
      const imageFiles = Object.keys(mediaFolder.files);
      for (const imageFileName of imageFiles) {
        const file = mediaFolder.file(imageFileName);
        if (file) {
          const imageBuffer = await file.async('base64');
          const imageType = imageFileName.split('.').pop().toLowerCase();
          images.push({
            name: file.name,
            data: imageBuffer,
            type: `image/${imageType}`,
            path: `attachments/${path.basename(originalName, path.extname(originalName))}/${file.name}`
          });
        }
      }
    }

    const turndownService = new TurndownService({
      headingStyle: 'atx',
      codeBlockStyle: 'fenced'
    });

    let markdown = `# ${path.basename(originalName, path.extname(originalName))}\n\n`;
    markdown += `**Converted on:** ${new Date().toISOString()}\n\n`;

    // Process each slide
    for (const slideFileName of slideFiles) {
      const slideXml = await zip.file(slideFileName).async('string');
      const slideContent = extractTextFromPPTX(slideXml);

      markdown += `## Slide ${extractSlideNumber(slideFileName)}\n\n`;
      markdown += turndownService.turndown(slideContent) + '\n\n';
    }

    // Append image references to markdown (optional)
    images.forEach((image, index) => {
      markdown += `![Image ${index + 1}](attachments/${path.basename(originalName, path.extname(originalName))}/${image.name})\n\n`;
    });

    return {
      content: markdown,
      images: images
    };
  } catch (error) {
    console.error('Error converting PPTX to Markdown:', error);
    throw error;
  }
}

/**
 * Extracts text content from PPTX slide XML.
 * @param {string} slideXml - The slide XML content.
 * @returns {string} - Extracted text as HTML.
 */
function extractTextFromPPTX(slideXml) {
  // Simple regex-based extraction of text within <a:t> tags
  const textMatches = slideXml.match(/<a:t>(.*?)<\/a:t>/g);
  const texts = textMatches ? textMatches.map(match => match.replace(/<\/?a:t>/g, '')) : [];
  return texts.join(' ');
}

/**
 * Extracts slide number from slide file name.
 * @param {string} slideFileName - The slide file name (e.g., ppt/slides/slide1.xml).
 * @returns {number} - The slide number.
 */
function extractSlideNumber(slideFileName) {
  const match = slideFileName.match(/slide(\d+)\.xml$/);
  return match ? parseInt(match[1], 10) : 0;
}

```

## services/converter/text/rtfConverter.js

```js
// services/converter/text/rtfConverter.js

import rtfModule from '@iarna/rtf-to-html'; // CommonJS module
import TurndownService from 'turndown';
import path from 'path';

/**
 * Converts an RTF buffer to Markdown format.
 * @param {Buffer} input - The RTF file buffer.
 * @param {string} originalName - Original filename for context.
 * @param {string} [apiKey] - API key if needed.
 * @returns {Promise<{ content: string, images: Array }>} - Converted content and images.
 * @throws Will throw an error if the conversion fails.
 */
export async function convertRtfToMarkdown(input, originalName, apiKey) {
  try {
    // Destructure the rtfToHTML function from the imported CommonJS module
    const { rtfToHTML } = rtfModule;

    // Convert RTF to HTML using the rtfToHTML function
    const html = await new Promise((resolve, reject) => {
      rtfToHTML(input, (err, htmlOutput) => {
        if (err) {
          reject(err);
        } else {
          resolve(htmlOutput);
        }
      });
    });

    // Initialize TurndownService for HTML to Markdown conversion
    const turndownService = new TurndownService();

    // Convert the HTML content to Markdown
    const markdown = turndownService.turndown(html);

    // Add some basic metadata
    const metadataMarkdown = `# ${path.basename(originalName, path.extname(originalName))}\n\n` +
                             `**Converted on:** ${new Date().toISOString()}\n\n`;

    return {
      content: metadataMarkdown + markdown,
      images: [] // No image extraction
    };
  } catch (error) {
    console.error('Error converting RTF to Markdown:', error);
    throw error;
  }
}

```

## services/converter/text/txtConverter.js

```js
// services/converter/text/txtConverter.js

import path from 'path';

/**
 * Converts a TXT buffer to Markdown format.
 * @param {Buffer} input - The TXT file buffer.
 * @param {string} originalName - Original filename for context.
 * @param {string} [apiKey] - API key if needed.
 * @returns {Promise<{ content: string, images: Array }>} - Converted content and images.
 * @throws Will throw an error if the conversion fails.
 */
export async function convertTxtToMarkdown(input, originalName, apiKey) {
  try {
    // Convert buffer to string
    const content = input.toString('utf-8');

    // Split content into lines
    const lines = content.split(/\r?\n/);

    // Process each line
    const markdownLines = lines.map(line => {
      // Escape Markdown syntax characters
      const escapedLine = line.replace(/([\\`*_{}[\]()#+\-.!])/g, '\\$1');
      
      // Ensure line breaks are preserved in Markdown
      return escapedLine + '  ';
    });

    // Join lines back together
    const markdownContent = markdownLines.join('\n');

    // Add some basic metadata
    const metadataMarkdown = `# ${path.basename(originalName, path.extname(originalName))}\n\n` +
                             `**Converted on:** ${new Date().toISOString()}\n\n`;

    return {
      content: metadataMarkdown + markdownContent,
      images: [] // No image extraction
    };
  } catch (error) {
    console.error('Error converting TXT to Markdown:', error);
    throw error;
  }
}

```

## services/converter/textConverterFactory.js

```js
// services/converter/textConverterFactory.js

import { convertTxtToMarkdown } from './text/txtConverter.js';
import { convertRtfToMarkdown } from './text/rtfConverter.js';
import { convertPdfToMarkdown } from './text/pdfConverter.js';
import { convertDocxToMarkdown } from './text/docxConverter.js';
import { convertOdtToMarkdown } from './text/odtConverter.js';
import { convertEpubToMarkdown } from './text/epubConverter.js';
import { convertPptxToMarkdown } from './text/pptxConverter.js';
import { convertCsvToMarkdown } from './data/csvConverter.js';
import { convertJsonToMarkdown } from './data/jsonConverter.js';
import { convertYamlToMarkdown } from './data/yamlConverter.js';
import { convertXlsxToMarkdown } from './data/xlsxConverter.js';
import { convertHtmlToMarkdown } from './web/htmlConverter.js';
import { convertXmlToMarkdown } from './web/xmlConverter.js';
import { convertUrlToMarkdown } from './web/urlConverter.js';
import { convertParentUrlToMarkdown } from './web/parentUrlConverter.js';
import { convertYoutubeToMarkdown } from './web/youtubeConverter.js';

/**
 * Factory class for managing different types of Markdown converters
 */
class TextConverterFactory {
  /**
   * Initialize the converter factory with supported file type mappings
   */
  constructor() {
    this.converters = {
      // Text converters
      txt: convertTxtToMarkdown,
      rtf: convertRtfToMarkdown,
      pdf: convertPdfToMarkdown,
      docx: convertDocxToMarkdown,
      odt: convertOdtToMarkdown,
      epub: convertEpubToMarkdown,
      pptx: convertPptxToMarkdown,

      // Data converters
      csv: convertCsvToMarkdown,
      json: convertJsonToMarkdown,
      yaml: convertYamlToMarkdown,
      yml: convertYamlToMarkdown,
      xlsx: convertXlsxToMarkdown,

      // Web converters
      html: convertHtmlToMarkdown,
      htm: convertHtmlToMarkdown,
      xml: convertXmlToMarkdown,
      url: convertUrlToMarkdown,
      parenturl: convertParentUrlToMarkdown,
      youtube: convertYoutubeToMarkdown,
    };

    // Map of expected input types for validation
    this.expectedInputTypes = {
      docx: ['buffer'],
      pdf: ['buffer'],
      txt: ['string', 'buffer'],
      rtf: ['buffer'],
      epub: ['buffer'],
      odt: ['buffer'],
      pptx: ['buffer'],
      html: ['string'],
      htm: ['string'],
      xml: ['string'],
      url: ['string'],
      parenturl: ['string', 'object'],
      youtube: ['string'],
    };

    console.log('Registered converters:', Object.keys(this.converters));
    console.log('Registered input types:', this.expectedInputTypes);
  }

  /**
   * Validates input type against expected types for the format
   * @private
   * @param {string} type - The file type
   * @param {any} input - The input to validate
   * @throws {Error} If input type is invalid
   */
  validateInput(type, input) {
    // Normalize type to lowercase
    const normalizedType = type.toLowerCase();

    console.log('Validating input:', {
      originalType: type,
      normalizedType,
      inputType: typeof input,
      isBuffer: Buffer.isBuffer(input),
      expectedTypes: this.expectedInputTypes[normalizedType],
      input: Buffer.isBuffer(input)
        ? '[Buffer data]'
        : typeof input === 'object'
        ? JSON.stringify(input)
        : input
    });

    const expectedTypes = this.expectedInputTypes[normalizedType] || ['buffer', 'string'];
    const inputType = typeof input;
    const isBuffer = Buffer.isBuffer(input);

    // Special handling for parenturl type
    if (normalizedType === 'parenturl') {
      if (typeof input === 'string' || typeof input === 'object') {
        return true;
      }
    }

    if (isBuffer && !expectedTypes.includes('buffer')) {
      throw new Error(`${type} converter does not accept Buffer input`);
    }

    if (!expectedTypes.includes(inputType) && !isBuffer) {
      throw new Error(
        `Invalid input type for ${type}. Expected ${expectedTypes.join(' or ')}, got ${inputType}`
      );
    }
  }

  /**
   * Converts input content to Markdown format
   * @param {string} type - The type of content
   * @param {Buffer|string|Object} input - The content to convert
   * @param {string} originalName - Original filename or identifier
   * @param {string} [apiKey] - API key for services that require authentication
   * @returns {Promise<{ content: string, images: Array }>} - Converted content and images
   */
  async convertToMarkdown(type, input, originalName, apiKey) {
    try {
      // Debug logging
      console.log('Converting to Markdown:', {
        type,
        inputType: typeof input,
        input: Buffer.isBuffer(input)
          ? '[Buffer data]'
          : typeof input === 'object'
          ? JSON.stringify(input)
          : input
      });

      if (!input) {
        throw new Error('No input provided');
      }

      if (!type) {
        throw new Error('No file type specified');
      }

      const normalizedType = type.toLowerCase();

      // Get the appropriate converter
      const converter = this.converters[normalizedType];
      if (!converter) {
        throw new Error(`Unsupported file type: ${type}`);
      }

      // Validate input type
      this.validateInput(normalizedType, input);

      // If input is an object with a url property, use that for parenturl
      const processedInput = normalizedType === 'parenturl' && typeof input === 'object'
        ? input.url || input.parenturl
        : input;

      const convertedResult = await converter(processedInput, originalName, apiKey);

      // Enhanced result validation
      if (!convertedResult) {
        throw new Error(`Converter returned no result for ${type}`);
      }

      if (typeof convertedResult !== 'object') {
        throw new Error(`Converter returned invalid result type for ${type}`);
      }

      if (!convertedResult.content && !convertedResult.error) {
        throw new Error(`Converter returned empty content for ${type}`);
      }

      // Ensure images array exists
      if (!convertedResult.images) {
        convertedResult.images = [];
      }

      return convertedResult;

    } catch (error) {
      console.error('Conversion error:', {
        type,
        error: error.message,
        stack: error.stack
      });

      // Return error content instead of throwing
      return {
        content: [
          `# Conversion Error: ${type}`,
          '',
          '```',
          `Error: ${error.message}`,
          '```',
          '',
          `**Time:** ${new Date().toISOString()}`,
          `**Type:** ${type}`,
          `**Input:** ${
            Buffer.isBuffer(input)
              ? '[Buffer data]'
              : typeof input === 'object'
              ? JSON.stringify(input)
              : input
          }`
        ].join('\n'),
        images: [],
        error: error.message
      };
    }
  }

  /**
   * Registers a new converter for a file type
   * @param {string} type - The file type
   * @param {Function} converterFunction - The converter function
   */
  addConverter(type, converterFunction) {
    if (typeof converterFunction !== 'function') {
      throw new Error('Converter must be a function');
    }
    this.converters[type.toLowerCase()] = converterFunction;
  }
}

// Export singleton instance
export const textConverterFactory = new TextConverterFactory();

```

## services/converter/web/htmlConverter.js

```js
// services/converter/web/htmlConverter.js

import TurndownService from 'turndown';
import * as cheerio from 'cheerio'; // Corrected import
import path from 'path';

/**
 * Converts an HTML string or buffer to Markdown format, extracting images.
 * @param {Buffer|string} input - The HTML content as a buffer or string.
 * @param {string} originalName - Original filename for context.
 * @param {string} [apiKey] - API key if needed.
 * @returns {Promise<{ content: string, images: Array }>} - Converted content and images.
 */
export async function convertHtmlToMarkdown(input, originalName, apiKey) {
  try {
    // Convert buffer to string if necessary
    const htmlContent = Buffer.isBuffer(input) ? input.toString('utf-8') : input;

    // Initialize TurndownService
    const turndownService = new TurndownService({
      headingStyle: 'atx',
      codeBlockStyle: 'fenced',
      emDelimiter: '_',
      strongDelimiter: '**'
    });

    // Add custom rules if needed
    turndownService.addRule('strikethrough', {
      filter: ['del', 's', 'strike'],
      replacement: function (content) {
        return '~~' + content + '~~';
      }
    });

    // Load HTML into Cheerio for parsing
    const $ = cheerio.load(htmlContent);

    // Extract images
    const images = [];
    $('img').each((index, img) => {
      const src = $(img).attr('src');
      const alt = $(img).attr('alt') || `Image ${index + 1}`;
      if (src) {
        // Handle base64 images or external URLs
        if (src.startsWith('data:')) {
          const matches = src.match(/^data:(image\/[a-zA-Z]+);base64,(.+)$/);
          if (matches) {
            const imageType = matches[1].split('/')[1];
            const imageData = matches[2];
            const imageName = `image-${index + 1}.${imageType}`;
            images.push({
              name: imageName,
              data: imageData,
              type: `image/${imageType}`,
              path: `attachments/${path.basename(originalName, path.extname(originalName))}/${imageName}`
            });

            // Replace src with new path
            $(img).attr(
              'src',
              `attachments/${path.basename(originalName, path.extname(originalName))}/${imageName}`
            );
          }
        } else {
          // For external URLs, you might want to download and include them
          // This implementation assumes images are to be handled externally
          images.push({
            name: path.basename(src),
            data: '', // Placeholder if you plan to download images
            type: '', // Placeholder for image type
            path: src // External path
          });
        }
      }
    });

    // Get modified HTML with updated image paths
    const modifiedHtml = $.html();

    // Convert HTML to Markdown
    let markdownContent = turndownService.turndown(modifiedHtml);

    // Add metadata
    const metadataMarkdown =
      `# ${path.basename(originalName, path.extname(originalName))}\n\n` +
      `**Converted on:** ${new Date().toISOString()}\n\n`;

    // Combine metadata and content
    const fullMarkdown = metadataMarkdown + markdownContent;

    return {
      content: fullMarkdown,
      images: images
    };
  } catch (error) {
    console.error('Error converting HTML to Markdown:', error);
    throw error;
  }
}

```

## services/converter/web/parentUrlConverter.js

```js
// services/converter/web/parenturlConverter.js

import puppeteer from 'puppeteer';
import pLimit from 'p-limit';
import { convertUrlToMarkdown } from './urlConverter.js';

/**
 * Configuration for URL processing and crawling
 */
const CONFIG = {
  crawler: {
    maxPages: 100,
    maxDepth: 1000,
    concurrentLimit: 5,
    timeout: 30000,
    validProtocols: ['http:', 'https:'],
    excludePatterns: [
      /\.(pdf|zip|doc|docx|xls|xlsx|ppt|pptx)$/i,
      /\?(utm_|source=|campaign=)/i,
      /#.*/,
      /\/api\//,
      /\/feed\//,
      /\/rss\//
    ]
  },
  puppeteer: {
    launch: {
      headless: true,
      args: [
        '--no-sandbox',
        '--disable-setuid-sandbox',
        '--disable-dev-shm-usage',
        '--disable-accelerated-2d-canvas',
        '--disable-gpu'
      ]
    },
    navigation: {
      waitUntil: 'networkidle2',
      timeout: 30000
    },
    userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
  }
};

/**
 * Validates and normalizes a URL
 * @param {string} url - URL to validate
 * @returns {string} Normalized URL
 */
function normalizeUrl(url) {
  try {
    url = url.trim();
    if (!/^https?:\/\//i.test(url)) {
      url = 'https://' + url.replace(/^\/\//, '');
    }

    const urlObj = new URL(url);
    if (!CONFIG.crawler.validProtocols.includes(urlObj.protocol)) {
      throw new Error(`Invalid protocol: ${urlObj.protocol}`);
    }

    return urlObj.href;
  } catch (error) {
    throw new Error(`Invalid URL: ${error.message}`);
  }
}

/**
 * Sanitizes a string for use as a filename
 * @param {string} input - String to sanitize
 * @returns {string} Sanitized string
 */
function sanitizeFilename(input) {
  if (!input) return 'index';

  return input
    .toLowerCase()
    .replace(/^\/+|\/+$/g, '')
    .replace(/[^a-z0-9]+/g, '-')
    .replace(/^-+|-+$/g, '')
    .slice(0, 100) || 'index';
}

/**
 * Checks if a URL should be processed
 * @param {string} url - URL to check
 * @param {string} parenturl - Parent URL for domain checking
 * @returns {boolean} Whether URL should be processed
 */
function shouldProcessUrl(url, parenturl) {
  try {
    const urlObj = new URL(url);
    const parentObj = new URL(parenturl);

    // Must be same domain
    if (urlObj.hostname !== parentObj.hostname) return false;

    // Check against exclude patterns
    if (CONFIG.crawler.excludePatterns.some(pattern => pattern.test(url))) {
      return false;
    }

    return true;
  } catch {
    return false;
  }
}

/**
 * Crawls a website to find all valid URLs
 * @param {string} parenturl - Starting URL
 * @returns {Promise<Set<string>>} Set of discovered URLs
 */
async function crawlWebsite(parenturl) {
  const browser = await puppeteer.launch(CONFIG.puppeteer.launch);
  const discoveredUrls = new Set();
  const processedUrls = new Set();

  try {
    const page = await browser.newPage();
    await page.setUserAgent(CONFIG.puppeteer.userAgent);

    async function processPage(url, depth) {
      if (depth > CONFIG.crawler.maxDepth) return;
      if (discoveredUrls.size >= CONFIG.crawler.maxPages) return;
      if (processedUrls.has(url)) return;

      try {
        processedUrls.add(url);
        console.log(`Processing page ${processedUrls.size}:`, url);

        const response = await page.goto(url, CONFIG.puppeteer.navigation);
        if (!response) {
          console.warn(`No response for URL: ${url}`);
          return;
        }

        // Extract and verify content type
        const contentType = response.headers()['content-type'] || '';

        if (contentType.includes('text/html') || contentType.includes('image/')) {
          discoveredUrls.add(url);
        }

        // Only continue crawling for HTML pages
        if (contentType.includes('text/html')) {
          const links = await page.evaluate(() =>
            Array.from(document.querySelectorAll('a[href]'))
              .map(a => a.href)
              .filter(Boolean)
          );

          for (const link of links) {
            if (shouldProcessUrl(link, parenturl) && !processedUrls.has(link)) {
              await processPage(link, depth + 1);
              if (discoveredUrls.size >= CONFIG.crawler.maxPages) break;
            }
          }
        }
      } catch (error) {
        console.error(`Error processing ${url}:`, error.message);
      }
    }

    await processPage(parenturl, 0);
    return discoveredUrls;

  } catch (error) {
    console.error('Error during crawling:', error);
    throw error;
  } finally {
    await browser.close();
  }
}

/**
 * Processes discovered URLs into Markdown content
 * @param {Set<string>} urls - URLs to process
 * @returns {Promise<Array>} Processed results
 */
async function processUrls(urls) {
  const limit = pLimit(CONFIG.crawler.concurrentLimit);

  const tasks = Array.from(urls).map(url =>
    limit(async () => {
      try {
        const urlObj = new URL(url);
        const name = sanitizeFilename(urlObj.pathname);

        const result = await convertUrlToMarkdown(url, name);

        return {
          success: true,
          type: 'url',
          name: `${name || 'index'}.md`,
          content: result.content,
          images: result.images || [],
          url
        };
      } catch (error) {
        console.error(`Error converting ${url}:`, error.message);
        return {
          success: false,
          type: 'url',
          url,
          error: error.message
        };
      }
    })
  );

  return await Promise.all(tasks);
}

/**
 * Generates index content for the website
 * @param {string} parenturl - Parent URL
 * @param {Array} pages - Processed pages
 * @returns {string} Index content in Markdown
 */
function generateIndex(parenturl, pages) {
  const successfulPages = pages.filter(p => p.success);
  const failedPages = pages.filter(p => !p.success);
  const hostname = new URL(parenturl).hostname;

  return [
    `---`,
    `Title: ${hostname} Archive`,
    `Description: Website archive of ${hostname}`,
    `Date: ${new Date().toISOString().split('T')[0]}`,
    `Tags:`,
    ` - "#website-archive"`,
    ` - "#${hostname.replace(/\./g, '-')}"`,
    `---`,
    '',
    `# ${hostname}`,
    '',
    '## Site Information',
    `- Source URL: ${parenturl}`,
    `- Archived: ${new Date().toISOString()}`,
    `- Total Pages: ${pages.length}`,
    `- Successful: ${successfulPages.length}`,
    `- Failed: ${failedPages.length}`,
    '',
    '## Pages',
    '',
    ...successfulPages.map(page => {
      const name = page.name.replace(/\.md$/, '');
      return `- [[${name}]]`;
    }),
    '',
    failedPages.length ? [
      '## Failed Pages',
      '',
      ...failedPages.map(page => `- ${page.url}: ${page.error}`),
      ''
    ].join('\n') : '',
    '## Notes',
    '',
    '- All images are stored in the assets folder',
    '- Internal links are preserved as wiki-links',
    '- Original URLs are preserved in page metadata'
  ].join('\n');
}

/**
 * Converts a parent URL and its children to Markdown
 * @param {string} parenturl - Parent URL to convert
 * @param {string} originalName - Original name for context
 * @returns {Promise<Object>} Conversion results
 */
export async function convertParentUrlToMarkdown(parenturl, originalName) {
  try {
    // Normalize and validate URL
    const normalizedUrl = normalizeUrl(parenturl);
    console.log(`Starting conversion of ${normalizedUrl}`);

    // Crawl website
    const urls = await crawlWebsite(normalizedUrl);

    if (urls.size === 0) {
      return {
        content: index,
        files: successfulPages.map(({ name, content }) => ({
          name: name, // Use the sanitized page name
          content: content || `# ${name}\n\nNo content available.`
        })),
        images: allImages.filter(img => img.data && img.name).map(img => ({
          name: img.name,
          data: img.data
        })),
        childUrls: Array.from(urls)
      };      
    }

    // Process discovered URLs
    const processedPages = await processUrls(urls);

    // Generate index
    const index = generateIndex(normalizedUrl, processedPages);

    // Collect successful pages and images
    const successfulPages = processedPages.filter(p => p.success);
    const allImages = successfulPages.flatMap(p => p.images || []);

    // Return with required content structure
    return {
      content: index,
      files: successfulPages.map(({ name, content }) => ({
        name: `pages/${name}`,
        content: content || `# ${name}\n\nNo content available.`
      })),
      images: allImages.filter(img => img.data && img.name).map(img => ({
        name: `assets/${img.name}`,
        data: img.data
      })),
      childUrls: Array.from(urls)
    };

  } catch (error) {
    console.error('Parent URL conversion failed:', error.message);

    return {
      content: [
        `# Conversion Error: ${parenturl}`,
        '',
        '```',
        `Error: ${error.message}`,
        '```',
        '',
        `**Time:** ${new Date().toISOString()}`,
        `**URL:** ${parenturl}`,
        `**Type:** parenturl`
      ].join('\n'),
      images: [],
      error: error.message
    };
  }
}
```

## services/converter/web/urlConverter.js

```js
// services/converter/web/urlConverter.js

import puppeteer from 'puppeteer';
import TurndownService from 'turndown';
import * as cheerio from 'cheerio';
import { v4 as uuidv4 } from 'uuid';
import pLimit from 'p-limit';
import fetch from 'node-fetch';
import { extractMetadata } from '../../../utils/metadataExtractor.js';

/**
 * Configuration for the URL converter
 */
const CONFIG = {
  puppeteer: {
    launch: {
      headless: true,
      args: [
        '--no-sandbox',
        '--disable-setuid-sandbox',
        '--disable-dev-shm-usage',
        '--disable-accelerated-2d-canvas',
        '--disable-gpu'
      ],
      defaultViewport: { width: 1920, height: 1080 }
    },
    navigation: {
      waitUntil: 'networkidle2',
      timeout: 30000
    },
    userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
  },
  content: {
    selectors: {
      mainContent: [
        'main',
        'article',
        '[role="main"]',
        '.main-content',
        '.content',
        '#content',
        '.post-content',
        '.article-content'
      ],
      remove: [
        'script',
        'style',
        'link',
        'meta',
        'noscript',
        'iframe',
        '.hidden',
        '[style*="display: none"]',
        '[style*="display:none"]',
        '[hidden]',
        '[data-ad]',
        '[id*="google"]',
        '[class*="advert"]',
        '[class*="tracking"]',
        '[aria-hidden="true"]'
      ]
    },
    turndown: {
      headingStyle: 'atx',
      codeBlockStyle: 'fenced',
      emDelimiter: '_',
      strongDelimiter: '**',
      bulletListMarker: '-'
    }
  },
  limits: {
    maxImages: 100,
    concurrentRequests: 5,
    maxRetries: 3,
    retryDelay: 1000
  }
};

/**
 * Class to handle URL content detection and conversion
 */
class ContentTypeHandler {
  /**
   * Detects the content type of a given URL.
   * @param {string} url - The URL to detect.
   * @returns {Promise<Object>} - An object containing content type details.
   */
  static async detect(url) {
    try {
      const response = await fetch(url, { method: 'HEAD' });
      const contentType = response.headers.get('content-type') || '';
      return {
        type: contentType.split(';')[0].toLowerCase(),
        isHtml: contentType.includes('text/html'),
        isImage: contentType.startsWith('image/'),
        extension: contentType.split('/')[1]
      };
    } catch (error) {
      console.error('Content type detection failed:', error);
      return { type: 'unknown', isHtml: false, isImage: false };
    }
  }

  /**
   * Handles image URLs by downloading and encoding them.
   * @param {string} url - The image URL.
   * @param {string} name - The base name for the image file.
   * @returns {Promise<Object>} - An object containing markdown content and image data.
   */
  static async handleImage(url, name) {
    try {
      const response = await fetch(url);
      if (!response.ok) {
        throw new Error(`Failed to fetch image: ${response.status} ${response.statusText}`);
      }
      const buffer = await response.arrayBuffer();
      const base64 = Buffer.from(buffer).toString('base64');
      const contentType = response.headers.get('content-type');
      const extension = contentType?.split('/')[1] || 'png';
      const imageName = `${sanitizeFilename(name || 'image')}-${uuidv4().slice(0, 8)}.${extension}`;

      return {
        content: [
          `# Image: ${imageName}`,
          '',
          `**Source:** ${url}`,
          `**Downloaded:** ${new Date().toISOString()}`,
          `**Type:** ${contentType}`,
          '',
          `![${imageName}](assets/${imageName})`,
          ''
        ].join('\n'),
        images: [{
          name: imageName,
          data: base64,
          type: contentType,
          path: `assets/${imageName}`
        }]
      };
    } catch (error) {
      throw new Error(`Image processing failed: ${error.message}`);
    }
  }
}

/**
 * Class to handle HTML content processing
 */
class HtmlProcessor {
  /**
   * Cleans up the HTML content by removing unwanted elements and attributes.
   * @param {CheerioStatic} $ - The Cheerio object containing HTML.
   * @returns {CheerioStatic} - The cleaned Cheerio object.
   */
  static cleanupContent($) {
    CONFIG.content.selectors.remove.forEach(selector => {
      $(selector).remove();
    });

    $('*').removeAttr('class').removeAttr('id');
    $('p:empty, div:empty').remove();

    return $;
  }

  /**
   * Extracts the main content from the cleaned HTML.
   * @param {CheerioStatic} $ - The cleaned Cheerio object.
   * @returns {CheerioElement} - The main content element.
   */
  static extractMainContent($) {
    for (const selector of CONFIG.content.selectors.mainContent) {
      const element = $(selector);
      if (element.length && element.text().trim().length > 100) {
        return element;
      }
    }
    return $('body');
  }

  /**
   * Cleans up and extracts the main content from the HTML.
   * @param {string} html - The raw HTML content.
   * @returns {Promise<{ $, mainContent: CheerioElement }>} - The Cheerio instance and the main content element.
   */
  static async cleanupAndExtract(html) {
    try {
      const $ = cheerio.load(html);
      this.cleanupContent($);
      const mainContent = this.extractMainContent($);
      return { $, mainContent };
    } catch (error) {
      throw new Error(`Failed to cleanup and extract content: ${error.message}`);
    }
  }

  /**
   * Processes images within the main content.
   * @param {CheerioStatic} $ - The Cheerio instance.
   * @param {CheerioElement} content - The main content element.
   * @param {string} baseName - The base name for image files.
   * @returns {Promise<{ content: string, images: Array }>} - The processed content and images.
   */
  static async processImages($, content, baseName) {
    const images = [];
    const limit = pLimit(CONFIG.limits.concurrentRequests);

    const imagePromises = [];
    $(content).find('img').each((index, img) => {
      if (images.length >= CONFIG.limits.maxImages) return;

      const src = $(img).attr('src');
      if (!src) return;

      const promise = limit(async () => {
        try {
          const imageResult = await this.processImage(src, baseName, index);
          if (imageResult) {
            images.push(imageResult.image);
            $(img).attr('src', imageResult.path);
          }
        } catch (error) {
          console.error(`Image processing failed: ${error.message}`);
        }
      });

      imagePromises.push(promise);
    });

    await Promise.all(imagePromises);
    return { content: $(content).html(), images };
  }

  /**
   * Processes a single image.
   * @param {string} src - The source URL of the image.
   * @param {string} baseName - The base name for the image file.
   * @param {number} index - The index of the image.
   * @returns {Promise<{ image: Object, path: string } | null>} - The image object and its path, or null.
   */
  static async processImage(src, baseName, index) {
    if (src.startsWith('data:')) {
      const matches = src.match(/^data:(image\/[a-zA-Z]+);base64,(.+)$/);
      if (matches) {
        const [_, type, data] = matches;
        const extension = type.split('/')[1];
        const name = `${sanitizeFilename(baseName)}-${index + 1}.${extension}`;
        return {
          image: {
            name,
            data,
            type,
            path: `assets/${name}`
          },
          path: `assets/${name}`
        };
      }
    } else if (src.startsWith('http') || src.startsWith('//')) {
      try {
        let imageUrl = src.startsWith('//') ? 'https:' + src : src;
        const response = await fetch(imageUrl);
        if (!response.ok) {
          throw new Error(`Failed to fetch image: ${response.status} ${response.statusText}`);
        }
        const buffer = await response.arrayBuffer();
        const type = response.headers.get('content-type');
        const extension = type?.split('/')[1] || 'png';
        const name = `${sanitizeFilename(baseName)}-${index + 1}.${extension}`;
        return {
          image: {
            name,
            data: Buffer.from(buffer).toString('base64'),
            type,
            path: `assets/${name}`
          },
          path: `assets/${name}`
        };
      } catch (error) {
        console.error(`Failed to fetch image ${src}:`, error);
      }
    }
    return null;
  }
}

/**
 * Sanitizes filenames by removing invalid characters.
 * @param {string} filename - The original filename.
 * @returns {string} - The sanitized filename.
 */
function sanitizeFilename(filename) {
  // Simple regex to remove invalid characters
  return filename.replace(/[^a-z0-9_\-\.]/gi, '_');
}

/**
 * Main URL converter function
 * @param {string|Object} urlInput - URL to convert
 * @param {string} originalName - Original name for file paths
 * @returns {Promise<{ content: string, images: Array, name: string, success: boolean }>}
 */
export async function convertUrlToMarkdown(urlInput, originalName) {
  let browser;
  try {
    // Normalize URL
    const url = typeof urlInput === 'object' ? urlInput.url || urlInput.href : urlInput.toString();
    if (!url) throw new Error('Invalid URL input');

    // Clean URL
    const cleanUrl = url.trim();
    const fullUrl = !/^https?:\/\//i.test(cleanUrl)
      ? 'https://' + cleanUrl.replace(/^\/\//, '')
      : cleanUrl;

    console.log(`Converting URL: ${fullUrl}`);

    // Detect content type
    const contentType = await ContentTypeHandler.detect(fullUrl);

    // Handle image URLs directly
    if (contentType.isImage) {
      const imageResult = await ContentTypeHandler.handleImage(fullUrl, originalName);
      return {
        content: imageResult.content,
        images: imageResult.images,
        name: originalName || sanitizeFilename(new URL(fullUrl).hostname),
        success: true
      };
    }

    // Handle non-HTML content
    if (!contentType.isHtml) {
      const metadata = await extractMetadata(fullUrl);
      const markdown = `\n\n> Non-HTML content at [${fullUrl}](${fullUrl})\n`;
      return {
        content: metadata + markdown,
        images: [],
        name: sanitizeFilename(new URL(fullUrl).hostname),
        success: true
      };
    }

    // Launch Puppeteer
    browser = await puppeteer.launch(CONFIG.puppeteer.launch);
    const page = await browser.newPage();
    await page.setUserAgent(CONFIG.puppeteer.userAgent);
    await page.goto(fullUrl, CONFIG.puppeteer.navigation);

    // Get the rendered HTML content
    const html = await page.content();

    // Close the browser
    await browser.close();
    browser = null;

    // Process HTML content
    const metadata = await extractMetadata(fullUrl);
    const { $, mainContent } = await HtmlProcessor.cleanupAndExtract(html);

    // Process images
    const { content: processedContent, images } = await HtmlProcessor.processImages($, mainContent, originalName);

    // Convert to Markdown
    const turndownService = new TurndownService(CONFIG.content.turndown);
    turndownService.addRule('strikethrough', {
      filter: ['del', 's', 'strike'],
      replacement: (content) => `~~${content}~~`,
    });

    const markdown = turndownService.turndown(processedContent);
    const finalContent = metadata + markdown;

    return {
      content: finalContent,
      images,
      name: sanitizeFilename(originalName || new URL(fullUrl).hostname),
      success: true
    };

  } catch (error) {
    console.error('URL conversion failed:', error);
    if (browser) await browser.close(); // Ensure browser is closed on error
    return {
      content: [
        `# Conversion Error`,
        '',
        `> Failed to convert URL to Markdown.`,
        '',
        '## Error Details',
        '```',
        error.message,
        '```',
        '',
        '## Request Information',
        `- **URL:** ${urlInput}`,
        `- **Time:** ${new Date().toISOString()}`,
        `- **Name:** ${originalName}`
      ].join('\n'),
      images: [],
      name: sanitizeFilename(originalName || 'unknown'),
      success: false
    };
  }
}

```

## services/converter/web/xmlConverter.js

```js
// services/converter/web/xmlConverter.js

import xml2js from 'xml2js';
import TurndownService from 'turndown';
import path from 'path';

/**
 * Converts an XML string or buffer to Markdown format.
 * @param {Buffer|string} input - The XML content as a buffer or string.
 * @param {string} originalName - Original filename for context.
 * @param {string} [apiKey] - API key if needed.
 * @returns {Promise<{ content: string, images: Array }>} - Converted content and images.
 */
export async function convertXmlToMarkdown(input, originalName, apiKey) {
  try {
    // Convert buffer to string if necessary
    const xmlContent = Buffer.isBuffer(input) ? input.toString('utf-8') : input;

    // Parse XML
    const parser = new xml2js.Parser({ explicitArray: false });
    const parsedXml = await parser.parseStringPromise(xmlContent);

    // Convert parsed XML to HTML or directly to Markdown
    const htmlContent = xmlToHtml(parsedXml);

    // Initialize TurndownService
    const turndownService = new TurndownService({
      headingStyle: 'atx',
      codeBlockStyle: 'fenced',
      emDelimiter: '_',
      strongDelimiter: '**'
    });

    // Add custom rules if needed
    turndownService.addRule('strikethrough', {
      filter: ['del', 's', 'strike'],
      replacement: function(content) {
        return '~~' + content + '~~';
      }
    });

    // Extract images if the XML contains image references
    // This implementation assumes that images are referenced in a specific way
    // Adjust the selector based on your XML structure
    const images = [];
    // Example: If XML has <image src="data:image/png;base64,..." alt="Description" />
    // Adjust according to actual XML structure

    // For demonstration, let's assume images are in a specific tag
    // You need to modify this based on your XML schema
    if (parsedXml.images && Array.isArray(parsedXml.images.image)) {
      parsedXml.images.image.forEach((img, index) => {
        const src = img.$.src;
        const alt = img.$.alt || `Image ${index + 1}`;
        if (src) {
          if (src.startsWith('data:')) {
            const matches = src.match(/^data:(image\/[a-zA-Z]+);base64,(.+)$/);
            if (matches) {
              const imageType = matches[1].split('/')[1];
              const imageData = matches[2];
              const imageName = `image-${index + 1}.${imageType}`;
              images.push({
                name: imageName,
                data: imageData,
                type: `image/${imageType}`,
                path: `attachments/${path.basename(originalName, path.extname(originalName))}/${imageName}`
              });

              // Replace src with new path in htmlContent
              // This requires converting xml to HTML in a way that includes the image src
              // Alternatively, handle image references separately in Markdown
            }
          } else {
            // Handle external image URLs if needed
            images.push({
              name: path.basename(src),
              data: '', // Placeholder if you plan to download images
              type: '', // Placeholder for image type
              path: src // External path
            });
          }
        }
      });
    }

    // Convert HTML to Markdown
    let markdownContent = turndownService.turndown(htmlContent);

    // Add metadata
    const metadataMarkdown = `# ${path.basename(originalName, path.extname(originalName))}\n\n` +
                             `**Converted on:** ${new Date().toISOString()}\n\n`;

    // Combine metadata and content
    const fullMarkdown = metadataMarkdown + markdownContent;

    return {
      content: fullMarkdown,
      images: images
    };
  } catch (error) {
    console.error('Error converting XML to Markdown:', error);
    throw error;
  }
}

/**
 * Converts parsed XML object to HTML string.
 * This function should be customized based on the XML schema.
 * @param {Object} parsedXml - Parsed XML object.
 * @returns {string} - HTML string.
 */
function xmlToHtml(parsedXml) {
  // Implement a conversion logic from XML to HTML based on your specific XML structure
  // Here's a simple example for demonstration purposes:

  let html = '';

  function traverse(obj) {
    for (const key in obj) {
      if (obj.hasOwnProperty(key)) {
        const value = obj[key];
        if (typeof value === 'object') {
          html += `<${key}>`;
          traverse(value);
          html += `</${key}>`;
        } else {
          html += `<${key}>${value}</${key}>`;
        }
      }
    }
  }

  traverse(parsedXml);
  return html;
}

```

## services/converter/web/youtubeConverter.js

```js
// services/converter/web/youtubeConverter.js
import sanitizeFilename from 'sanitize-filename';
import puppeteer from 'puppeteer';
import { YoutubeTranscript } from 'youtube-transcript'; // Ensure this package is installed
import { extractVideoId, formatTimestamp, extractYoutubeMetadata } from '../../../routes/utils/youtubeUtils.js';

/**
 * Generates markdown content with transcript and title
 * @param {string} url - The YouTube video URL
 * @param {string} videoId - The extracted video ID
 * @param {Array} transcript - The transcript array
 * @param {Object} metadata - The extracted metadata
 * @returns {string} - The generated markdown content
 */
function generateMarkdown(url, videoId, transcript, metadata) {
  const frontmatter = `---
title: "${metadata.title.replace(/"/g, '\\"')}"
url: "${url}"
videoId: "${videoId}"
date: "${new Date().toISOString()}"
tags: 
 - youtube
 - video
 - transcript
---

`;

  const videoEmbed = `<iframe width="560" height="315" src="https://www.youtube.com/embed/${videoId}" frameborder="0" allowfullscreen></iframe>\n\n`;

  const transcriptMarkdown = transcript
    .map(
      (entry) =>
        `**[${formatTimestamp(entry.offset)}]** ${entry.text.replace(/\n/g, ' ').trim()}\n`
    )
    .join('\n');

  return `${frontmatter}${videoEmbed}# Transcript\n\n${transcriptMarkdown}`;
}

/**
 * YouTube to Markdown Converter
 * @param {string} url - The YouTube video URL
 * @param {string} apiKey - (Optional) API key if required
 * @returns {Promise<Object>} - The conversion result
 */
export async function convertYoutubeToMarkdown(url, apiKey) {
  let browser;
  try {
    console.log('Starting YouTube conversion for:', url);

    const videoId = extractVideoId(url);
    if (!videoId || videoId === 'unknown') {
      throw new Error('Invalid YouTube URL');
    }
    console.log('Extracted video ID:', videoId);

    console.log('Launching browser...');
    browser = await puppeteer.launch({
      headless: true, // Set to false for debugging
      args: [
        '--no-sandbox',
        '--disable-setuid-sandbox',
        '--disable-dev-shm-usage',
        '--disable-accelerated-2d-canvas',
        '--disable-gpu',
      ],
      defaultViewport: { width: 1280, height: 800 },
    });

    const page = await browser.newPage();
    console.log('Navigating to YouTube page...');
    await page.goto(url, {
      waitUntil: 'networkidle2',
      timeout: 30000,
    });

    console.log('Extracting metadata...');
    const metadata = await extractYoutubeMetadata(page);
    console.log('Metadata extracted:', {
      title: metadata.title,
    });

    // Fetch transcript
    console.log('Fetching transcript...');
    let transcript = [];
    try {
      transcript = await YoutubeTranscript.fetchTranscript(videoId);
      console.log('Transcript fetched, entries:', transcript.length);
    } catch (transcriptError) {
      console.warn('Transcript not available:', transcriptError.message);
      // Optionally, set transcript to an empty array or provide a default message
    }

    console.log('Generating markdown...');
    const markdownContent = generateMarkdown(url, videoId, transcript, metadata);

    return {
      success: true,
      type: 'youtube',
      category: 'web',
      name: sanitizeFilename(metadata.title),
      content: markdownContent,
      images: [],
      files: [],
      originalUrl: url,
    };
  } catch (error) {
    console.error('YouTube conversion failed:', error);
    return {
      success: false,
      type: 'youtube',
      name: 'youtube_video',
      error: error.message,
      images: [],
    };
  } finally {
    if (browser) {
      console.log('Closing browser...');
      await browser.close();
    }
  }
}

```

## services/fileProcessor.js

```js
// services/fileProcessor.js
import { textConverterFactory } from './converter/textConverterFactory.js';
import { AppError } from '../utils/errorHandler.js';

export async function processFile(fileBuffer, fileType, apiKey, originalName) {
  try {
    // Just convert and return the content
    return await textConverterFactory.convertToMarkdown(
      fileBuffer,
      fileType,
      apiKey,
      originalName
    );
  } catch (error) {
    console.error(`Error processing file ${originalName}:`, error);
    throw new AppError('File conversion failed', 500, error.message);
  }
}
```

## services/fileStorage.js

```js
// services/fileStorage.js

import { v4 as uuidv4 } from 'uuid';

/**
 * In-memory storage for converted files.
 * Key: fileId (string)
 * Value: { content: string, filename: string }
 */
const fileDatabase = new Map();

/**
 * Stores a converted file and returns its unique fileId.
 * @param {string} content - The converted content (Markdown string).
 * @param {string} filename - The sanitized filename.
 * @returns {string} The generated fileId.
 */
export function storeConvertedFile(content, filename) {
  const fileId = uuidv4();
  fileDatabase.set(fileId, { content, filename });
  console.log(`Stored converted file: ${filename} with ID: ${fileId}`);
  return fileId;
}

/**
 * Retrieves a converted file by its fileId.
 * @param {string} fileId - The unique identifier of the file.
 * @returns {Object|null} The file object or null if not found.
 */
export function getConvertedFile(fileId) {
  return fileDatabase.get(fileId) || null;
}

/**
 * Retrieves multiple converted files by their fileIds.
 * @param {Array<string>} fileIds - Array of fileIds.
 * @returns {Array<Object>} Array of file objects.
 */
export function getMultipleConvertedFiles(fileIds) {
  return fileIds.map(id => {
    const file = getConvertedFile(id);
    if (file) {
      return { fileId: id, ...file };
    }
    return null;
  }).filter(file => file !== null);
}

```

## services/openaiProxy.js

```js
// services/openaiProxy.js

import OpenAI from 'openai';
import { createRequire } from 'module'; // Import createRequire
const require = createRequire(import.meta.url); // Create a require function
const { RateLimiter } = require('limiter'); // Destructure RateLimiter from the required package
import fs from 'fs';
import axios from 'axios';
import axiosRetry from 'axios-retry';
import { config } from '../config/default.js';
import NodeCache from 'node-cache';
import { AppError } from '../utils/errorHandler.js';

class OpenAIProxy {
  constructor() {
    this.openai = null;
    this.rateLimiter = new RateLimiter({
      tokensPerInterval: config.api.openai.maxRequests || 50,
      interval: 'minute',
    });
    this.cache = new NodeCache({ stdTTL: 300 }); // Cache for 5 minutes
  }

  async initialize(apiKey) {
    if (!this.openai) {
      this.openai = new OpenAI({
        apiKey,
        baseURL: config.api.openai.baseUrl,
        timeout: config.api.openai.timeout,
      });

      // Configure axios retry
      axiosRetry(this.openai.httpClient, {
        retries: config.api.openai.maxRetries,
        retryDelay: axiosRetry.exponentialDelay,
        retryCondition: (error) => {
          return axiosRetry.isNetworkError(error) || axiosRetry.isRetryableError(error);
        },
      });
    }
  }

  async makeRequest(apiKey, endpoint, data) {
    await this.rateLimiter.removeTokens(1);
    await this.initialize(apiKey);

    const cacheKey = `${endpoint}:${JSON.stringify(data)}`;
    const cachedResponse = this.cache.get(cacheKey);
    if (cachedResponse) {
      return cachedResponse;
    }

    try {
      const response = await this.openai.httpClient.post(`/${endpoint}`, data, {
        headers: {
          Authorization: `Bearer ${apiKey}`,
          ...(data.getHeaders ? data.getHeaders() : {}),
        },
      });

      this.cache.set(cacheKey, response.data);
      return response.data;
    } catch (error) {
      throw this.handleApiError(error);
    }
  }

  handleApiError(error) {
    if (error.response) {
      const { status, data } = error.response;
      switch (status) {
        case 401:
          return new AppError('Invalid API key', 401);
        case 429:
          return new AppError('Rate limit exceeded', 429);
        case 500:
          return new AppError('OpenAI server error', 500);
        default:
          return new AppError(`Whisper API error: ${data.error.message}`, status);
      }
    }
    return new AppError('Unknown OpenAI API error', 500);
  }
}

export const openaiProxy = new OpenAIProxy();

```

## services/transcriber.js

```js
// services/transcriber.js

import fs from 'fs/promises';
import path from 'path';
import { OpenAI } from 'openai';
import ffmpeg from 'fluent-ffmpeg';
import ffmpegStatic from 'ffmpeg-static';
import { Readable } from 'stream';

// Set the ffmpeg path
ffmpeg.setFfmpegPath(ffmpegStatic);

class Transcriber {
  constructor() {
    this.openai = null;
  }

  initialize(apiKey) {
    this.openai = new OpenAI({ apiKey });
  }

  async transcribe(filePath, apiKey) {
    if (!this.openai) {
      this.initialize(apiKey);
    }

    try {
      const fileExtension = path.extname(filePath).toLowerCase();
      let audioFile = filePath;

      // Convert video to audio if necessary
      if (['.mp4', '.avi', '.mov', '.webm'].includes(fileExtension)) {
        audioFile = await this.convertVideoToAudio(filePath);
      }

      // Check if the audio format is supported, convert if not
      if (!['.mp3', '.mp4', '.mpeg', '.mpga', '.m4a', '.wav', '.webm'].includes(path.extname(audioFile).toLowerCase())) {
        audioFile = await this.convertToSupportedAudioFormat(audioFile);
      }

      const transcript = await this.transcribeAudio(audioFile);

      // Clean up temporary audio file if it was created
      if (audioFile !== filePath) {
        await fs.unlink(audioFile);
      }

      return transcript;
    } catch (error) {
      console.error('Transcription error:', error);
      throw error;
    }
  }

  async convertVideoToAudio(videoPath) {
    const outputPath = videoPath.replace(path.extname(videoPath), '.mp3');
    return new Promise((resolve, reject) => {
      ffmpeg(videoPath)
        .outputOptions('-ab', '192k')
        .save(outputPath)
        .on('end', () => resolve(outputPath))
        .on('error', (err) => reject(err));
    });
  }

  async convertToSupportedAudioFormat(audioPath) {
    const outputPath = audioPath.replace(path.extname(audioPath), '.mp3');
    return new Promise((resolve, reject) => {
      ffmpeg(audioPath)
        .toFormat('mp3')
        .on('end', () => resolve(outputPath))
        .on('error', (err) => reject(err))
        .save(outputPath);
    });
  }

  async transcribeAudio(audioPath) {
    const audioStream = fs.createReadStream(audioPath);
    
    const response = await this.openai.audio.transcriptions.create({
      file: audioStream,
      model: "whisper-1",
    });

    return response.text;
  }
}

export const transcriber = new Transcriber();
```

## utils/errorHandler.js

```js
// utils/errorHandler.js

import winston from 'winston';
import 'winston-daily-rotate-file';

// Create a Winston logger instance with daily rotation
const logger = winston.createLogger({
  level: 'error',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.json()
  ),
  transports: [
    new winston.transports.DailyRotateFile({
      filename: 'logs/error-%DATE%.log',
      datePattern: 'YYYY-MM-DD',
      maxSize: '20m',
      maxFiles: '14d'
    }),
    new winston.transports.Console()
  ]
});

// Custom Error Class
class AppError extends Error {
  constructor(message, statusCode, details = null) {
    super(message);
    this.statusCode = statusCode;
    this.status = `${statusCode}`.startsWith('4') ? 'fail' : 'error';
    this.details = details;
    this.isOperational = true;

    Error.captureStackTrace(this, this.constructor);
  }
}

// Error handling functions
const handleCastError = (err) => {
  const message = `Invalid ${err.path}: ${err.value}.`;
  return new AppError(message, 400);
};

const handleDuplicateFields = (err) => {
  const value = err.message.match(/(["'])(\\?.)*?\1/)[0];
  const message = `Duplicate field value: ${value}. Please use another value!`;
  return new AppError(message, 400);
};

const handleValidationError = (err) => {
  const errors = Object.values(err.errors).map(el => el.message);
  const message = `Invalid input data. ${errors.join('. ')}`;
  return new AppError(message, 400);
};

const handleJWTError = () => new AppError('Invalid token. Please log in again!', 401);
const handleJWTExpiredError = () => new AppError('Your token has expired! Please log in again.', 401);

// Send error during development
const sendErrorDev = (err, res) => {
  res.status(err.statusCode).json({
    status: err.status,
    error: err,
    message: err.message,
    stack: err.stack
  });
};

// Send error during production
const sendErrorProd = (err, res) => {
  if (err.isOperational) {
    // Operational, trusted error: send message to client
    res.status(err.statusCode).json({
      status: err.status,
      message: err.message
    });
  } else {
    // Programming or other unknown error: don't leak details
    // Log the error
    logger.error('ERROR 💥', { message: err.message, stack: err.stack });

    // Send generic message
    res.status(500).json({
      status: 'error',
      message: 'Something went wrong!'
    });
  }
};

// Centralized Error Handling Middleware
export const errorHandler = (err, req, res, next) => {
  // Set defaults
  err.statusCode = err.statusCode || 500;
  err.status = err.status || 'error';

  // Determine environment
  const env = process.env.NODE_ENV || 'development';

  if (env === 'development') {
    sendErrorDev(err, res);
  } else if (env === 'production') {
    let error = { ...err };
    error.message = err.message;

    // Handle specific error types
    if (error.name === 'CastError') error = handleCastError(error);
    if (error.code === 11000) error = handleDuplicateFields(error);
    if (error.name === 'ValidationError') error = handleValidationError(error);
    if (error.name === 'JsonWebTokenError') error = handleJWTError();
    if (error.name === 'TokenExpiredError') error = handleJWTExpiredError();

    sendErrorProd(error, res);
  } else {
    // Fallback for other environments
    sendErrorProd(err, res);
  }
};

// Export AppError for use in other modules
export { AppError };

```

## utils/markdownGenerator.js

```js
// utils/markdownGenerator.js

/**
 * Generates a Markdown document from the given content
 * @param {Object} options - The content and formatting options
 * @param {string} options.title - The title of the document
 * @param {string|Array} options.content - The main content (string or array of strings)
 * @param {Object} [options.metadata] - Optional metadata key-value pairs
 * @param {boolean} [options.tableOfContents=false] - Whether to include a table of contents
 * @returns {string} The formatted Markdown content
 */
export function generateMarkdown(options) {
    const { title, content, metadata = {}, tableOfContents = false } = options;
    let markdown = '';
  
    // Add title
    markdown += `# ${escapeMarkdown(title)}\n\n`;
  
    // Add metadata
    if (Object.keys(metadata).length > 0) {
      markdown += '## Metadata\n\n';
      for (const [key, value] of Object.entries(metadata)) {
        markdown += `- **${escapeMarkdown(key)}**: ${escapeMarkdown(value)}\n`;
      }
      markdown += '\n';
    }
  
    // Add table of contents if requested
    if (tableOfContents) {
      markdown += generateTableOfContents(content);
    }
  
    // Add main content
    markdown += formatContent(content);
  
    return markdown;
  }
  
  /**
   * Formats the main content, handling both strings and arrays
   * @param {string|Array} content - The content to format
   * @returns {string} The formatted content
   */
  function formatContent(content) {
    if (Array.isArray(content)) {
      return content.map(item => formatContentItem(item)).join('\n\n');
    } else {
      return formatContentItem(content);
    }
  }
  
  /**
   * Formats a single content item
   * @param {string|Object} item - The content item to format
   * @returns {string} The formatted content item
   */
  function formatContentItem(item) {
    if (typeof item === 'string') {
      return item;
    } else if (typeof item === 'object') {
      if (item.type === 'list') {
        return formatList(item.items, item.ordered);
      } else if (item.type === 'code') {
        return formatCodeBlock(item.code, item.language);
      } else if (item.type === 'quote') {
        return formatBlockquote(item.text);
      }
    }
    return '';
  }
  
  /**
   * Generates a table of contents from the content
   * @param {string|Array} content - The content to generate TOC from
   * @returns {string} The table of contents in Markdown format
   */
  function generateTableOfContents(content) {
    // This is a simplified TOC generation. You might want to enhance this
    // to handle nested headers and more complex structures.
    let toc = '## Table of Contents\n\n';
    const headers = content.match(/^#{2,3} .+$/gm) || [];
    headers.forEach(header => {
      const level = header.match(/^#{2,3}/)[0].length - 2;
      const title = header.replace(/^#{2,3} /, '');
      const link = title.toLowerCase().replace(/[^\w]+/g, '-');
      toc += `${'  '.repeat(level)}* [${title}](#${link})\n`;
    });
    return toc + '\n';
  }
  
  /**
   * Formats a list in Markdown
   * @param {Array} items - The list items
   * @param {boolean} [ordered=false] - Whether the list is ordered
   * @returns {string} The formatted list
   */
  function formatList(items, ordered = false) {
    return items.map((item, index) => 
      `${ordered ? `${index + 1}.` : '-'} ${escapeMarkdown(item)}`
    ).join('\n');
  }
  
  /**
   * Formats a code block in Markdown
   * @param {string} code - The code content
   * @param {string} [language=''] - The programming language
   * @returns {string} The formatted code block
   */
  function formatCodeBlock(code, language = '') {
    return `\`\`\`${language}\n${code}\n\`\`\``;
  }
  
  /**
   * Formats a blockquote in Markdown
   * @param {string} text - The quote text
   * @returns {string} The formatted blockquote
   */
  function formatBlockquote(text) {
    return text.split('\n').map(line => `> ${line}`).join('\n');
  }
  
  /**
   * Escapes special Markdown characters in a string
   * @param {string} text - The text to escape
   * @returns {string} The escaped text
   */
  function escapeMarkdown(text) {
    return text.replace(/([*_`~\[\]()#+\-.!])/g, '\\$1');
  }
```

## utils/metadataExtractor.js

```js
// utils/metadataExtractor.js

import fetch from 'node-fetch';
import * as cheerio from 'cheerio';

/**
 * Extracts metadata from a given URL.
 * @param {string} url - The URL to extract metadata from.
 * @returns {Promise<string>} - The formatted metadata in Markdown.
 * @throws {Error} - If fetching or parsing fails.
 */
export async function extractMetadata(url) {
  try {
    const response = await fetch(url);
    if (!response.ok) {
      throw new Error(`Failed to fetch URL for metadata: ${response.status} ${response.statusText}`);
    }

    const html = await response.text();
    const $ = cheerio.load(html);

    const title = $('title').text().trim() || new URL(url).hostname;
    const description = $('meta[name="description"]').attr('content') || '';
    const author = $('meta[name="author"]').attr('content') || '';
    const keywords = $('meta[name="keywords"]').attr('content') || '';

    const metadataLines = [
      `# ${title}`,
      '',
      description ? `> ${description}` : '',
      '',
      '## Metadata',
      '',
      `- **Source:** [${url}](${url})`,
      `- **Captured:** ${new Date().toISOString()}`,
      author ? `- **Author:** ${author}` : '',
      keywords ? `- **Keywords:** ${keywords}` : '',
      '',
      '---',
      ''
    ];

    return metadataLines.filter(Boolean).join('\n');
  } catch (error) {
    throw new Error(`Failed to extract metadata: ${error.message}`);
  }
}

```



